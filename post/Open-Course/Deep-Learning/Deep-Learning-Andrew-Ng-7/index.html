<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/tag.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/tag.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/tag.png">
  <link rel="mask-icon" href="/images/tag.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto Sans SC:300,300italic,400,400italic,700,700italic|Encode Sans:300,300italic,400,400italic,700,700italic|M PLUS 1p:300,300italic,400,400italic,700,700italic|Mulish:300,300italic,400,400italic,700,700italic|Oxygen Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.bugstop.cc","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":"flat"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Deep Learning Specialization, Course BImproving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationby deeplearning.ai, Andrew Ng, Coursera Week 3: Hyperparameter Tuning, Batch">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep Learning (7) · Hyperparameter Tuning">
<meta property="og:url" content="https://www.bugstop.cc/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/">
<meta property="og:site_name" content="bugstop">
<meta property="og:description" content="Deep Learning Specialization, Course BImproving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimizationby deeplearning.ai, Andrew Ng, Coursera Week 3: Hyperparameter Tuning, Batch">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://www.bugstop.cc/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/1.png">
<meta property="og:image" content="https://www.bugstop.cc/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/2.png">
<meta property="og:image" content="https://www.bugstop.cc/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/3.png">
<meta property="og:image" content="https://www.bugstop.cc/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/4.png">
<meta property="article:published_time" content="2020-04-02T05:33:34.000Z">
<meta property="article:modified_time" content="2021-01-29T02:21:36.027Z">
<meta property="article:author" content="Muhan Li">
<meta property="article:tag" content="Artificial Intelligence">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.bugstop.cc/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/1.png">

<link rel="canonical" href="https://www.bugstop.cc/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Deep Learning (7) · Hyperparameter Tuning | bugstop</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">bugstop</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Tech Blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="far fa-window-maximize fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fas fa-quote-left fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fas fa-hashtag fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fas fa-bars fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fas fa-inbox fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    

  <a href="https://github.com/bugstop" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://www.bugstop.cc/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lightball.png">
      <meta itemprop="name" content="Muhan Li">
      <meta itemprop="description" content="bugstop">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bugstop">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Deep Learning (7) · Hyperparameter Tuning
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 04-02-2020 13:33:34" itemprop="dateCreated datePublished" datetime="2020-04-02T13:33:34+08:00">04-02-2020</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Open-Course/" itemprop="url" rel="index"><span itemprop="name">Open Course</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Open-Course/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>7.6k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>7 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Deep Learning Specialization, Course B<br><strong>Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization</strong><br>by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a target="_blank" rel="noopener" href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 3:</em></strong> <em>Hyperparameter Tuning, Batch Normalization and Programming Frameworks</em></p>
<ol>
<li>Master the process of hyperparameter tuning</li>
</ol>
<a id="more"></a>
<h3 id="Hyperparameter-Tuning"><a href="#Hyperparameter-Tuning" class="headerlink" title="Hyperparameter Tuning"></a>Hyperparameter Tuning</h3><h4 id="Tuning-Process"><a href="#Tuning-Process" class="headerlink" title="Tuning Process"></a>Tuning Process</h4><ul>
<li><strong>hyperparameter</strong></li>
<li><strong><em>α</em></strong><ul>
<li><strong>β</strong> ~ 0.9</li>
<li>β<sub>1</sub>, β<sub>2</sub>, ε = 0.9, 0.999, 10<sup>-8</sup></li>
<li><em># layers</em></li>
<li><strong># hidden units</strong></li>
<li><em>learning rate decay</em></li>
<li><strong>mini-batch size</strong></li>
</ul>
</li>
</ul>
<p>try <strong>random values,</strong> don’t use a <em>grid;</em><br><strong>coarse to fine</strong> search</p>
<h4 id="Using-an-Appropriate-Scale-to-Pick-Hyperparameters"><a href="#Using-an-Appropriate-Scale-to-Pick-Hyperparameters" class="headerlink" title="Using an Appropriate Scale to Pick Hyperparameters"></a>Using an Appropriate Scale to Pick Hyperparameters</h4><p>α ~ 10<sup>a</sup> ~ 10<sup>b</sup></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = np.random.uniform(a, b)</span><br><span class="line">alpha = <span class="number">10</span> ** r</span><br></pre></td></tr></table></figure>
<p>β ~ 0.9 ~ 0.999… → 1-10<sup>b</sup> ~ 1-10<sup>a</sup></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = np.random.uniform(a, b)</span><br><span class="line">beta = <span class="number">1</span> - <span class="number">10</span> ** r</span><br></pre></td></tr></table></figure>
<h4 id="Hyperparameters-Tuning-in-Practice-Pandas-vs-Caviar"><a href="#Hyperparameters-Tuning-in-Practice-Pandas-vs-Caviar" class="headerlink" title="Hyperparameters Tuning in Practice: Pandas vs. Caviar"></a>Hyperparameters Tuning in Practice: Pandas vs. Caviar</h4><ul>
<li><strong><em>Pandas:</em></strong> babysitting one model</li>
<li><strong><em>Caviar:</em></strong> training many models in parallel</li>
</ul>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><h4 id="Normalizing-Activations-in-a-Network"><a href="#Normalizing-Activations-in-a-Network" class="headerlink" title="Normalizing Activations in a Network"></a>Normalizing Activations in a Network</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/1.png" alt="c"></p>
<p>$\qquad \begin{aligned}\mu &amp;= \frac{1}{m} \sum_{i=1}^{m} x^{\left( i \right)} \\\sigma ^2 &amp;= \frac{1}{m} \sum_{i=1}^{m} { x^{\left( i \right)} } ^2 \\ x &amp;= \dfrac{x- \mu}{\sigma} \end{aligned}$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/2.png" alt="c"></p>
<p><strong>normalize z<sup>[l]</sup></strong></p>
<p>Given some intermediate values $z^{\left[l\right]\left(i\right)} = z^{\left( 1 \right)},\,z^{\left( 2 \right)},\,\dots,\,z^{\left( m \right)}$</p>
<p>$\qquad \begin{aligned}\mu &amp;= \frac{1}{m} \sum_{i=1}^{m} z^{\left( i \right)} \\ \sigma ^2 &amp;= \frac{1}{m} \sum_{i=1}^{m} {\left( z^{\left( i \right)} -\mu \right)} ^2 \\ z^{\left( i \right)}_{\rm norm} &amp;= \dfrac{z^{\left( i \right)}- \mu}{\sqrt{ \sigma^2 + \varepsilon }} \\ \tilde{z}^{\left( i \right)} &amp;= \gamma z^{\left( i \right)}_{\rm norm} + \beta \end{aligned}$</p>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;<em>γ, β are learnable parameters of your model</em></p>
<p>use $\tilde{z}^{\left[l\right]\left(i\right)}$ instead of $z^{\left[l\right]\left(i\right)}$</p>
<h4 id="Fitting-Batch-Norm-into-a-Neural-Network"><a href="#Fitting-Batch-Norm-into-a-Neural-Network" class="headerlink" title="Fitting Batch Norm into a Neural Network"></a>Fitting Batch Norm into a Neural Network</h4><p>$x \xrightarrow{ W^{\left[1\right]},\,b^{\left[1\right]} } z^{\left[1\right]} \xrightarrow[\small {}^\textsf{Batch Norm}]{ \gamma^{\left[1\right]},\,\beta^{\left[1\right]} } \tilde{z}^{\left[1\right]} \xrightarrow[\small {}^{g^{\left[1\right]}}]{} a^{\left[1\right]}  \xrightarrow{ W^{\left[2\right]},\,b^{\left[2\right]} } z^{\left[2\right]} \xrightarrow[\small {}^\textsf{Batch Norm}]{ \gamma^{\left[2\right]},\,\beta^{\left[2\right]} } \tilde{z}^{\left[2\right]} \xrightarrow[\small {}^{g^{\left[2\right]}}]{} a^{\left[2\right]} \xrightarrow{} \cdots$</p>
<p><strong>Parameters:</strong> $\begin{aligned} &amp; W^{\left[1\right]},\,b^{\left[1\right]} ,\, W^{\left[2\right]},\,b^{\left[2\right]} ,\, \dots,\, W^{\left[l\right]},\,b^{\left[l\right]} \\  &amp; \gamma^{\left[1\right]},\,\beta^{\left[1\right]} ,\, \gamma^{\left[2\right]},\,\beta^{\left[2\right]} ,\, \dots,\, \gamma^{\left[l\right]},\,\beta^{\left[l\right]} \end{aligned}$</p>
<h5 id="working-with-mini-batches"><a href="#working-with-mini-batches" class="headerlink" title="working with mini-batches"></a>working with mini-batches</h5><p>$\begin{aligned} &amp; X^{\left\{1\right\}} \xrightarrow{ W^{\left[1\right]},\,b^{\left[1\right]} } Z^{\left[1\right]} \xrightarrow[\small {}^\textsf{Batch Norm}]{ \gamma^{\left[1\right]},\,\beta^{\left[1\right]} } \tilde{Z}^{\left[1\right]} \xrightarrow[\small {}^{g^{\left[1\right]}}]{} A^{\left[1\right]}  \xrightarrow{ W^{\left[2\right]},\,b^{\left[2\right]} } Z^{\left[2\right]} \xrightarrow[\small {}^\textsf{Batch Norm}]{ \gamma^{\left[2\right]},\,\beta^{\left[2\right]} } \tilde{Z}^{\left[2\right]} \xrightarrow[\small {}^{g^{\left[2\right]}}]{} A^{\left[2\right]} \xrightarrow{} \cdots \\ &amp; X^{\left\{2\right\}} \xrightarrow{ W^{\left[1\right]},\,b^{\left[1\right]} } Z^{\left[1\right]} \xrightarrow[\small {}^\textsf{Batch Norm}]{ \gamma^{\left[1\right]},\,\beta^{\left[1\right]} } \tilde{Z}^{\left[1\right]} \xrightarrow[\small {}^{g^{\left[1\right]}}]{} A^{\left[1\right]}  \xrightarrow{ W^{\left[2\right]},\,b^{\left[2\right]} } Z^{\left[2\right]} \xrightarrow[\small {}^\textsf{Batch Norm}]{ \gamma^{\left[2\right]},\,\beta^{\left[2\right]} } \tilde{Z}^{\left[2\right]} \xrightarrow[\small {}^{g^{\left[2\right]}}]{} A^{\left[2\right]} \xrightarrow{} \cdots \\ &amp; \cdots \end{aligned}$</p>
<p>&emsp;&emsp;<strong><em>Notice:</em></strong> b<sup>[l]</sup> can be eliminated (or always be zero) since it is subtracted out during batch normalization</p>
<p>&emsp;&emsp;$\begin{aligned} &amp; z^{\left[l\right]} = W^{\left[l\right]}a^{\left[l-1\right]} \\ &amp; \tilde{z}^{\left[l\right]} = \gamma^{\left[l\right]} z^{\left( l \right)}_{\rm norm} +\beta^{\left[l\right]} \end{aligned}$</p>
<p><strong>Parameters:</strong> $W^{\left[1\right]} \in \mathbb{R}^{n^{\left[ l \right]} \times n^{\left[ l-1 \right]}} ,\quad \gamma^{\left[l\right]} \in \mathbb{R}^{n^{\left[ l \right]} \times 1} ,\quad \beta^{\left[l\right]} \in \mathbb{R}^{n^{\left[ l \right]} \times 1}$</p>
<p>for t = 1, 2, …, num_mini_batches</p>
<p>&emsp;&emsp;forward prop on X<sup>{t}</sup></p>
<p>&emsp;&emsp;&emsp;&emsp;in each hidden layer, use BN to replace z<sup>[l]</sup> with z̃<sup>[l]</sup></p>
<p>&emsp;&emsp;back prop  to compute dW<sup>[l]</sup>, dγ<sup>[l]</sup>, dβ<sup>[l]</sup></p>
<p>&emsp;&emsp;update parameters</p>
<p>&emsp;&emsp;$\qquad \begin{aligned} &amp; W^{\left[l\right]} := W^{\left[l\right]} - dW^{\left[l\right]} \\ &amp; \gamma^{\left[l\right]} := \gamma^{\left[l\right]} - d\gamma^{\left[l\right]} \\ &amp; \beta^{\left[l\right]} := \beta^{\left[l\right]} - d\beta^{\left[l\right]} \end{aligned}$</p>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<em>works with Momentum / RMSProp / Adam</em></p>
<h4 id="Why-does-Batch-Norm-Work"><a href="#Why-does-Batch-Norm-Work" class="headerlink" title="Why does Batch Norm Work?"></a>Why does Batch Norm Work?</h4><p><strong>covariate shift</strong></p>
<p>batch norm limits the amount to which updating the parameters in the earlier layers can affect the distribution of values that the layer now sees and therefore has to learn on</p>
<p><strong>regularization</strong></p>
<p>similar to dropout, batch norm adds some noise to each hidden layer’s activations which has a <em>slight</em> effect</p>
<h4 id="Batch-Norm-at-Test-Time"><a href="#Batch-Norm-at-Test-Time" class="headerlink" title="Batch Norm at Test Time"></a>Batch Norm at Test Time</h4><p><strong>on mini-batches:</strong></p>
<p>$\qquad \begin{aligned}\mu^{\left[l\right]} &amp;= \frac{1}{m} \sum_{i=1}^{m} z^{\left[l\right]\left(i\right)} \\ {\sigma ^2} ^{\left[l\right]} &amp;= \frac{1}{m} \sum_{i=1}^{m} {\left( z^{\left[l\right]\left(i\right)} -\mu ^{\left[l\right]} \right)} ^2 \\ z^{\left[l\right]\left(i\right)}_{\rm norm} &amp;= \dfrac{z^{\left[l\right]\left(i\right)}- \mu ^{\left[l\right]}}{\sqrt{ {\sigma ^2} ^{\left[l\right]} + \varepsilon }} \\ \tilde{z}^{\left[l\right]\left(i\right)} &amp;= \gamma^{\left[l\right]}  z^{\left[l\right]\left(i\right)}_{\rm norm} + \beta ^{\left[l\right]} \end{aligned}$</p>
<p><strong>at test time:</strong></p>
<p>μ, σ<sup>2</sup> is estimated using a exponentially weighted average (across the mini-batches)</p>
<p>$\qquad \begin{aligned}\mu ^{\left[l\right]} &amp;= \frac{1}{T} \sum_{t=1}^{T} \mu^{\left\{t\right\} \left[l\right]} \\ {\sigma ^2} ^{\left[l\right]} &amp;= \frac{1}{T} \sum_{t=1}^{T} {\sigma ^2}^{\left\{t\right\} \left[l\right]} \\ z^{\left[l\right]\left(i\right)}_{\rm norm} &amp;= \dfrac{z^{\left[l\right]\left(i\right)}- \mu ^{\left[l\right]}}{\sqrt{ {\sigma ^2} ^{\left[l\right]} + \varepsilon }} \\ \tilde{z}^{\left[l\right]\left(i\right)} &amp;= \gamma^{\left[l\right]}  z^{\left[l\right]\left(i\right)}_{\rm norm} + \beta ^{\left[l\right]} \end{aligned}$</p>
<h3 id="Multi-Class-Classification"><a href="#Multi-Class-Classification" class="headerlink" title="Multi-Class Classification"></a>Multi-Class Classification</h3><h4 id="Softmax-Regression"><a href="#Softmax-Regression" class="headerlink" title="Softmax Regression"></a>Softmax Regression</h4><p><strong>C = #classes</strong> = 4 → <strong>n<sup>[L]</sup> = C</strong> = 4 → ŷ ∈ R<sup>4×1</sup></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/3.png" alt="c"></p>
<p>$\begin{aligned} z^{\left[L\right]} &amp;= W^{\left[L\right]} a^{\left[L-1\right]} + b^{\left[L\right]} \\ &amp; \textsf{Activation Function}^{\strut} \\ t &amp;= e^{ z^{\left[L\right]} } , \qquad t \in \mathbb{R}^{4 \times 1} \\ a^{\left[L\right]} &amp;= \dfrac{e^{ z^{\left[L\right]} }}{\sum_{i=1}^{4} t_i} , \qquad a_i^{\left[L\right]} = \dfrac{t_i}{\sum_{i=1}^{4} t_i} \end{aligned}$</p>
<p>$\Rightarrow {\rm softmax:}\ \ a^{\left[L\right]}_{\Tiny{(C,1)}} = g^{\left[L\right]} \left( z^{\left[L\right]}_{\Tiny{(C,1)}} \right)$</p>
<p><strong><em>softmax regression generalizes logistic regression to C classes</em></strong></p>
<h4 id="Training-a-Softmax-Classifier"><a href="#Training-a-Softmax-Classifier" class="headerlink" title="Training a Softmax Classifier"></a>Training a Softmax Classifier</h4><h5 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h5><p>$\begin{aligned}&amp; y= \left[\begin{matrix} 0\\1\\0\\0 \end{matrix}\right] \quad a^{\left[L\right]} = \hat{y}= \left[\begin{matrix} 0.3\\0.2\\0.1\\0.4 \end{matrix}\right] \qquad C=4 \\ &amp; \ \ \ \ \qquad\qquad\qquad\qquad\qquad\Downarrow \\ &amp; L\left(\hat{y},\,y\right) = -\sum_{j=1}^{4} y_j \log \hat{y}_j = -\log \hat{y}_2 \Rightarrow \hat{y}_2 \uparrow \\ &amp; J\left( W^{\left[1\right]},b^{\left[1\right]}, \dots,W^{\left[L\right]},b^{\left[L\right]} \right) = \dfrac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{\left(i\right)},\,y^{\left(i\right)}\right) \end{aligned}$</p>
<h5 id="Gradient-Decent"><a href="#Gradient-Decent" class="headerlink" title="Gradient Decent"></a>Gradient Decent</h5><p>$dz^{\left[L\right]} = \dfrac{\partial J}{\partial z^{\left[L\right]}} = \hat{y}-y$</p>
<h3 id="Introduction-to-Programming-Frameworks"><a href="#Introduction-to-Programming-Frameworks" class="headerlink" title="Introduction to Programming Frameworks"></a>Introduction to Programming Frameworks</h3><h4 id="Deep-Learning-Frameworks"><a href="#Deep-Learning-Frameworks" class="headerlink" title="Deep Learning Frameworks"></a>Deep Learning Frameworks</h4><ul>
<li>ease of programming</li>
<li>running speed</li>
<li>truly open</li>
</ul>
<h4 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h4><p><a href="Deep-Learning-Andrew-Ng-7/tensorflow.ipynb">tensorflow.ipynb</a></p>
<h3 id="Programming-Assignments"><a href="#Programming-Assignments" class="headerlink" title="Programming Assignments"></a>Programming Assignments</h3><h4 id="TensorFlow-1"><a href="#TensorFlow-1" class="headerlink" title="TensorFlow"></a>TensorFlow</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/4.png" alt="t"></p>
<p><a href="https://github.com/bugstop/coursera-deep-learning-solutions" target="_blank">Solutions Manual</a></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Artificial-Intelligence/" rel="tag"># Artificial Intelligence</a>
              <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-6/" rel="prev" title="Deep Learning (6) · Optimization Algorithms">
      <i class="fa fa-chevron-left"></i> Deep Learning (6) · Optimization Algorithms
    </a></div>
      <div class="post-nav-item">
    <a href="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-8/" rel="next" title="Deep Learning (8) · ML Strategy · I">
      Deep Learning (8) · ML Strategy · I <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hyperparameter-Tuning"><span class="nav-number">1.</span> <span class="nav-text">Hyperparameter Tuning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Tuning-Process"><span class="nav-number">1.1.</span> <span class="nav-text">Tuning Process</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Using-an-Appropriate-Scale-to-Pick-Hyperparameters"><span class="nav-number">1.2.</span> <span class="nav-text">Using an Appropriate Scale to Pick Hyperparameters</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hyperparameters-Tuning-in-Practice-Pandas-vs-Caviar"><span class="nav-number">1.3.</span> <span class="nav-text">Hyperparameters Tuning in Practice: Pandas vs. Caviar</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Batch-Normalization"><span class="nav-number">2.</span> <span class="nav-text">Batch Normalization</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Normalizing-Activations-in-a-Network"><span class="nav-number">2.1.</span> <span class="nav-text">Normalizing Activations in a Network</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Fitting-Batch-Norm-into-a-Neural-Network"><span class="nav-number">2.2.</span> <span class="nav-text">Fitting Batch Norm into a Neural Network</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#working-with-mini-batches"><span class="nav-number">2.2.1.</span> <span class="nav-text">working with mini-batches</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Why-does-Batch-Norm-Work"><span class="nav-number">2.3.</span> <span class="nav-text">Why does Batch Norm Work?</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Batch-Norm-at-Test-Time"><span class="nav-number">2.4.</span> <span class="nav-text">Batch Norm at Test Time</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Multi-Class-Classification"><span class="nav-number">3.</span> <span class="nav-text">Multi-Class Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Softmax-Regression"><span class="nav-number">3.1.</span> <span class="nav-text">Softmax Regression</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Training-a-Softmax-Classifier"><span class="nav-number">3.2.</span> <span class="nav-text">Training a Softmax Classifier</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Loss-Function"><span class="nav-number">3.2.1.</span> <span class="nav-text">Loss Function</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Gradient-Decent"><span class="nav-number">3.2.2.</span> <span class="nav-text">Gradient Decent</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Introduction-to-Programming-Frameworks"><span class="nav-number">4.</span> <span class="nav-text">Introduction to Programming Frameworks</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Deep-Learning-Frameworks"><span class="nav-number">4.1.</span> <span class="nav-text">Deep Learning Frameworks</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TensorFlow"><span class="nav-number">4.2.</span> <span class="nav-text">TensorFlow</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Programming-Assignments"><span class="nav-number">5.</span> <span class="nav-text">Programming Assignments</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#TensorFlow-1"><span class="nav-number">5.1.</span> <span class="nav-text">TensorFlow</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Muhan Li"
      src="/images/lightball.png">
  <p class="site-author-name" itemprop="name">Muhan Li</p>
  <div class="site-description" itemprop="description">bugstop</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">39</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/bugstop" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;bugstop" rel="noopener" target="_blank"><i class="fab fa-github-square fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.linkedin.com/public-profile/in/limh" title="LinkedIn → https:&#x2F;&#x2F;www.linkedin.com&#x2F;public-profile&#x2F;in&#x2F;limh" rel="noopener" target="_blank"><i class="fab fa-linkedin fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:limuhan@msn.com" title="Email → mailto:limuhan@msn.com" rel="noopener" target="_blank"><i class="fas fa-envelope-square fa-fw"></i></a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fas fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Li, Muhan</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">159k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">2:24</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
