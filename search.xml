<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Artificial Intelligence (1) · Introduction</title>
    <url>/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-1/</url>
    <content><![CDATA[<h3 id="课程信息"><a href="#课程信息" class="headerlink" title="课程信息"></a>课程信息</h3><p>MIT OPEN COURSE WARE<br>6.034, Fall 2010, <strong>Artificial Intelligence,</strong> <em>Patrick H. Winston</em><br><a href="https://www.youtube.com/watch?v=TjZBTDzGeGg&amp;list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi">Youtube</a> / <a href="https://www.bilibili.com/video/av75097245">Bilibili</a></p>
<p><br></p>
<p>本节内容：生成测试，状态图和状态空间</p>
<!--
<br>

### 写作目的

虽然写第一讲之前我就已经把整个课程看完了，但是怕马上转眼就忘了（其实已经记不太清了），所以一是稍微总结一下加深记忆，另外梳理一下以后方便回头看。在这里主要写一下每一讲的关键点，详细内容还要看原视频。然后可能会有很多疏漏错误，请一切以 Winston 原文为准 2333
-->
<a id="more"></a>
<p><br></p>
<h3 id="第一讲-概论"><a href="#第一讲-概论" class="headerlink" title="第一讲 概论"></a>第一讲 概论</h3><h4 id="Definition-of-Artificial-Intelligence"><a href="#Definition-of-Artificial-Intelligence" class="headerlink" title="Definition of Artificial Intelligence"></a>Definition of Artificial Intelligence</h4><p>Algorithms enabled by<br>Constraint exposed by<br>Representations that support<br>Models targeted at<br>Thinking Perception Action</p>
<p><br></p>
<h4 id="Generate-and-Test"><a href="#Generate-and-Test" class="headerlink" title="Generate and Test"></a>Generate and Test</h4><p>生成器：不冗余（重复），且能提供足够的信息以判断<br><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-1/gt.png" alt="Generate and Test"></p>
<p><br></p>
<h4 id="状态图和推理-Reasoning"><a href="#状态图和推理-Reasoning" class="headerlink" title="状态图和推理 (Reasoning)"></a>状态图和推理 (Reasoning)</h4><p>状态空间法（例：农夫过河问题）</p>
<p><br></p>
<h4 id="语言-Language"><a href="#语言-Language" class="headerlink" title="语言 (Language)"></a>语言 (Language)</h4><ol>
<li>讲故事和理解故事</li>
<li>整理感官系统和指挥感官系统</li>
</ol>
<p><br></p>
<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p><strong>Rumpelstilskin Principle</strong><br>Once you have a name for something, you get power over it.</p>
<p><strong>Occam’s Razor</strong><br>Simple ideas are often the most powerful.</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>
<p><br></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>Artificial Intelligence (2) · Reasoning</title>
    <url>/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-2/</url>
    <content><![CDATA[<h3 id="课程信息"><a href="#课程信息" class="headerlink" title="课程信息"></a>课程信息</h3><p>MIT OPEN COURSE WARE<br>6.034, Fall 2010, <strong>Artificial Intelligence,</strong> <em>Patrick H. Winston</em><br><a href="https://www.youtube.com/watch?v=TjZBTDzGeGg&amp;list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi">Youtube</a> / <a href="https://www.bilibili.com/video/av75097245">Bilibili</a></p>
<p><br></p>
<p>本节内容：目标树，产生式系统</p>
<a id="more"></a>
<p><br></p>
<h4 id="第二讲-目标树与问题求解"><a href="#第二讲-目标树与问题求解" class="headerlink" title="第二讲 目标树与问题求解"></a>第二讲 目标树与问题求解</h4><h4 id="Problem-Reduction"><a href="#Problem-Reduction" class="headerlink" title="Problem Reduction"></a>Problem Reduction</h4><p><strong>Goal Tree</strong> (also called <strong>and/or tree</strong>, <strong>problem reduction tree</strong>)</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-2/GoalTree.jpg" alt="GoalTree"></p>
<p>PROCEDURE:</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-2/math.png" alt="math"></p>
<p>Safe transformations, Heuristic transformations</p>
<p><br></p>
<h4 id="CATECHISM"><a href="#CATECHISM" class="headerlink" title="CATECHISM"></a>CATECHISM</h4><ul>
<li>WHAT KIND</li>
<li>HOW REPRESENTED</li>
<li>HOW USED</li>
<li>HOW MUCH</li>
<li>WHAT EXACTLY</li>
</ul>
<p><br></p>
<h4 id="Modeling-Problem-Solving"><a href="#Modeling-Problem-Solving" class="headerlink" title="Modeling Problem Solving"></a>Modeling Problem Solving</h4><ul>
<li>Generate and Test</li>
<li>Problem Reduction</li>
</ul>
<p><br></p>
<h3 id="第三讲-目标树和基于规则的专家系统（产生式）"><a href="#第三讲-目标树和基于规则的专家系统（产生式）" class="headerlink" title="第三讲 目标树和基于规则的专家系统（产生式）"></a>第三讲 目标树和基于规则的专家系统（产生式）</h3><h4 id="移放方块问题"><a href="#移放方块问题" class="headerlink" title="移放方块问题"></a>移放方块问题</h4><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-2/box.jpg" alt="box"></p>
<p><strong>Goal tree can answer certain kinds of questions about its own behavior.</strong></p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-2/gt.jpg" alt="box"></p>
<p><br></p>
<h4 id="Simon’s-Ant"><a href="#Simon’s-Ant" class="headerlink" title="Simon’s Ant"></a>Simon’s Ant</h4><p>The complexity of the behavior is a consequence of the complexity of the environment, not the complexity of the program.</p>
<p><strong>C(behavior) = max{C(program), C(environment)}</strong></p>
<p><br></p>
<h4 id="RULE-BASED-SYSTEM"><a href="#RULE-BASED-SYSTEM" class="headerlink" title="RULE-BASED SYSTEM"></a>RULE-BASED SYSTEM</h4><p><em>BUILDING A GOAL TREE</em></p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-2/ExpertSystem.jpg" alt="ExpertSystem"></p>
<ul>
<li><p><strong>FORWARD-CHAINING RULE-BASED “EXPERT” SYSTEM</strong></p>
<p>work forward from facts</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-2/ExpertSystem1.jpg" alt="ExpertSystem"></p>
</li>
<li><p><strong>BACKWARD-CHAINING RULE-BASED “EXPERT” SYSTEM</strong></p>
<p>work backward from a hypothesis</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-2/ExpertSystem2.jpg" alt="ExpertSystem"></p>
</li>
</ul>
<p><strong>Deduction(演绎) System:</strong> working with facts to produce new facts</p>
<p><br></p>
<h4 id="建立规则库"><a href="#建立规则库" class="headerlink" title="建立规则库"></a>建立规则库</h4><ol>
<li>将专家做法转化为 IF-THEN 条件语句</li>
<li>考虑个例（而 1 中只得到了总体的规则）</li>
<li>考虑看起来相同但实际处理不同的东西</li>
<li>运行系统，看它在什么情况下会出错</li>
</ol>
<p><br></p>
<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>Knowledge <strong>about knowledge</strong> is power.</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>
<p><br></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>Artificial Intelligence (4) · Search · II</title>
    <url>/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-4/</url>
    <content><![CDATA[<h3 id="课程信息"><a href="#课程信息" class="headerlink" title="课程信息"></a>课程信息</h3><p>MIT OPEN COURSE WARE<br>6.034, Fall 2010, <strong>Artificial Intelligence,</strong> <em>Patrick H. Winston</em><br><a href="https://www.youtube.com/watch?v=TjZBTDzGeGg&amp;list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi">Youtube</a> / <a href="https://www.bilibili.com/video/av75097245">Bilibili</a></p>
<p><br></p>
<p>本节内容：极小极大，α-β 剪枝</p>
<a id="more"></a>
<p><br></p>
<h3 id="第六讲-博弈、极小极大、α-β-剪枝"><a href="#第六讲-博弈、极小极大、α-β-剪枝" class="headerlink" title="第六讲 博弈、极小极大、α-β 剪枝"></a>第六讲 博弈、极小极大、α-β 剪枝</h3><h4 id="下棋程序"><a href="#下棋程序" class="headerlink" title="下棋程序"></a>下棋程序</h4><ol>
<li><p><del>Analysis Strategy Tactics</del></p>
</li>
<li><p>IF-THEN Rules</p>
</li>
<li><p>Look Ahead &amp; Evaluate</p>
<p>static value $ S=g\left( f_{1},f_{2},\ldots ,f_{n}\right) =c_{1}f_{1}+c_{1}f_{2}+\ldots +c_{n}f_{n} $</p>
</li>
<li><p>British Museum</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-4/vocab.jpg" alt="vocab"></p>
</li>
<li><p>LOOK AHEAD AS FAR AS POSSIBLE</p>
<ul>
<li><p>Game Tree</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-4/GameTree.jpg" alt="GameTree"></p>
</li>
<li><p>Pruning</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-4/Pruning.jpg" alt="Pruning"><strong>注意：α-β 剪枝是对 minimax 的优化（而不是近似），因此会给出同样的解</strong></p>
</li>
<li><p><em>Deep Cutoff</em></p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-4/DeepCutoff.jpg" alt="DeepCutoff"></p>
<p><strong>S ≈ 2b<sup>d/2</sup></strong> —— 同样算力加多了一倍深度 / 同样深度所需算力开根号</p>
</li>
<li><p><strong><em>Progressive Deepening</em></strong></p>
<pre><code> 为避免运行超时得不到结果而只能走随机的一步，可以在上（每）一层先给出一个走法，一层一层做极小极大。这样只需要完成当前层的 1/d 算力，却能给出比较靠谱的结果。从下面的式子看出，对每一层的代价求和，总代价与只算倒数第二层相差不大。
</code></pre><p>$ S’=1+b+b^{2}+\ldots +b^{n-1}=\dfrac {b^{n}-1}{b-1}\approx b^{n-1} $<br><br><em>P.S. 计算的中间值将用于对树重新排序以求得最大化的剪枝</em></p>
</li>
</ul>
</li>
</ol>
<p><br></p>
<h4 id="Minimax-Alpha-Beta-Progressive-Deepening"><a href="#Minimax-Alpha-Beta-Progressive-Deepening" class="headerlink" title="Minimax + Alpha-Beta + Progressive Deepening"></a>Minimax + Alpha-Beta + Progressive Deepening</h4><ul>
<li><strong>DEAD HORSE PRINCIPLE</strong><br>一旦确定比最优差，就把整枝剪掉</li>
<li><strong>MARSHALL ARTS PRINCIPLE</strong><br>在每一层给出结果，避免下一层算不完</li>
<li><strong>ANYTIME ALGORITHMS</strong><br>一旦需要，随时都能给出一个（当时的最佳）答案</li>
</ul>
<p><br></p>
<h4 id="Deep-Blue"><a href="#Deep-Blue" class="headerlink" title="Deep Blue"></a>Deep Blue</h4><ul>
<li>MINIMAX</li>
<li>Alpha-Beta</li>
<li>Progressive Deepening</li>
<li>Parallel Computing</li>
<li>Opening Book</li>
<li>End Game</li>
<li><strong>Uneven Tree Development</strong></li>
</ul>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>Artificial Intelligence (3) · Search · I</title>
    <url>/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-3/</url>
    <content><![CDATA[<h3 id="课程信息"><a href="#课程信息" class="headerlink" title="课程信息"></a>课程信息</h3><p>MIT OPEN COURSE WARE<br>6.034, Fall 2010, <strong>Artificial Intelligence,</strong> <em>Patrick H. Winston</em><br><a href="https://www.youtube.com/watch?v=TjZBTDzGeGg&amp;list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi">Youtube</a> / <a href="https://www.bilibili.com/video/av75097245">Bilibili</a></p>
<p><br></p>
<p>本节内容：深度优先，广度优先，爬山算法，束搜索，代价一致，A*</p>
<a id="more"></a>
<p><br></p>
<h3 id="第四讲-深度优先、广度优先、爬山算法、-集束搜索"><a href="#第四讲-深度优先、广度优先、爬山算法、-集束搜索" class="headerlink" title="第四讲 深度优先、广度优先、爬山算法、 集束搜索"></a>第四讲 深度优先、广度优先、爬山算法、 集束搜索</h3><h4 id="British-Museum-Search"><a href="#British-Museum-Search" class="headerlink" title="British Museum Search"></a>British Museum Search</h4><p>find every possible path（注意不能绕圈）</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-3/BritishMuseum.jpg" alt="British Museum"></p>
<p><br></p>
<h4 id="Depth-First-Search"><a href="#Depth-First-Search" class="headerlink" title="Depth First Search"></a>Depth First Search</h4><p><em>backup / backtracking</em></p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-3/DepthFirst.jpg" alt="Depth First"></p>
<p><br></p>
<h4 id="Breadth-First-Search"><a href="#Breadth-First-Search" class="headerlink" title="Breadth First Search"></a>Breadth First Search</h4><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-3/BreadthFirst.jpg" alt="Breadth First"></p>
<p><br></p>
<h4 id="Hill-Climbing"><a href="#Hill-Climbing" class="headerlink" title="Hill Climbing"></a>Hill Climbing</h4><p>深度优先的改良：每次拓展离目标最近的节点</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-3/HillClimbing.jpg" alt="Hill Climbing"></p>
<p><strong>在连续空间中使用爬山算法可能存在的问题：</strong></p>
<ol>
<li>卡在局部极大值</li>
<li>遇到电线杆问题</li>
<li>落在山脊上（高维空间尤甚）</li>
</ol>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-3/Hill.jpg" alt="Hill Climbing"></p>
<p><br></p>
<h4 id="Beam-Search"><a href="#Beam-Search" class="headerlink" title="Beam Search"></a>Beam Search</h4><p>广度优先的改良：每层只保留离目标最近的 ω 个节点</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-3/BeamSearch.jpg" alt="Beam Search"></p>
<p><br></p>
<h4 id="Best-First-Search"><a href="#Best-First-Search" class="headerlink" title="Best First Search"></a>Best First Search</h4><p>总是拓展整个树中离目标最近的节点</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-3/Algorithm.png" alt="Algorithm"></p>
<p><br></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">SEARCH</th>
<th style="text-align:center">BACKTRACKING</th>
<th style="text-align:center">USE ENQUED LIST</th>
<th style="text-align:center">INFORMED</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>British Museum</strong></td>
<td style="text-align:center">×</td>
<td style="text-align:center">×</td>
<td style="text-align:center">×</td>
</tr>
<tr>
<td style="text-align:center"><strong>Depth First</strong></td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">×</td>
</tr>
<tr>
<td style="text-align:center"><strong>Breadth First</strong></td>
<td style="text-align:center">×</td>
<td style="text-align:center">√</td>
<td style="text-align:center">×</td>
</tr>
<tr>
<td style="text-align:center"><strong>Hill Climbing</strong></td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
</tr>
<tr>
<td style="text-align:center"><strong>Beam Search</strong></td>
<td style="text-align:center">×</td>
<td style="text-align:center">√</td>
<td style="text-align:center">√</td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<h3 id="第五讲-代价一致、A"><a href="#第五讲-代价一致、A" class="headerlink" title="第五讲 代价一致、A*"></a>第五讲 代价一致、A*</h3><h4 id="Uniform-Cost-Search-Branch-amp-Bound"><a href="#Uniform-Cost-Search-Branch-amp-Bound" class="headerlink" title="Uniform Cost Search (Branch &amp; Bound)"></a>Uniform Cost Search (Branch &amp; Bound)</h4><p>每次拓展已经走过的代价最小的路径</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-3/UniformCost.jpg" alt="Uniform Cost"></p>
<p><strong><em>Use Extended List:</em></strong></p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-3/ExtendedList.jpg" alt="UCS+EL"></p>
<p><strong><em>Admissible Heuristic:</em></strong></p>
<p><em>accumulated distance + airline distance</em></p>
<p>admissible: 确保小于实际距离（注：在这里直线距离给出了两点路程的下界）</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-3/AdmissibleHeuristic.jpg" alt="Admissible Heuristic"></p>
<p>在考虑<strong>地图</strong>时，可容许启发式总是最优搜索的稳妥方式，但非欧时：</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-3/AH.jpg" alt="Admissible Heuristic"></p>
<p>因此需要强化可容许启发式的限制条件：</p>
<ul>
<li><p><strong>可容许 admissible</strong><br>$ H\left( x,G\right) \leq D\left( x,G\right) $</p>
</li>
<li><p><strong>一致性 consistent</strong><br>$ \left| H\left( x,G\right) -H\left( y,G\right) \right| \leq D\left( x,y\right) $<br><br></p>
</li>
</ul>
<h4 id="A"><a href="#A" class="headerlink" title="A*"></a>A*</h4><p>use both <strong>EXTENDED LIST</strong> and <strong>ADMISSIBLE HEURISTIC</strong></p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-3/AlgorithmB.png" alt="Algorithm"></p>
<p><br></p>
<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>Search is not about maps; <strong>Search is about choice.</strong></p>

            <i class="fa fa-quote-right"></i>
          </blockquote>
<p><br></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>Artificial Intelligence (5) · Constraints</title>
    <url>/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-5/</url>
    <content><![CDATA[<h3 id="课程信息"><a href="#课程信息" class="headerlink" title="课程信息"></a>课程信息</h3><p>MIT OPEN COURSE WARE<br>6.034, Fall 2010, <strong>Artificial Intelligence,</strong> <em>Patrick H. Winston</em><br><a href="https://www.youtube.com/watch?v=TjZBTDzGeGg&amp;list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi">Youtube</a> / <a href="https://www.bilibili.com/video/av75097245">Bilibili</a></p>
<p><br></p>
<p>本节内容：约束（线条图、地图着色、物体识别）</p>
<!--
<br>

> 期末考试加拖延症，没想到直接拖更到 2020 年了 OTZ 强迫更新一波，本来准备是趁热打铁现在直接变成二刷了 2333
-->
<a id="more"></a>
<p><br></p>
<h3 id="第七讲-解释线条图"><a href="#第七讲-解释线条图" class="headerlink" title="第七讲 解释线条图"></a>第七讲 解释线条图</h3><h4 id="Guzman-的工作"><a href="#Guzman-的工作" class="headerlink" title="Guzman 的工作"></a>Guzman 的工作</h4><p><strong>ABDUCTION:</strong> THREE FACED VERTEXES —&gt; ARROW / FORK</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-5/1.jpg" alt="Guzman"></p>
<p><br></p>
<h4 id="Huffman-的工作"><a href="#Huffman-的工作" class="headerlink" title="Huffman 的工作"></a>Huffman 的工作</h4><p><strong>Characteristics:</strong></p>
<ul>
<li>general position</li>
<li>trihedral, 3 faces</li>
<li>4 kinds of lines (concave, convex, boundary)</li>
<li>(cracks &amp; shadows left out)</li>
</ul>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-5/2.jpg" alt="Huffman"></p>
<p>检验能否构建一个物体<em>（必要非充分条件）</em>：</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-5/3.jpg" alt="Huffman"></p>
<p>（不能处理四面交汇的问题：）</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-5/4.jpg" alt="Huffman"></p>
<p><br></p>
<h4 id="Waltz-的工作"><a href="#Waltz-的工作" class="headerlink" title="Waltz 的工作"></a>Waltz 的工作</h4><p><strong>Waltz’s Label</strong></p>
<ul>
<li>CRACKS</li>
<li>SHADOWS</li>
<li>NON-TRIHEDRAL VERTEXES</li>
<li>LIGHT</li>
</ul>
<p><strong>Waltz’s Algorithm</strong></p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-5/5.jpg" alt="Waltz"></p>
<p><br></p>
<h3 id="第八讲-搜索、域缩减"><a href="#第八讲-搜索、域缩减" class="headerlink" title="第八讲 搜索、域缩减"></a>第八讲 搜索、域缩减</h3><ul>
<li><del>深度优先</del></li>
<li><del>条件约束</del></li>
<li>局部约束（Martial Arts Principal）</li>
</ul>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-5/6.jpg" alt="map"></p>
<h4 id="Domain-Reduction-Algorithm"><a href="#Domain-Reduction-Algorithm" class="headerlink" title="Domain Reduction Algorithm"></a>Domain Reduction Algorithm</h4><p>VARIABLE <strong>V</strong>: something that can have assignment<br>VALUE <strong>x</strong>: something that can be an assignment<br>DOMAIN <strong>D</strong>: bag of values<br>CONSTRAINT <strong>C</strong>: limit on variable values</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FOR EACH DFS ASSIGNMENT</span><br><span class="line">  FOR EACH VARIABLE Vi CONSIDERED</span><br><span class="line">    FOR EACH Xi IN Di</span><br><span class="line">      FOR EACH CONSTRAINT C(Xi, Xj) WHERE Xj ∈ Dj</span><br><span class="line">        IF NOT ∃ Xj SUCH THAT C(Xi, Xj) SATISFIED</span><br><span class="line">          REMOVE Xi FROM Di</span><br><span class="line">        IF Di EMPTY</span><br><span class="line">          BACKUP</span><br></pre></td></tr></table></figure>
<p><strong><em><br>CONSIDERED</em></strong></p>
<ul>
<li><del>NOTHING</del></li>
<li>ASSIGNMENT</li>
<li>NEIGHBORS</li>
<li><strong>PROPAGATE CHECKING THROUGH V WITH D REDUCED TO ONE VALUE</strong></li>
<li>PROPAGATE CHECKING THROUGH V WITH REDUCED D</li>
<li><del>EVERYTHING</del></li>
</ul>
<p><strong>+ 按约束多到少的顺序做深度优先搜索</strong></p>
<p><strong>+ 可以使用两边夹逼的方法快速确定一个狭小的范围</strong></p>
<p><br></p>
<p>类似的问题还有：</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-5/7.jpg" alt="flight"></p>
<p><br></p>
<h3 id="第九讲-视觉对象识别"><a href="#第九讲-视觉对象识别" class="headerlink" title="第九讲 视觉对象识别"></a>第九讲 视觉对象识别</h3><h4 id="Marr-的工作"><a href="#Marr-的工作" class="headerlink" title="Marr 的工作"></a>Marr 的工作</h4><ol>
<li>Camera Input</li>
<li>Primal Sketch</li>
<li>2.5D Sketch</li>
<li>Generalized Cylinders</li>
<li>Recognition</li>
</ol>
<p><br></p>
<h4 id="Ullman’s-ALIGNMENT-THEORY"><a href="#Ullman’s-ALIGNMENT-THEORY" class="headerlink" title="Ullman’s ALIGNMENT THEORY"></a>Ullman’s ALIGNMENT THEORY</h4><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-5/8.jpg" alt="AT"></p>
<p><br></p>
<h4 id="Ullman’s-INTERMEDIATE-FEATURES-THEORY"><a href="#Ullman’s-INTERMEDIATE-FEATURES-THEORY" class="headerlink" title="Ullman’s INTERMEDIATE FEATURES THEORY"></a>Ullman’s INTERMEDIATE FEATURES THEORY</h4><p><strong>Goldilocks Principle:</strong> not too big, not too small</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-5/9.jpg" alt="faces"></p>
<p><strong>SIGNAL, CORRELATION</strong></p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-5/10.jpg" alt="signal"></p>
<script type="math/tex; mode=display">
\max _{X,Y}\int _{x,y}f\left(x-X\right)\cdot g\left(x-X,y-Y\right)</script>]]></content>
      <categories>
        <category>Open Course</category>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>Artificial Intelligence (6) · Learning · I</title>
    <url>/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-6/</url>
    <content><![CDATA[<h3 id="课程信息"><a href="#课程信息" class="headerlink" title="课程信息"></a>课程信息</h3><p>MIT OPEN COURSE WARE<br>6.034, Fall 2010, <strong>Artificial Intelligence,</strong> <em>Patrick H. Winston</em><br><a href="https://www.youtube.com/watch?v=TjZBTDzGeGg&amp;list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi">Youtube</a> / <a href="https://www.bilibili.com/video/av75097245">Bilibili</a></p>
<p><br></p>
<p>本节内容：最近邻、识别树</p>
<a id="more"></a>
<p><br></p>
<h3 id="第十讲-最近邻"><a href="#第十讲-最近邻" class="headerlink" title="第十讲 最近邻"></a>第十讲 最近邻</h3><h4 id="学习的分类"><a href="#学习的分类" class="headerlink" title="学习的分类"></a>学习的分类</h4><ol>
<li>BASED ON <strong>REGULARITY</strong> <sup><em>BULLDOZER</em></sup><ul>
<li>Nearest Neighbors <sup><em>pattern recognition</em></sup></li>
<li>Neural Nets <sup><em>mimic biology</em></sup></li>
<li>Boosting <sup><em>theory</em></sup></li>
</ul>
</li>
<li>BASED ON <strong>CONSTRAINS</strong> <sup><em>HUMANLIKE</em></sup><ul>
<li>One Shot</li>
<li>Explanation Based Learning</li>
</ul>
</li>
</ol>
<p><br></p>
<h4 id="NEAREST-NEIGHBOR-BASED-LEARNING"><a href="#NEAREST-NEIGHBOR-BASED-LEARNING" class="headerlink" title="NEAREST NEIGHBOR BASED LEARNING"></a>NEAREST NEIGHBOR BASED LEARNING</h4><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-6/knn.png" alt="Nearest Neighbor"></p>
<h5 id="插座分类的例子"><a href="#插座分类的例子" class="headerlink" title="插座分类的例子"></a>插座分类的例子</h5><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-6/db.jpg" alt="Decision Boundary"></p>
<h5 id="文章分类的例子"><a href="#文章分类的例子" class="headerlink" title="文章分类的例子"></a>文章分类的例子</h5><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-6/nonsm.jpg" alt="non standard metric"></p>
<h5 id="机械臂运动的例子"><a href="#机械臂运动的例子" class="headerlink" title="机械臂运动的例子"></a>机械臂运动的例子</h5><p>Find the closest match in the ‘childhood’ table:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">θ<sub>1</sub></th>
<th style="text-align:center">θ<sub>2</sub></th>
<th style="text-align:center">θ<sub>1</sub>‘</th>
<th style="text-align:center">θ<sub>2</sub>‘</th>
<th style="text-align:center">θ<sub>1</sub>‘’</th>
<th style="text-align:center">θ<sub>2</sub>‘’</th>
<th style="text-align:center">τ<sub>1</sub></th>
<th style="text-align:center">τ<sub>2</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
</tr>
<tr>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
</tr>
</tbody>
</table>
</div>
<h5 id="存在的一些问题"><a href="#存在的一些问题" class="headerlink" title="存在的一些问题"></a>存在的一些问题</h5><ul>
<li><p><strong>SPREAD</strong> <sup><strong><em>non-uniformity</em></strong></sup> —&gt; NORMALIZE</p>
</li>
<li><p><strong>WHAT MATTERS</strong></p>
</li>
<li><p><strong>INDEPENDENCE</strong><br>confusion of correlation with cause</p>
</li>
</ul>
<p><br></p>
<h3 id="第十一讲-识别树"><a href="#第十一讲-识别树" class="headerlink" title="第十一讲 识别树"></a>第十一讲 识别树</h3><h4 id="IDENTIFICATION-TREES"><a href="#IDENTIFICATION-TREES" class="headerlink" title="IDENTIFICATION TREES"></a>IDENTIFICATION TREES</h4><h5 id="吸血鬼的例子"><a href="#吸血鬼的例子" class="headerlink" title="吸血鬼的例子"></a>吸血鬼的例子</h5><ul>
<li>NON NUMERIC</li>
<li>SOME DON’T MATTER</li>
<li>SOME MATTER ONLY SOME OF TIME</li>
<li>COST</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Vampire</th>
<th style="text-align:center">Shadow</th>
<th style="text-align:center">Garlic</th>
<th style="text-align:center">Complexion</th>
<th style="text-align:center">Accent</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>No</strong></td>
<td style="text-align:center">?</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Pale</td>
<td style="text-align:center">None</td>
</tr>
<tr>
<td style="text-align:center"><strong>No</strong></td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Ruddy</td>
<td style="text-align:center">None</td>
</tr>
<tr>
<td style="text-align:center"><strong>Yes</strong></td>
<td style="text-align:center">?</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Ruddy</td>
<td style="text-align:center">None</td>
</tr>
<tr>
<td style="text-align:center"><strong>Yes</strong></td>
<td style="text-align:center">No</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Average</td>
<td style="text-align:center">Heavy</td>
</tr>
<tr>
<td style="text-align:center"><strong>Yes</strong></td>
<td style="text-align:center">?</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Average</td>
<td style="text-align:center">Odd</td>
</tr>
<tr>
<td style="text-align:center"><strong>No</strong></td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Pale</td>
<td style="text-align:center">Heavy</td>
</tr>
<tr>
<td style="text-align:center"><strong>No</strong></td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Average</td>
<td style="text-align:center">Heavy</td>
</tr>
<tr>
<td style="text-align:center"><strong>No</strong></td>
<td style="text-align:center">?</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Ruddy</td>
<td style="text-align:center">Odd</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-6/tq.jpg" alt="Test Quality"></p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-6/id.jpg" alt="Test 1"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Vampire</th>
<th style="text-align:center">Shadow</th>
<th style="text-align:center">Garlic</th>
<th style="text-align:center">Complexion</th>
<th style="text-align:center">Accent</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>No</strong></td>
<td style="text-align:center">?</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Pale</td>
<td style="text-align:center">None</td>
</tr>
<tr>
<td style="text-align:center"><del><strong>No</strong></del></td>
<td style="text-align:center"><del>Yes</del></td>
<td style="text-align:center"><del>Yes</del></td>
<td style="text-align:center"><del>Ruddy</del></td>
<td style="text-align:center"><del>None</del></td>
</tr>
<tr>
<td style="text-align:center"><strong>Yes</strong></td>
<td style="text-align:center">?</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Ruddy</td>
<td style="text-align:center">None</td>
</tr>
<tr>
<td style="text-align:center"><del><strong>Yes</strong></del></td>
<td style="text-align:center"><del>No</del></td>
<td style="text-align:center"><del>No</del></td>
<td style="text-align:center"><del>Average</del></td>
<td style="text-align:center"><del>Heavy</del></td>
</tr>
<tr>
<td style="text-align:center"><strong>Yes</strong></td>
<td style="text-align:center">?</td>
<td style="text-align:center">No</td>
<td style="text-align:center">Average</td>
<td style="text-align:center">Odd</td>
</tr>
<tr>
<td style="text-align:center"><del><strong>No</strong></del></td>
<td style="text-align:center"><del>Yes</del></td>
<td style="text-align:center"><del>No</del></td>
<td style="text-align:center"><del>Pale</del></td>
<td style="text-align:center"><del>Heavy</del></td>
</tr>
<tr>
<td style="text-align:center"><del><strong>No</strong></del></td>
<td style="text-align:center"><del>Yes</del></td>
<td style="text-align:center"><del>No</del></td>
<td style="text-align:center"><del>Average</del></td>
<td style="text-align:center"><del>Heavy</del></td>
</tr>
<tr>
<td style="text-align:center"><strong>No</strong></td>
<td style="text-align:center">?</td>
<td style="text-align:center">Yes</td>
<td style="text-align:center">Ruddy</td>
<td style="text-align:center">Odd</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-6/t2.jpg" alt="Test Quality"></p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-6/idt.jpg" alt="Test 2"></p>
<p><br></p>
<h5 id="LARGE-DATASET"><a href="#LARGE-DATASET" class="headerlink" title="LARGE DATASET"></a>LARGE DATASET</h5><h6 id="Measuring-DISORDER-of-tests"><a href="#Measuring-DISORDER-of-tests" class="headerlink" title="Measuring DISORDER of tests"></a><span style="font-size:110%;">Measuring DISORDER of tests</span></h6><script type="math/tex; mode=display">
D\left(set\right) =-\dfrac {P}{T}\log _{2}\dfrac {P}{T}-\dfrac {N}{T}\log _{2}\dfrac {N}{T}</script><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-6/plot.png" alt="disorder"></p>
<h6 id="Measuring-the-OVERALL-QUALITY"><a href="#Measuring-the-OVERALL-QUALITY" class="headerlink" title="Measuring the OVERALL QUALITY"></a><span style="font-size:110%;">Measuring the OVERALL QUALITY</span></h6><script type="math/tex; mode=display">
Q\left(test\right) =\sum _{^{sets\ produced}}D\left(set\right)\times\mathrm{\dfrac {Number\ of\ Samples\ in\ Set}{Number\ of\ Samples\ Handeled\ by\ Test}}</script><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-6/q.jpg" alt="Test Quality"></p>
<h6 id="NUMERICAL-data"><a href="#NUMERICAL-data" class="headerlink" title="NUMERICAL data"></a><span style="font-size:110%;">NUMERICAL data</span></h6><p>NUMERICAL —&gt; <strong><em>threshold</em></strong> —&gt; <em>binary test</em></p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-6/t.jpg" alt="numerical"></p>
<p>NUMBER OF TESTS = NUMBER OF SAMPLES - 1</p>
<p><br></p>
<h4 id="NN-与-ID-Tree-的比较"><a href="#NN-与-ID-Tree-的比较" class="headerlink" title="NN 与 ID Tree 的比较"></a>NN 与 ID Tree 的比较</h4><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-6/c.jpg" alt></p>
<p><br></p>
<h4 id="Convert-tree-into-a-set-of-rules"><a href="#Convert-tree-into-a-set-of-rules" class="headerlink" title="Convert tree into a set of rules"></a>Convert tree into a set of rules</h4><p>Go down each branch to the leaf.</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-6/idt.jpg" alt="Test 2"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">IF SHADOW &#x3D; ? &amp; GARLIC &#x3D; Y THEN -</span><br><span class="line">IF SHADOW &#x3D; ? &amp; GARLIC &#x3D; N THEN +</span><br><span class="line">IF SHADOW &#x3D; Y THEN -</span><br><span class="line">IF SHADOW &#x3D; N THEN +</span><br></pre></td></tr></table></figure>
<p>然后对规则优化.，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">IF SHADOW &#x3D; ?   &lt;-- no need to take both tests</span><br><span class="line">   GARLIC &#x3D; Y</span><br><span class="line">THEN -</span><br><span class="line"></span><br><span class="line">IF GARLIC &#x3D; Y THEN -</span><br></pre></td></tr></table></figure>
<p><br></p>
<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p><strong>The Precedent Principle</strong><br>If something is similar in some respects, it is likely to be similar in other respects.</p>
<p><strong>Occam’s Razor</strong><br>The simplest explanation is often the best explanation.</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>
<p><br></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>Artificial Intelligence (7) · Learning · II</title>
    <url>/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-7/</url>
    <content><![CDATA[<h3 id="课程信息"><a href="#课程信息" class="headerlink" title="课程信息"></a>课程信息</h3><p>MIT OPEN COURSE WARE<br>6.034, Fall 2010, <strong>Artificial Intelligence,</strong> <em>Patrick H. Winston</em><br><a href="https://www.youtube.com/watch?v=TjZBTDzGeGg&amp;list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi">Youtube</a> / <a href="https://www.bilibili.com/video/av75097245">Bilibili</a></p>
<p><br></p>
<p>本节内容：神经网络</p>
<a id="more"></a>
<p><br></p>
<h3 id="第十二讲-神经网络、反向传播算法"><a href="#第十二讲-神经网络、反向传播算法" class="headerlink" title="第十二讲 神经网络、反向传播算法"></a>第十二讲 神经网络、反向传播算法</h3><h4 id="NEURAL-NETS"><a href="#NEURAL-NETS" class="headerlink" title="NEURAL NETS"></a>NEURAL NETS</h4><h5 id="NAIVE-NEURO-BIOLOGY"><a href="#NAIVE-NEURO-BIOLOGY" class="headerlink" title="NAIVE NEURO-BIOLOGY"></a>NAIVE NEURO-BIOLOGY</h5><ol>
<li>Synaptic Weights</li>
<li>Cumulative Effect</li>
<li>All or None</li>
<li>…</li>
</ol>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-7/nueron.jpg" alt="BIOLOGY"></p>
<h5 id="NEURON-MODEL"><a href="#NEURON-MODEL" class="headerlink" title="NEURON MODEL"></a>NEURON MODEL</h5><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-7/model.jpg" alt="MODEL"></p>
<p><strong><em>fix1:</em></strong> <em>RENDER TRIGGER AS WEIGHT</em></p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-7/m1.jpg" alt="MODEL"></p>
<p><strong><em>fix2:</em></strong> <em>USE SIGMOID FUNCTION</em></p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-7/m2.jpg" alt="MODEL"></p>
<h5 id="NEURAL-NETS-MODEL"><a href="#NEURAL-NETS-MODEL" class="headerlink" title="NEURAL NETS MODEL"></a>NEURAL NETS MODEL</h5><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-7/nn.jpg" alt="MODEL"></p>
<ul>
<li><p><strong>output vector</strong> $ \overline {z}=f\left( \overline {x},\overline {\omega }\right)  $</p>
</li>
<li><p><strong>desired output</strong> $ \overline {d}=g\left( \overline {x}\right)  $</p>
</li>
<li><p><strong>performance function</strong> $ P\left( \overline {d},\overline {z}\right) =- \dfrac {1}{2}\left| \overline {d}-\overline {z}\right| ^{2}$ <span style="color: gray">← trigger T? → <strong><em>fix1</em></strong></span><br><em>MAXIMIZE</em> ← gradient ascent <span style="color: gray">← <strong><em>smooth, continuous?</em></strong> → STEP FUNCTION → <strong><em>fix2</em></strong></span></p>
<p>$ \beta _{sigmoid} =\dfrac {1}{1 + e ^{- \alpha }} $, $ \Delta \omega =\tau _{rate} \left( \dfrac {\partial P}{\partial \omega_{1}}i+\dfrac {\partial P}{\partial \omega_{2}}j\right) $</p>
</li>
</ul>
<p><br></p>
<h4 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h4><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-7/eg.jpg" alt="example"></p>
<p>$ \dfrac {\partial p}{\partial \omega _{2}}=\dfrac {\partial p}{\partial z}\dfrac {\partial z}{\partial \omega _{2}}=\dfrac {\partial p}{\partial z}\dfrac {\partial z}{\partial p_{2}}\dfrac {\partial p_{2}}{\partial \omega_{2}}=\left( d-z\right) \cdot \dfrac {\partial z}{\partial p_{2}}\cdot y $</p>
<p>$ \dfrac {\partial p}{\partial \omega _{1}}=\dfrac {\partial p}{\partial z}\dfrac {\partial z}{\partial p_{2}}\dfrac {\partial p_{2}}{\partial y}\dfrac {\partial y}{\partial p_{1}}\dfrac {\partial p_{1}}{\partial \omega_{1}}=\left( d-z\right) \cdot \dfrac {\partial z}{\partial p_{2}} \cdot\omega_{2}\cdot \dfrac {\partial y}{\partial p_{1}} \cdot x $</p>
<p>$ \dfrac {d\beta }{d\alpha }=\dfrac {d}{d\alpha }\left( \dfrac {1}{1+e^{-\alpha }}\right) =\dfrac {e^{-\alpha }}{\left( 1+e^{-\alpha }\right) ^{2}} =\dfrac {1}{\left( 1+e^{-\alpha }\right) }\cdot\left( 1-\dfrac {1}{1+e^{-\alpha }}\right) =\beta\left( 1-\beta\right) $</p>
<p>$ \dfrac {\partial p}{\partial \omega _{2}}=\left( d-z \right) \cdot \dfrac {\partial z}{\partial p_{2}} \cdot y= \left( d-z \right) \cdot z \left( 1-z \right) \cdot y $</p>
<p>$ \dfrac {\partial p}{\partial \omega _{1}}=\left( d-z\right) \cdot \dfrac {\partial z}{\partial p_{2}} \cdot\omega_{2}\cdot \dfrac {\partial y}{\partial p_{1}} \cdot x=\left( d-z\right) \cdot z\left( 1-z\right) \cdot\omega_{2}\cdot y\left( 1-y\right) \cdot x $</p>
<p><br></p>
<h5 id="BACK-PROPAGATION-ALGORITHM"><a href="#BACK-PROPAGATION-ALGORITHM" class="headerlink" title="BACK-PROPAGATION ALGORITHM"></a>BACK-PROPAGATION ALGORITHM</h5><p>先计算最近的 ω，下一个 ω 只依赖于当前计算的值和前一个 ω<br>也就是说，在一长串节点中，各点的计算量是相同的（总量是线性的）</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-7/bp.jpg" alt="BACK-PROPAGATION ALGORITHM"></p>
<h5 id="PROBLEMS"><a href="#PROBLEMS" class="headerlink" title="PROBLEMS"></a>PROBLEMS</h5><ul>
<li>Encoding</li>
<li>Overfitting <sup><em>(steps)</em></sup></li>
<li>Overshooting <sup><em>(rate constant)</em></sup></li>
</ul>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>Artificial Intelligence (8) · Learning · III</title>
    <url>/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-8/</url>
    <content><![CDATA[<h3 id="课程信息"><a href="#课程信息" class="headerlink" title="课程信息"></a>课程信息</h3><p>MIT OPEN COURSE WARE<br>6.034, Fall 2010, <strong>Artificial Intelligence,</strong> <em>Patrick H. Winston</em><br><a href="https://www.youtube.com/watch?v=TjZBTDzGeGg&amp;list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi">Youtube</a> / <a href="https://www.bilibili.com/video/av75097245">Bilibili</a></p>
<p><br></p>
<p>本节内容：遗传算法、模拟退火、稀疏空间</p>
<a id="more"></a>
<p><br></p>
<h3 id="第十三讲-遗传算法"><a href="#第十三讲-遗传算法" class="headerlink" title="第十三讲 遗传算法"></a>第十三讲 遗传算法</h3><h4 id="GENETIC-ALGORITHMS"><a href="#GENETIC-ALGORITHMS" class="headerlink" title="GENETIC ALGORITHMS"></a>GENETIC ALGORITHMS</h4><h5 id="NAIVE-EVOLUTION"><a href="#NAIVE-EVOLUTION" class="headerlink" title="NAIVE EVOLUTION"></a>NAIVE EVOLUTION</h5><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-8/MitosisMeiosis.jpg" alt="Mitosis vs Meiosis"></p>
<p><br></p>
<h5 id="MIMICKING"><a href="#MIMICKING" class="headerlink" title="MIMICKING"></a>MIMICKING</h5><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-8/mimic.jpg" alt="mimic"></p>
<ul>
<li><p><strong>存活概率的计算机制</strong></p>
<ol>
<li>$ P_{i}=\dfrac {f_{i}}{\sum _{j}f_{j}} $</li>
<li><strong>RANK SPACE</strong><br>P<sub>1</sub> = P<sub>c</sub><br>P<sub>2</sub> = (1 - P<sub>c</sub>) P<sub>c</sub><br>P<sub>3</sub> = (1 - P<sub>c</sub>)<sup>2</sup> P<sub>c</sub><br>…<br>P<sub>n-1</sub> = (1 - P<sub>c</sub>)<sup>n-2</sup> P<sub>c</sub><br>P<sub>n</sub> = (1 - P<sub>c</sub>)<sup>n-1</sup></li>
<li>MEASURE <strong>DIVERSITY</strong><br><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-8/m3.jpg" alt="DIVERSITY"></li>
</ol>
</li>
<li><p><strong>模拟退火算法（Simulated Annealing）</strong></p>
</li>
</ul>
<p><br>ASK WHERE THE CREDIT <strong><em>LIES</em></strong></p>
<p><strong>Rich with Solutions</strong></p>
<p><br></p>
<h3 id="第十四讲-稀疏空间、音韵学"><a href="#第十四讲-稀疏空间、音韵学" class="headerlink" title="第十四讲 稀疏空间、音韵学"></a>第十四讲 稀疏空间、音韵学</h3><p>BASIC METHODS → NAIVE MIMICRY → FOCUS ON PROBLEM → FOCUS ON THEORY FIOS (for its own sake)</p>
<h4 id="Phonology"><a href="#Phonology" class="headerlink" title="Phonology"></a>Phonology</h4><p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-8/141.png" alt="phonology"></p>
<h5 id="Propagators"><a href="#Propagators" class="headerlink" title="Propagators"></a>Propagators</h5><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">(4/14)</th>
<th style="text-align:center">K</th>
<th style="text-align:center">A</th>
<th style="text-align:center">T</th>
<th style="text-align:center">S</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>SYLLABIC</strong></td>
<td style="text-align:center">–</td>
<td style="text-align:center">+</td>
<td style="text-align:center">+</td>
<td style="text-align:center">–</td>
</tr>
<tr>
<td style="text-align:center"><strong>VOICED</strong></td>
<td style="text-align:center">–</td>
<td style="text-align:center">+</td>
<td style="text-align:center">–</td>
<td style="text-align:center">–</td>
</tr>
<tr>
<td style="text-align:center"><strong>CONTINUANT</strong></td>
<td style="text-align:center">–</td>
<td style="text-align:center">+</td>
<td style="text-align:center">–</td>
<td style="text-align:center">+</td>
</tr>
<tr>
<td style="text-align:center"><strong>STRIDENT</strong></td>
<td style="text-align:center">–</td>
<td style="text-align:center">–</td>
<td style="text-align:center">–</td>
<td style="text-align:center"><strong>+</strong></td>
</tr>
</tbody>
</table>
</div>
<ol>
<li><strong>COLLECT + &amp; – EXAMPLES</strong></li>
<li><strong>PICK + SEED</strong></li>
<li><strong>GENERALIZE <sup>(+ → x, – → x) </sup></strong><br><strong>UNTIL COVER –</strong></li>
</ol>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">(4/14)</th>
<th style="text-align:center">K</th>
<th style="text-align:center">A</th>
<th style="text-align:center">T</th>
<th style="text-align:center">S</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>SYLLABIC</strong></td>
<td style="text-align:center">x</td>
<td style="text-align:center">x</td>
<td style="text-align:center">x</td>
<td style="text-align:center">–</td>
</tr>
<tr>
<td style="text-align:center"><strong>VOICED</strong></td>
<td style="text-align:center">x</td>
<td style="text-align:center">x</td>
<td style="text-align:center"><strong>–</strong></td>
<td style="text-align:center">–</td>
</tr>
<tr>
<td style="text-align:center"><strong>CONTINUANT</strong></td>
<td style="text-align:center">x</td>
<td style="text-align:center">x</td>
<td style="text-align:center">x</td>
<td style="text-align:center">+</td>
</tr>
<tr>
<td style="text-align:center"><strong>STRIDENT</strong></td>
<td style="text-align:center">x</td>
<td style="text-align:center">x</td>
<td style="text-align:center"><strong>–</strong></td>
<td style="text-align:center"><strong>+</strong></td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">(4/14)</th>
<th style="text-align:center">D</th>
<th style="text-align:center">O</th>
<th style="text-align:center">G</th>
<th style="text-align:center">Z</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>SYLLABIC</strong></td>
<td style="text-align:center">x</td>
<td style="text-align:center">x</td>
<td style="text-align:center">x</td>
<td style="text-align:center">–</td>
</tr>
<tr>
<td style="text-align:center"><strong>VOICED</strong></td>
<td style="text-align:center">x</td>
<td style="text-align:center">x</td>
<td style="text-align:center"><strong>+</strong></td>
<td style="text-align:center">+</td>
</tr>
<tr>
<td style="text-align:center"><strong>CONTINUANT</strong></td>
<td style="text-align:center">x</td>
<td style="text-align:center">x</td>
<td style="text-align:center">x</td>
<td style="text-align:center">+</td>
</tr>
<tr>
<td style="text-align:center"><strong>STRIDENT</strong></td>
<td style="text-align:center">x</td>
<td style="text-align:center">x</td>
<td style="text-align:center">x</td>
<td style="text-align:center"><strong>–</strong></td>
</tr>
</tbody>
</table>
</div>
<p><span style="color:gray">btw fyi 如果要借机学英语的话，strident <strong>+</strong> 对应的是 <strong>-es</strong>，如 peach -&gt; peaches</span></p>
<p><br></p>
<h4 id="SPARSE-SPACE"><a href="#SPARSE-SPACE" class="headerlink" title="SPARSE SPACE"></a>SPARSE SPACE</h4><p>在稀疏空间中很容易找到一个超平面分开两组例子</p>
<p><img src="/post/Open-Course/Artificial-Intelligence/Artificial-Intelligence-Patrick-Winston-8/142.jpg" alt="SPARSE SPACE"></p>
<p><br></p>
<h4 id="Marr’s-Catechism"><a href="#Marr’s-Catechism" class="headerlink" title="Marr’s Catechism"></a>Marr’s Catechism</h4><ol>
<li><strong>PROBLEM</strong></li>
<li><strong>REPRESENTATION</strong><ul>
<li>EXPLICIT</li>
<li>EXPOSE CONSTRAINT</li>
<li>LOCALNESS CRITERIA</li>
</ul>
</li>
<li><strong>APPROACH / METHOD</strong></li>
<li><strong>MECHANISM / ALGORITHM</strong></li>
<li><strong>EXPERIMENT</strong></li>
</ol>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (10) · Foundations of Convolutional Neural Networks</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-10/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course D<br><strong>Convolutional Neural Networks</strong> by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 1:</em></strong> <em>Foundations of Convolutional Neural Networks</em></p>
<ol>
<li>Understand the convolution operation</li>
<li>Understand the pooling operation</li>
<li>Remember the vocabulary used in convolutional neural network (padding, stride, filter, …)</li>
<li>Build a convolutional neural network for image multi-class classification</li>
</ol>
<a id="more"></a>
<h3 id="Convolutional-Neural-Networks"><a href="#Convolutional-Neural-Networks" class="headerlink" title="Convolutional Neural Networks"></a>Convolutional Neural Networks</h3><h4 id="Computer-Vision"><a href="#Computer-Vision" class="headerlink" title="Computer Vision"></a>Computer Vision</h4><p>large images → convolution operation</p>
<h4 id="Edge-Detection-Example"><a href="#Edge-Detection-Example" class="headerlink" title="Edge Detection Example"></a>Edge Detection Example</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-10/1.png" alt="edges"></p>
<h5 id="Edges-Detection"><a href="#Edges-Detection" class="headerlink" title="Edges Detection"></a>Edges Detection</h5><p><strong><em>Pooling:</em></strong> <strong>convolution (cross-correlation),</strong> <em>filter (kernel)</em></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-10/2.gif" alt="edges"></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-10/3.png" alt="v"></p>
<h4 id="More-Edge-Detection"><a href="#More-Edge-Detection" class="headerlink" title="More Edge Detection"></a>More Edge Detection</h4><p>$\begin{array}{cc|cc} \textsf{Vertical Edges Detection} &amp; &amp; &amp; \textsf{Horizontal Edges Detection}_\strut \\ \left[ {\begin{matrix}1&amp;0&amp;-1\\1&amp;0&amp;-1\\1&amp;0&amp;-1 \end{matrix}} \right] &amp; &amp; &amp; \left[ {\begin{matrix}1&amp;1&amp;1\\0&amp;0&amp;0\\ -1&amp;-1&amp;-1 \end{matrix}} \right] \\ \textsf{Sobel Filter} ^{\strut} \\ \left[ {\begin{matrix}1&amp;0&amp;-1\\2&amp;0&amp;-2\\1&amp;0&amp;-1 \end{matrix}} \right] &amp; &amp; &amp; \left[ {\begin{matrix}1&amp;2&amp;1\\0&amp;0&amp;0\\ -1&amp;-2&amp;-1 \end{matrix}} \right] \\ \textsf{Scharr Filter} ^{\strut} \\ \left[ {\begin{matrix}3&amp;0&amp;-3\\10&amp;0&amp;-10\\3&amp;0&amp;-3 \end{matrix}} \right] &amp; &amp; &amp; \left[ {\begin{matrix}3&amp;10&amp;3\\0&amp;0&amp;0\\ -3&amp;-10&amp;-3 \end{matrix}} \right] \end{array}$</p>
<p><strong>Learn as Parameters</strong></p>
<p>$\ast \left[ {\begin{matrix}w_1&amp;w_2&amp;w_3 \\ w_4&amp;w_5&amp;w_6 \\ w_7&amp;w_8&amp;w_9 \end{matrix}} \right]$</p>
<h4 id="Padding"><a href="#Padding" class="headerlink" title="Padding"></a>Padding</h4><ul>
<li>shrink output (n-f+1 × n-f+1) → (n+2p-f+1 × n+2p-f+1)</li>
<li>throw away info from edges</li>
</ul>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-10/4.png" alt="p"></p>
<p><strong>Valid and Same convolution</strong>  </p>
<ul>
<li><strong><em>valid:</em></strong> no padding &emsp; $n \ast f \rightarrow n-f+1$</li>
<li><strong><em>same:</em></strong> pad so that output size is the same as the input size &emsp; $p=(f-1)/2$ &emsp; <em>(f is usually odd)</em></li>
</ul>
<h4 id="Strided-Convolutions"><a href="#Strided-Convolutions" class="headerlink" title="Strided Convolutions"></a>Strided Convolutions</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-10/5.png" alt="s"></p>
<p>$n \ast f \xrightarrow{ {\rm padding}=p,\ {\rm stride}=s } \left\lfloor \dfrac{n+2p-f}{s}+1 \right\rfloor$</p>
<h4 id="Convolutions-Over-Volume"><a href="#Convolutions-Over-Volume" class="headerlink" title="Convolutions Over Volume"></a>Convolutions Over Volume</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-10/6.png" alt="v"></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-10/7.png" alt="m"></p>
<p>$\Rightarrow \ n \times n \times n_{channel} \quad\ast\quad f \times f \times n_{channel} \quad=\quad n\!\!-\!\!f\!\!+\!\!1 \times n\!\!-\!\!f\!\!+\!\!1 \times n_{filter}$</p>
<h4 id="One-Layer-of-a-Convolutional-Network"><a href="#One-Layer-of-a-Convolutional-Network" class="headerlink" title="One Layer of a Convolutional Network"></a>One Layer of a Convolutional Network</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-10/8.png" alt="l"></p>
<ul>
<li><strong><em>filter size:</em></strong> f<sup>[l]</sup></li>
<li><strong><em>padding:</em></strong> p<sup>[l]</sup></li>
<li><strong><em>stride:</em></strong> s<sup>[l]</sup></li>
<li><p><strong><em>number of filters:</em></strong> n<sub>c</sub><sup>[l]</sup></p>
</li>
<li><p><strong><em>filter:</em></strong> f<sup>[l]</sup> × f<sup>[l]</sup> × n<sub>c</sub><sup>[l-1]</sup></p>
</li>
<li><strong><em>weights:</em></strong> f<sup>[l]</sup> × f<sup>[l]</sup> × n<sub>c</sub><sup>[l-1]</sup> × n<sub>c</sub><sup>[l]</sup></li>
<li><strong><em>bias:</em></strong> 1 × 1× 1× n<sub>c</sub><sup>[l]</sup></li>
<li><strong><em>activations:</em></strong> n<sub>H</sub><sup>[l]</sup> × n<sub>W</sub><sup>[l]</sup> × n<sub>c</sub><sup>[l]</sup></li>
<li><strong><em>input:</em></strong> n<sub>H</sub><sup>[l-1]</sup> × n<sub>W</sub><sup>[l-1]</sup> × n<sub>c</sub><sup>[l-1]</sup></li>
<li><strong><em>output:</em></strong> <em>(m ×)</em> n<sub>H</sub><sup>[l]</sup> × n<sub>W</sub><sup>[l]</sup> × n<sub>c</sub><sup>[l]</sup><br>$\begin{aligned} n_H^{\left[l\right]} &amp;= \left\lfloor \dfrac{n_H^{\left[l-1\right]} +2p^{\left[l\right]} -f^{\left[l\right]}} {s^{\left[l\right]}} +1 \right\rfloor ^{\strut} \\ n_W^{\left[l\right]} &amp;= \left\lfloor \dfrac{n_W^{\left[l-1\right]} +2p^{\left[l\right]} -f^{\left[l\right]}} {s^{\left[l\right]}} +1 \right\rfloor ^{\strut} \end{aligned}$</li>
</ul>
<h4 id="Simple-Convolutional-Network-Example"><a href="#Simple-Convolutional-Network-Example" class="headerlink" title="Simple Convolutional Network Example"></a>Simple Convolutional Network Example</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-10/9.png" alt="ConvNet"></p>
<h5 id="Types-of-Layers-in-a-ConvNet"><a href="#Types-of-Layers-in-a-ConvNet" class="headerlink" title="Types of Layers in a ConvNet"></a>Types of Layers in a ConvNet</h5><ul>
<li><strong>CONV:</strong> convolution</li>
<li><strong>POOL:</strong> pooling</li>
<li><strong>FC:</strong> fully connected</li>
</ul>
<h4 id="Pooling-Layers"><a href="#Pooling-Layers" class="headerlink" title="Pooling Layers"></a>Pooling Layers</h4><h5 id="Max-Pooling"><a href="#Max-Pooling" class="headerlink" title="Max Pooling"></a>Max Pooling</h5><blockquote>
<p><em>feature detected?</em></p>
</blockquote>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-10/10.png" alt="mp"></p>
<p>perform the computation on each of the channels independently</p>
<h5 id="Average-Pooling"><a href="#Average-Pooling" class="headerlink" title="Average Pooling"></a>Average Pooling</h5><p>use average pooling to collapse representation</p>
<h5 id="Hyperparameters"><a href="#Hyperparameters" class="headerlink" title="Hyperparameters"></a>Hyperparameters</h5><ul>
<li><strong><em>f:</em></strong> filter size</li>
<li><strong><em>s:</em></strong> stride</li>
<li><strong><em>max / average</em></strong></li>
<li><del><strong><em>p:</em></strong> padding</del></li>
</ul>
<p><strong>NO PARAMETERS TO LEARN</strong></p>
<h4 id="CNN-Example"><a href="#CNN-Example" class="headerlink" title="CNN Example"></a>CNN Example</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-10/11.png" alt="cnn"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">Activation Shape</th>
<th style="text-align:center">Activation Size</th>
<th style="text-align:center"># Parameters</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>INPUT</strong></td>
<td style="text-align:center">(32, 32, 3)</td>
<td style="text-align:center">3072</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center"><strong>CONV1</strong></td>
<td style="text-align:center">(28, 28, 8)</td>
<td style="text-align:center">3272</td>
<td style="text-align:center">608</td>
</tr>
<tr>
<td style="text-align:center"><strong>POOL1</strong></td>
<td style="text-align:center">(14, 14, 8)</td>
<td style="text-align:center">1568</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center"><strong>CONV2</strong></td>
<td style="text-align:center">(10, 10, 16)</td>
<td style="text-align:center">1600</td>
<td style="text-align:center">3216</td>
</tr>
<tr>
<td style="text-align:center"><strong>POOL2</strong></td>
<td style="text-align:center">(5, 5, 16)</td>
<td style="text-align:center">400</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center"><strong>FC3</strong></td>
<td style="text-align:center">(120, 1)</td>
<td style="text-align:center">120</td>
<td style="text-align:center">48120</td>
</tr>
<tr>
<td style="text-align:center"><strong>FC4</strong></td>
<td style="text-align:center">(84, 1)</td>
<td style="text-align:center">84</td>
<td style="text-align:center">10164</td>
</tr>
<tr>
<td style="text-align:center"><strong>SOFTMAX</strong></td>
<td style="text-align:center">(10, 1)</td>
<td style="text-align:center">10</td>
<td style="text-align:center">850</td>
</tr>
</tbody>
</table>
</div>
<h4 id="Why-Convolutions"><a href="#Why-Convolutions" class="headerlink" title="Why Convolutions"></a>Why Convolutions</h4><ul>
<li><strong><em>Parameter Sharing:</em></strong> a feature detector (such as edge detector) that is useful in one part of the image is probably useful in another part of the image</li>
<li><strong><em>Sparsity of Connections:</em></strong> in each layer, each output value depends on only a small number of inputs</li>
<li><strong><em>Translation Invariance:</em></strong> applying same filter to better capture the property of translation invariance</li>
</ul>
<p>${\rm Cost} \ \ \begin{aligned} J = \dfrac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{\left(i\right)},\,y^{\left(i\right)}\right) \end{aligned}$<br>use gradient descent (or momentum, …) to optimize parameters to reduce J</p>
<h3 id="Programming-Assignments"><a href="#Programming-Assignments" class="headerlink" title="Programming Assignments"></a>Programming Assignments</h3><h4 id="Convolutional-Model-step-by-step"><a href="#Convolutional-Model-step-by-step" class="headerlink" title="Convolutional Model: step by step"></a>Convolutional Model: step by step</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-10/12.png" alt="1"></p>
<h4 id="Convolutional-Model-application"><a href="#Convolutional-Model-application" class="headerlink" title="Convolutional Model: application"></a>Convolutional Model: application</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-10/13.png" alt="2"></p>
<p><a href="https://github.com/bugstop/coursera-deep-learning-solutions" target="_blank">Solutions Manual</a></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (1) · Introduction</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-1/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course A<br><strong>Neural Networks and Deep Learning</strong> by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 1:</em></strong> <em>Introduction to Deep Learning</em></p>
<ol>
<li>Understand the major trends driving the rise of deep learning.</li>
<li>Be able to explain how deep learning is applied to supervised learning.</li>
<li>Understand what are the major categories of models (such as CNNs and RNNs), and when they should be applied.</li>
<li>Be able to recognize the basics of when deep learning will (or will not) work well.</li>
</ol>
<a id="more"></a>
<h3 id="Introduction-to-Deep-Learning"><a href="#Introduction-to-Deep-Learning" class="headerlink" title="Introduction to Deep Learning"></a>Introduction to Deep Learning</h3><h4 id="What-is-a-neural-network"><a href="#What-is-a-neural-network" class="headerlink" title="What is a neural network?"></a>What is a neural network?</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-1/house-price.png" alt="House Price"></p>
<p><strong>ReLU,</strong> Rectified Linear Unit Function: $\max\left(0,y\right)$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-1/1.png" alt="What is a neural network?"></p>
<p><strong>Notice</strong> that each of these hidden units in the neural network takes its inputs all four input features. <strong><em>(density connected)</em></strong></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-1/2.png" alt="What is a neural network?"></p>
<h4 id="Supervised-Learning-with-Neural-Networks"><a href="#Supervised-Learning-with-Neural-Networks" class="headerlink" title="Supervised Learning with Neural Networks"></a>Supervised Learning with Neural Networks</h4><ul>
<li><strong>standard neural network</strong></li>
<li><strong>convolution on neural networks, CNN:</strong> image applications</li>
<li><strong>recurrent neural network, RNN:</strong> sequence data</li>
<li><strong>custom / hybrid</strong></li>
</ul>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-1/nn.png" alt="Neural Networks"></p>
<ul>
<li><strong>Structured Data:</strong> features have well defined meanings</li>
<li><strong>Unstructured Data:</strong> audio / image / text</li>
</ul>
<h4 id="Why-is-Deep-Learning-taking-off"><a href="#Why-is-Deep-Learning-taking-off" class="headerlink" title="Why is Deep Learning taking off?"></a>Why is Deep Learning taking off?</h4><ul>
<li><strong>Data</strong><br><strong><em>m:</em></strong> size of training sets / number of training examples &emsp; <em>(on small training sets: feature engineering)</em><br><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-1/scale.png" alt="Scale"></li>
<li><strong>Computation</strong></li>
<li><strong>Algorithms</strong><br><strong><em>activation function:</em></strong> Sigmoid → ReLU<br><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-1/relu.png" alt="Activation Function"></li>
</ul>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (11) · Deep Convolutional Models</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course D<br><strong>Convolutional Neural Networks</strong> by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 2:</em></strong> <em>Deep Convolutional Models: case studies</em></p>
<ol>
<li>Understand multiple foundational papers of convolutional neural networks</li>
<li>Analyze the dimensionality reduction of a volume in a very deep network</li>
<li>Understand and Implement a Residual network</li>
<li>Build a deep neural network using Keras</li>
<li>Implement a skip-connection in your network</li>
<li>Clone a repository from GitHub and use transfer learning</li>
</ol>
<a id="more"></a>
<h3 id="Case-Studies"><a href="#Case-Studies" class="headerlink" title="Case Studies"></a>Case Studies</h3><h4 id="Classic-Networks"><a href="#Classic-Networks" class="headerlink" title="Classic Networks"></a>Classic Networks</h4><h5 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet - 5"></a>LeNet - 5</h5><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/1.png" alt></p>
<h5 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h5><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/2.png" alt></p>
<h5 id="VGG-16"><a href="#VGG-16" class="headerlink" title="VGG - 16"></a>VGG - 16</h5><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/3.png" alt></p>
<h4 id="Residual-Networks"><a href="#Residual-Networks" class="headerlink" title="Residual Networks"></a>Residual Networks</h4><h5 id="Residual-Block"><a href="#Residual-Block" class="headerlink" title="Residual Block"></a>Residual Block</h5><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/4.png" alt></p>
<p>$\begin{aligned} z^{\left[l+1\right]} &amp;= W^{\left[l+1\right]}a^{\left[l\right]} + b^{\left[l+1\right]} \\ a^{\left[l+1\right]} &amp;= g\left( z^{\left[l+1\right]} \right) \\ z^{\left[l+2\right]} &amp;= W^{\left[l+2\right]}a^{\left[l+1\right]} + b^{\left[l+2\right]} \\ a^{\left[l+2\right]} &amp;= g\left( z^{\left[l+2\right]} \right) \end{aligned}$</p>
<p>$\begin{aligned} \xrightarrow[\rm main\ path]{ \Large{ a^{\left[l\right]} } { {\xrightarrow{ \  {\rm short\ cut} \ / \ {\rm skip\ connection} \ } } \atop {\large {\rightarrow{\rm Linear} \rightarrow {\rm ReLU} \rightarrow a^{\left[l+1\right]} \rightarrow {\rm Linear} \rightarrow}} } {\rm ReLU} \rightarrow a^{\left[l+2\right]}} \\ a^{\left[l+2\right]} = g\left( z^{\left[l+2\right]} + \underline{ a^{\left[l\right]} _{}} \right) ^{\strut} \end{aligned}$</p>
<h5 id="Residual-Networks-1"><a href="#Residual-Networks-1" class="headerlink" title="Residual Networks"></a>Residual Networks</h5><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/5.png" alt></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/6.png" alt></p>
<h4 id="Why-ResNets-Work"><a href="#Why-ResNets-Work" class="headerlink" title="Why ResNets Work"></a>Why ResNets Work</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/7.png" alt></p>
<p><em>identity function is easy for residual block to learn</em></p>
<h4 id="Networks-in-Networks-and-1×1-Convolutions"><a href="#Networks-in-Networks-and-1×1-Convolutions" class="headerlink" title="Networks in Networks and 1×1 Convolutions"></a>Networks in Networks and 1×1 Convolutions</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/8.png" alt></p>
<h4 id="Inception-Network-Motivation"><a href="#Inception-Network-Motivation" class="headerlink" title="Inception Network Motivation"></a>Inception Network Motivation</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/9.png" alt></p>
<h5 id="Computation-Cost"><a href="#Computation-Cost" class="headerlink" title="Computation Cost"></a>Computation Cost</h5><p><strong><em>bottleneck layer</em></strong></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/10.png" alt></p>
<h4 id="Inception-Network"><a href="#Inception-Network" class="headerlink" title="Inception Network"></a>Inception Network</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/11.png" alt></p>
<h5 id="googLeNet"><a href="#googLeNet" class="headerlink" title="googLeNet"></a>googLeNet</h5><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/12.png" alt></p>
<h4 id="Practical-Advices-for-Using-ConvNets"><a href="#Practical-Advices-for-Using-ConvNets" class="headerlink" title="Practical Advices for Using ConvNets"></a>Practical Advices for Using ConvNets</h4><h4 id="Using-Open-Source-Implementation"><a href="#Using-Open-Source-Implementation" class="headerlink" title="Using Open-Source Implementation"></a>Using Open-Source Implementation</h4><p>GitHub → Transfer Learning</p>
<h4 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h4><ul>
<li>download <strong>code</strong> and <strong>weight</strong> as initialization</li>
<li>train <strong>new</strong> softmax layer, <strong>freeze</strong> (all) other layers</li>
<li><strong>pre-compute</strong> activation for all the examples in training sets and <strong>save</strong> them to disk</li>
</ul>
<h4 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h4><ul>
<li><strong>Mirroring</strong></li>
<li><strong>Random Cropping</strong></li>
<li>Rotation</li>
<li>Shearing</li>
<li>Local Warping</li>
<li><strong>Color Shifting</strong><ul>
<li>PCA color argumentation</li>
</ul>
</li>
</ul>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/13.png" alt></p>
<h4 id="State-of-Computer-Vision"><a href="#State-of-Computer-Vision" class="headerlink" title="State of Computer Vision"></a>State of Computer Vision</h4><ul>
<li>labeled data</li>
<li>hand-engineering features / network architecture / other components</li>
</ul>
<p>$\begin{aligned} {Little\ Data \atop {\small\textsf{more hand-engineering} \atop hack}} \xrightarrow[\qquad \uparrow\ {\rm Object\ Detection} \qquad  \qquad \uparrow\ {\rm Speech\ Recognition} \qquad]{\qquad \downarrow\ {\rm Image\ Recognition}} {Lots\ of\ Data \atop {\small\textsf{less hand-engineering} \atop simpler\ algo}}  \end{aligned}$</p>
<p><strong>on benchmarks</strong>  </p>
<ul>
<li><strong><em>assembling:</em></strong> train several networks independently and average their <em>outputs</em></li>
<li><strong><em>multi-crop:</em></strong> run classifier on multiple versions of <em>test</em> images and average results</li>
</ul>
<p><strong>use open source code</strong>  </p>
<ul>
<li>use architecture of networks published in the literature</li>
<li>use open source implementations if possible</li>
<li>use pretrained models and fine-tune on your dataset</li>
</ul>
<h3 id="Programming-Assignments"><a href="#Programming-Assignments" class="headerlink" title="Programming Assignments"></a>Programming Assignments</h3><h4 id="Keras-Tutorial"><a href="#Keras-Tutorial" class="headerlink" title="Keras Tutorial"></a>Keras Tutorial</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/14.png" alt="1"></p>
<h4 id="Residual-Networks-2"><a href="#Residual-Networks-2" class="headerlink" title="Residual Networks"></a>Residual Networks</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-11/15.png" alt="1"></p>
<p><a href="https://github.com/bugstop/coursera-deep-learning-solutions" target="_blank">Solutions Manual</a></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (12) · Object Detection</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-12/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course D<br><strong>Convolutional Neural Networks</strong> by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 3:</em></strong> <em>Object Detection</em></p>
<ol>
<li>Understand the challenges of Object Localization, Object Detection and Landmark Finding</li>
<li>Understand and implement non-max suppression</li>
<li>Understand and implement intersection over union</li>
<li>Understand how we label a dataset for an object detection application</li>
<li>Remember the vocabulary of object detection (landmark, anchor, bounding box, grid, …)</li>
</ol>
<a id="more"></a>
<h3 id="Detection-Algorithms"><a href="#Detection-Algorithms" class="headerlink" title="Detection Algorithms"></a>Detection Algorithms</h3><h4 id="Object-Localization"><a href="#Object-Localization" class="headerlink" title="Object Localization"></a>Object Localization</h4><p>image classification → classification with localization → detection</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-12/1.png" alt></p>
<ul>
<li>is there any object?</li>
<li>what is the size?</li>
<li>what is the class?</li>
</ul>
<p>$y = \left[\begin{matrix} p_c \\ b_x \\ b_y \\ b_h \\ b_w \\ c_1 \\ c_2 \\ c_3 \end{matrix}\right] \qquad y_{\rm car} = \left[\begin{matrix} 1 \\ 0.5 \\ 0.7 \\ 0.3 \\ 0.4 \\ 0 \\ 1 \\ 0 \end{matrix}\right] \qquad y_{\rm no_obj} = \left[\begin{matrix} 0 \\ ? \\ ? \\ ? \\ ? \\ ? \\ ? \\ ? \end{matrix}\right]$</p>
<p>$L= \begin{cases} \left(\hat{y}_1-y_1\right)^2 + \left(\hat{y}_2-y_2\right)^2 + \dots + \left(\hat{y}_8-y_8\right)^2 \quad &amp;{\rm if}\ \ y_1=1 \\ \left(\hat{y}_1-y_1\right)^2 &amp;{\rm if}\ \ y_1=0 \end{cases}$</p>
<h4 id="Landmark-Detection"><a href="#Landmark-Detection" class="headerlink" title="Landmark Detection"></a>Landmark Detection</h4><p>$y = \left[\begin{matrix} p_c \\ l_{1_x} \\ l_{1_y} \\ l_{2_x} \\ l_{2_y} \\ \vdots \end{matrix}\right]$</p>
<h4 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h4><h5 id="Sliding-Window-Detection"><a href="#Sliding-Window-Detection" class="headerlink" title="Sliding Window Detection"></a>Sliding Window Detection</h5><p><strong><em>computational cost</em></strong></p>
<h4 id="Convolutional-Implementation-of-Sliding-Windows"><a href="#Convolutional-Implementation-of-Sliding-Windows" class="headerlink" title="Convolutional Implementation of Sliding Windows"></a>Convolutional Implementation of Sliding Windows</h4><h4 id="Turning-FC-Layer-into-CONV-Layers"><a href="#Turning-FC-Layer-into-CONV-Layers" class="headerlink" title="Turning FC Layer into CONV Layers"></a>Turning FC Layer into CONV Layers</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-12/2.png" alt></p>
<h5 id="Convolution-Implementation-of-Sliding-Windows"><a href="#Convolution-Implementation-of-Sliding-Windows" class="headerlink" title="Convolution Implementation of Sliding Windows"></a>Convolution Implementation of Sliding Windows</h5><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-12/3.png" alt></p>
<h4 id="Bounding-Box-Predictions"><a href="#Bounding-Box-Predictions" class="headerlink" title="Bounding Box Predictions"></a>Bounding Box Predictions</h4><h5 id="YOLO-Algorithm"><a href="#YOLO-Algorithm" class="headerlink" title="YOLO Algorithm"></a>YOLO Algorithm</h5><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-12/4.png" alt></p>
<p><em>convolutional</em></p>
<p>$b_x,\, b_y,\, b_h,\, b_w$ are specified relative to the grid cell</p>
<h4 id="Intersection-over-Union"><a href="#Intersection-over-Union" class="headerlink" title="Intersection over Union"></a>Intersection over Union</h4><p>${\rm IoU}=\dfrac{\rm size \ of \ \cap}{\rm size \ of \ \cup} \geq 0.5 \Rightarrow {\rm correct} \ {\rm bounding} \ {\rm box}$</p>
<h4 id="Non-Max-Suppression"><a href="#Non-Max-Suppression" class="headerlink" title="Non-Max Suppression"></a>Non-Max Suppression</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-12/5.png" alt></p>
<ol>
<li>discard all boxes with p<sub>c</sub> &lt; 0.6</li>
<li>while there are any remaining boxes<ul>
<li>pick the box with the <strong>largest p<sub>c</sub></strong> output as a <strong>prediction</strong></li>
<li><strong>discard</strong> any remaining box with <strong>IoU ≥ 0.5</strong> with the box output in the previous step</li>
</ul>
</li>
<li><strong>independently</strong> carry out non-max suppression on each of the outputs classes</li>
</ol>
<h4 id="Anchor-Boxes"><a href="#Anchor-Boxes" class="headerlink" title="Anchor Boxes"></a>Anchor Boxes</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-12/6.png" alt></p>
<p><strong>Previously</strong><br>Each object in training image is assigned to grid cell that contains that object’s midpoint</p>
<p><strong>With two (or more) anchor boxes</strong><br>Each object in training image is assigned to grid cell that contains that object’s midpoint and anchor box for the grid cell with highest IoU</p>
<p>$y = \left[\begin{matrix} p_c \\ b_x \\ b_y \\ b_h \\ b_w \\ c_1 \\ c_2 \\ c_3 \\ p_c \\ b_x \\ b_y \\ b_h \\ b_w \\ c_1 \\ c_2 \\ c_3 \end{matrix}\right] \qquad y_{\rm car} = \left[\begin{matrix} 0 \\ ? \\ ? \\ ? \\ ? \\ ? \\ ? \\ ? \\ 1 \\ b_x \\ b_y \\ b_h \\ b_w \\ 0 \\ 1 \\ 0 \end{matrix}\right] \qquad y_{\rm man} = \left[\begin{matrix} 1 \\ b_x \\ b_y \\ b_h \\ b_w \\ 0 \\ 1 \\ 0 \\ 0 \\ ? \\ ? \\ ? \\ ? \\ ? \\ ? \\ ? \end{matrix}\right]  \qquad y_{\rm car\&amp;man} = \left[\begin{matrix} 1 \\ b_x \\ b_y \\ b_h \\ b_w \\ 0 \\ 1 \\ 0 \\ 1 \\ b_x \\ b_y \\ b_h \\ b_w \\ 0 \\ 1 \\ 0 \end{matrix}\right]$</p>
<h4 id="YOLO-Algorithm-1"><a href="#YOLO-Algorithm-1" class="headerlink" title="YOLO Algorithm"></a>YOLO Algorithm</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-12/7.png" alt></p>
<ol>
<li>for each grid cell, get two predicted bounding boxes</li>
<li>get rid of low probability predictions</li>
<li>for each class, use non-max suppression to generate final predictions</li>
</ol>
<h4 id="Region-Proposals-R-CNN"><a href="#Region-Proposals-R-CNN" class="headerlink" title="Region Proposals (R-CNN)"></a>Region Proposals (R-CNN)</h4><p><strong>segmentation algorithm</strong></p>
<h3 id="Programming-Assignments"><a href="#Programming-Assignments" class="headerlink" title="Programming Assignments"></a>Programming Assignments</h3><h4 id="Car-detection-with-YOLO"><a href="#Car-detection-with-YOLO" class="headerlink" title="Car detection with YOLO"></a>Car detection with YOLO</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-12/8.png" alt></p>
<p><a href="https://github.com/bugstop/coursera-deep-learning-solutions" target="_blank">Solutions Manual</a></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (13) · Special Applications</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-13/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course D<br><strong>Convolutional Neural Networks</strong> by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 4:</em></strong> <em>Special Applications: Face Recognition &amp; Neural Style Transfer</em></p>
<ol>
<li>Discover how CNNs can be applied to multiple fields, including art generation and face recognition. Implement your own algorithm to generate art and recognize faces!</li>
</ol>
<a id="more"></a>
<h3 id="Face-Recognition"><a href="#Face-Recognition" class="headerlink" title="Face Recognition"></a>Face Recognition</h3><h4 id="What-is-Face-Recognition"><a href="#What-is-Face-Recognition" class="headerlink" title="What is Face Recognition?"></a>What is Face Recognition?</h4><p><strong>Verification</strong> <em>( 1 - 1 )</em></p>
<ul>
<li>input image, name / ID</li>
<li>output whether the input image is that of the claimed person</li>
</ul>
<p><strong>Recognition</strong> <em>( 1 - k )</em></p>
<ul>
<li>a database of K persons</li>
<li>get an input image</li>
<li>output ID if the image is any of the K persons (or ‘not recognized’)</li>
</ul>
<h4 id="One-Shot-Learning"><a href="#One-Shot-Learning" class="headerlink" title="One Shot Learning"></a>One Shot Learning</h4><p>learning from one example to recognize the person again</p>
<p><strong>Learning a <em>similarity</em> function</strong></p>
<h4 id="Siamese-Network"><a href="#Siamese-Network" class="headerlink" title="Siamese Network"></a>Siamese Network</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-13/1.png" alt></p>
<p>$d\left( x^{\left( 1\right) },x^{\left( 2\right) }\right) =\left| f\left( x^{\left( 1\right) }\right) -f\left( x^{\left( 2\right) }\right) \right| ^{2}$</p>
<ul>
<li>Parameters of NN define an encoding $f\left( x^{\left( i\right) }\right)$</li>
<li>Learn parameters so that<ul>
<li>if $x^{\left( i\right) } , x^{\left( j\right)}$ are the same person, $\left| f\left( x^{\left( i\right) }\right) -f\left( x^{\left( j\right) }\right) \right| ^{2}$ is small</li>
<li>if $x^{\left( i\right) } , x^{\left( j\right)}$ are different persons, $\left| f\left( x^{\left( i\right) }\right) -f\left( x^{\left( j\right) }\right) \right| ^{2}$ is large</li>
</ul>
</li>
</ul>
<h4 id="Triplet-Loss"><a href="#Triplet-Loss" class="headerlink" title="Triplet Loss"></a>Triplet Loss</h4><p><strong><em>anchor, positive, negative</em></strong></p>
<p>$\begin{aligned} d\left(A,P\right) &amp;\leq d\left(A,N\right) \\ \left| f\left( A \right) -f\left( P \right) \right| ^{2} &amp;\leq \left| f\left( A \right) -f\left( N \right) \right| ^{2} \\ \Rightarrow \ \left| f\left( A \right) -f\left( P \right) \right| ^{2} &amp;\,- \left| f\left( A \right) -f\left( N \right) \right| ^{2} +\alpha \leq 0\end{aligned}$</p>
<p>$L\left(A,P,N\right) = \max\left( \left| f\left( A \right) -f\left( P \right) \right| ^{2} - \left| f\left( A \right) -f\left( N \right) \right| ^{2} +\alpha, \ 0 \right)$</p>
<p>$J=\sum_{i=1}^{m} L\left(A^{\left( i\right) },P^{\left( i\right) },N^{\left( i\right) }\right)$</p>
<h5 id="choosing-the-triplets-A-P-N"><a href="#choosing-the-triplets-A-P-N" class="headerlink" title="choosing the triplets A, P, N"></a>choosing the triplets A, P, N</h5><p>choose triplets <em>hard</em> to train on</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-13/2.png" alt></p>
<h4 id="Face-Verification-and-Binary-Classification"><a href="#Face-Verification-and-Binary-Classification" class="headerlink" title="Face Verification and Binary Classification"></a>Face Verification and Binary Classification</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-13/3.png" alt></p>
<p>$\begin{aligned} \widehat {y} &amp;=\sigma \left( \sum ^{n}_{k=1}w_{k}\left| f\left( x^{\left( i\right) }\right) _{k}-f\left( x^{\left( j\right) }\right) _{k}\right| +b\right) \\ \widehat {y} &amp;=\sigma \left( \sum ^{n}_{k=1}w_{k} \dfrac{\left( f\left( x^{\left( i\right) }\right) _{k}-f\left( x^{\left( j\right) }\right) _{k}\right)^2}{f\left( x^{\left( i\right) }\right) _{k}+f\left( x^{\left( j\right) }\right) _{k}} +b\right) \qquad \chi ^2\ {\rm similarity} \end{aligned}$</p>
<p><em>precompute database</em></p>
<h3 id="Neural-Style-Transfer"><a href="#Neural-Style-Transfer" class="headerlink" title="Neural Style Transfer"></a>Neural Style Transfer</h3><h4 id="What-is-Neural-Style-Transfer"><a href="#What-is-Neural-Style-Transfer" class="headerlink" title="What is Neural Style Transfer?"></a>What is Neural Style Transfer?</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-13/4.png" alt></p>
<h4 id="What-are-Deep-ConvNets-Learning"><a href="#What-are-Deep-ConvNets-Learning" class="headerlink" title="What are Deep ConvNets Learning?"></a>What are Deep ConvNets Learning?</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-13/5.png" alt></p>
<h4 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function"></a>Cost Function</h4><p>$J\left(G\right) = \alpha\cdot J_{\rm content} \left(C,G\right) + \beta\cdot J_{\rm style} \left(S,G\right)$</p>
<ol>
<li>initialize G randomly</li>
<li>use gradient descent to minimize J(G)</li>
</ol>
<h4 id="Content-Cost-Function"><a href="#Content-Cost-Function" class="headerlink" title="Content Cost Function"></a>Content Cost Function</h4><ul>
<li>use hidden layer l to compute content cost</li>
<li>use a pretrained ConvNet</li>
<li>let a<sup>[l](C)</sup> and a<sup>[l](G)</sup> be the activation of layer l on the images</li>
<li>if a<sup>[l](C)</sup> and a<sup>[l](G)</sup> are similar, both images have similar content</li>
</ul>
<p>$J_{\rm content} \left(C,G\right) = \dfrac{1}{2} \cdot \left| a^{\left[l\right]\left(C\right)}  - a^{\left[l\right]\left(G\right)} \right| ^2$</p>
<h4 id="Style-Cost-Function"><a href="#Style-Cost-Function" class="headerlink" title="Style Cost Function"></a>Style Cost Function</h4><ul>
<li>use hidden layer l to compute style cost</li>
<li>define style as correlation between activations across channels</li>
</ul>
<p>$\textsf{Let } a_{i,j,k}^{\left[l\right]} = \textsf{ activation at } \overbrace{ \left( i,j,k \right) }^{\rm H,W,C}.\ G^{\left[l\right]} \textsf{ is } n_c^{\left[l\right]} \times n_c^{\left[l\right]}.$</p>
<p>$\begin{aligned} G_{kk’}^{\left[l\right]\left(S\right)} &amp;= \sum_{i=1}^{n_H^{\left[l\right]}} \sum_{j=1}^{n_W^{\left[l\right]}} a_{i,j,k}^{\left[l\right]\left(S\right)} a_{i,j,k’}^{\left[l\right]\left(S\right)} \\ G_{kk’}^{\left[l\right]\left(G\right)} &amp;= \sum_{i=1}^{n_H^{\left[l\right]}} \sum_{j=1}^{n_W^{\left[l\right]}} a_{i,j,k}^{\left[l\right]\left(G\right)} a_{i,j,k’}^{\left[l\right]\left(G\right)} \qquad \textsf{Gram Matrix}^{\strut} \end{aligned}$</p>
<p>$\begin{aligned} J_{\rm style}^{\left[l\right]} \left(S,G\right) &amp;= \dfrac{1}{\left(2 n_H^{\left[l\right]} n_W^{\left[l\right]} n_C^{\left[l\right]} \right)^2} \cdot \left| G^{\left[l\right]\left(S\right)}  - G^{\left[l\right]\left(G\right)} \right| ^2_F \\ &amp;= \dfrac{1}{\left(2 n_H^{\left[l\right]} n_W^{\left[l\right]} n_C^{\left[l\right]} \right)^2} \cdot \sum_{k} \sum_{k’} \left( G^{\left[l\right]\left(S\right)}_{kk’}  - G^{\left[l\right]\left(G\right)}_{kk’} \right)^2 \\ \\ J_{\rm style} \left(S,G\right) &amp;= \sum_l \lambda ^{\left[l\right]} J_{\rm style}^{\left[l\right]} \left(S,G\right) \end{aligned}$</p>
<p>$J\left(G\right) = \alpha\cdot J_{\rm content} \left(C,G\right) + \beta\cdot J_{\rm style} \left(S,G\right)$</p>
<h4 id="1D-and-3D-Generalizations"><a href="#1D-and-3D-Generalizations" class="headerlink" title="1D and 3D Generalizations"></a>1D and 3D Generalizations</h4><h5 id="2D-to-1D"><a href="#2D-to-1D" class="headerlink" title="2D to 1D"></a>2D to 1D</h5><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-13/6.png" alt></p>
<h5 id="2D-to-3D"><a href="#2D-to-3D" class="headerlink" title="2D to 3D"></a>2D to 3D</h5><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-13/7.png" alt></p>
<h3 id="Programming-Assignments"><a href="#Programming-Assignments" class="headerlink" title="Programming Assignments"></a>Programming Assignments</h3><h4 id="Art-generation-with-Neural-Style-Transfer"><a href="#Art-generation-with-Neural-Style-Transfer" class="headerlink" title="Art generation with Neural Style Transfer"></a>Art generation with Neural Style Transfer</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-13/8.png" alt></p>
<h4 id="Face-Recognition-1"><a href="#Face-Recognition-1" class="headerlink" title="Face Recognition"></a>Face Recognition</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-13/9.png" alt></p>
<p><a href="https://github.com/bugstop/coursera-deep-learning-solutions" target="_blank">Solutions Manual</a></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (15) · Natural Language Processing</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-15/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course E<br><strong>Sequence Models</strong> by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 2:</em></strong> <em>Natural Language Processing &amp; Word Embeddings</em></p>
<ol>
<li>Natural language processing with deep learning is an important combination. Using word vector representations and embedding layers you can train recurrent neural networks with outstanding performances in a wide variety of industries. Examples of applications are sentiment analysis, named entity recognition and machine translation.</li>
</ol>
<a id="more"></a>
<h3 id="Introduction-to-Word-Embeddings"><a href="#Introduction-to-Word-Embeddings" class="headerlink" title="Introduction to Word Embeddings"></a>Introduction to Word Embeddings</h3><h4 id="Word-Representation"><a href="#Word-Representation" class="headerlink" title="Word Representation"></a>Word Representation</h4><p><em>the inner product between any two different <strong>one-hot</strong> vector is zero</em></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-15/1.png" alt></p>
<h5 id="t-SNE"><a href="#t-SNE" class="headerlink" title="t-SNE"></a>t-SNE</h5><p>visualize word embeddings</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-15/2.png" alt></p>
<h4 id="Using-Word-Embeddings"><a href="#Using-Word-Embeddings" class="headerlink" title="Using Word Embeddings"></a>Using Word Embeddings</h4><ol>
<li>Learning word embeddings from large text corpus, or download pretrained embedding online. <em>(1-100B words)</em></li>
<li>Transfer embedding to new task with smaller training set. <em>(~100k words)</em></li>
<li><em>Optional:</em> Continue to finetune the word embeddings with new data.</li>
</ol>
<h4 id="Properties-of-Word-Embeddings"><a href="#Properties-of-Word-Embeddings" class="headerlink" title="Properties of Word Embeddings"></a>Properties of Word Embeddings</h4><p>$\begin{aligned}&amp; \!\!\!\!\! \textsf{Man} \rightarrow \textsf{Woman  as  King} \rightarrow \underline{\rm Queen} \\ e_{man} &amp;- e_{woman} \approx \left[\begin{matrix} -2\\0\\0\\0 \end{matrix}\right] \approx e_{king} - e_{queen} \end{aligned}$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-15/3.png" alt></p>
<p>find word w: ${\rm argmax}\ {\rm sim} \left(e_w, \ e_{king} - e_{man} + e_{woman} \right) \qquad {\rm sim}\left(u,v\right) = \dfrac{u^{\mathsf{T}}v} {\left|u\right|_2\left|v\right|_2}$</p>
<h4 id="Embedding-Matrix"><a href="#Embedding-Matrix" class="headerlink" title="Embedding Matrix"></a>Embedding Matrix</h4><ul>
<li><strong><em>E:</em></strong> embedding matrix</li>
<li><strong><em>o:</em></strong> one-hot vector</li>
<li><strong><em>e:</em></strong> embedding vector</li>
</ul>
<p>$E_{300\times10000}\cdot o_{10000\times1} = \left[\begin{matrix} a&amp;aaron&amp;\cdots&amp;orange&amp;\cdots&amp;zulu \\ \\ \\ &amp;&amp;&amp;E \\ \\ \\ \end{matrix}\right] \left[\begin{matrix} 0\\0\\\vdots\\1\\\vdots\\0 \end{matrix}\right] = e_{300\times1} $</p>
<p><em>use embedding layer to call out the column instead of a matrix vector multiplication</em></p>
<h3 id="Learning-Word-Embeddings-Word2Vec-amp-GloVe"><a href="#Learning-Word-Embeddings-Word2Vec-amp-GloVe" class="headerlink" title="Learning Word Embeddings: Word2Vec &amp; GloVe"></a>Learning Word Embeddings: Word2Vec &amp; GloVe</h3><h4 id="Learning-Word-Embeddings"><a href="#Learning-Word-Embeddings" class="headerlink" title="Learning Word Embeddings"></a>Learning Word Embeddings</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-15/4.png" alt></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-15/5.png" alt></p>
<h4 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h4><h5 id="Skip-Grams"><a href="#Skip-Grams" class="headerlink" title="Skip Grams"></a>Skip Grams</h5><p>$\begin{aligned} &amp; \Rightarrow \quad \textrm{I want a glass of orange juice to go along with my cereal.} \\ &amp; \qquad\qquad \begin{matrix} \textsf{context} &amp; orange &amp; orange &amp; orange &amp; \cdots &amp;&amp; \\ \textsf{target} &amp; juice &amp; glass &amp; my &amp; \cdots &amp;&amp; \textsf{randomly picked within some window} \end{matrix} \\ &amp; \Rightarrow \quad {\rm Context} \ c \rightarrow {\rm Target} \ t \quad \Rightarrow \quad o_c \rightarrow E \rightarrow e_c \rightarrow {\rm softmax} \rightarrow \hat{y} \\ &amp; \qquad\qquad {\rm softmax} \ p\left(t|c\right) = \dfrac{e^{\theta_t^{\mathsf{T}} e_c}}{\sum_j e^{\theta_j^{\mathsf{T}} e_c}} \qquad \theta_t \textsf{: parameter associated with output } t \\ &amp; \qquad\qquad {\rm Loss} \ L\left(\hat{y},y\right) = -\sum_i y_i \log \hat{y}_i \end{aligned}$</p>
<p><strong>Problems</strong></p>
<ul>
<li><p><strong><em>softmax is slow</em></strong></p>
<ul>
<li><p>hierarchical softmax classifier</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-15/6.png" alt></p>
</li>
</ul>
</li>
<li><p><strong><em>how to sample the context c</em></strong></p>
<ul>
<li>uniformly random → <em>the, of, a, and, to, …</em></li>
<li><strong>heuristics</strong></li>
</ul>
</li>
</ul>
<h4 id="Negative-Sampling"><a href="#Negative-Sampling" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h4><p><strong>Generate Negative Samples</strong><br>pick <strong><em>k</em></strong> target words from the dictionary <strong><em>randomly</em></strong> and label all those <strong><em>0</em></strong></p>
<p>$P\left(\omega_i\right) = \dfrac{f\left(\omega_i\right)^{3/4}}{\sum_j f\left(\omega_j\right)^{3/4}} \qquad f \textsf{: frequency of word}$</p>
<p>$\begin{matrix} \rm context &amp; \rm word &amp; \rm target? \\ orange &amp; juice &amp; 1 \\ orange &amp; king &amp; 0 \\ orange &amp; the &amp; 0 \\ \vdots &amp; \vdots &amp; \vdots \\ orange &amp; of &amp; 0 \\ c&amp;t&amp;y \end{matrix}$</p>
<p>$\begin{aligned} \Downarrow \quad p\left(t|c\right) &amp;= \dfrac{e^{\theta_t^{\mathsf{T}} e_c}}{\sum_j e^{\theta_j^{\mathsf{T}} e_c}} \qquad &amp; \textsf{compute 10000-way softmax function} \\ p\left(y=1|c,t\right) &amp;= {\rm sigmoid} \left( \theta_t^{\mathsf{T}} e_c \right) &amp; \textsf{k out of 10000 binary classifications} \end{aligned}$</p>
<h4 id="GloVe-Word-Vectors"><a href="#GloVe-Word-Vectors" class="headerlink" title="GloVe Word Vectors"></a>GloVe Word Vectors</h4><p><strong>Global Vectors for Word Representation</strong></p>
<p>$\begin{aligned} X_{ij} &amp;= \textrm{number of times } j \textrm{ appears in context of } i \qquad \textit{( i: c ,  j: t )} \\ X_{ji} &amp;= X_{ij} \end{aligned}$</p>
<p>$\begin{aligned} {\rm minimize} \ &amp; \sum_i \sum_j f\left(X_{ij}\right) \left( \theta_i^{\mathsf{T}} e_j +b_i +b’_j -\log X_{ij} \right) ^2 \\ \cdot \ &amp; \textsf{weighting term } f\left(X_{ij}\right) = 0 \quad {\rm if} \quad X_{ij}=0 , \qquad 0\log0=0 \\ &amp;\qquad \textsf{also deal with stop words (is, of, a), and weigh less frequent words} \\ \cdot \ &amp; \theta_i,\, e_j\textsf{ are symmetric} \end{aligned}$</p>
<h3 id="Applications-Using-Word-Embeddings"><a href="#Applications-Using-Word-Embeddings" class="headerlink" title="Applications Using Word Embeddings"></a>Applications Using Word Embeddings</h3><h4 id="Sentiment-Classification"><a href="#Sentiment-Classification" class="headerlink" title="Sentiment Classification"></a>Sentiment Classification</h4><p><strong><em>small training sets</em></strong></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-15/7.png" alt></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-15/8.png" alt></p>
<h4 id="Debiasing-Word-Embeddings"><a href="#Debiasing-Word-Embeddings" class="headerlink" title="Debiasing Word Embeddings"></a>Debiasing Word Embeddings</h4><ul>
<li>Man: Woman as King: Queen</li>
<li>Man: Computer_Programmer as Woman: Homemaker</li>
<li>Father: Doctor as Mother: Nurse</li>
</ul>
<p><em>Word embeddings can reflect gender, ethnicity, age, sexual orientation, and other biases of the text used to train the model.</em></p>
<ol>
<li><p><strong>Identify bias direction.</strong></p>
<p>${\rm average} \begin{cases}e_{he}-e_{she} \\ e_{male}-e_{female} \\\cdots \end{cases} \qquad$<em>( SVU, singular value decomposition )</em></p>
</li>
<li><p><strong>Neutralize: for every word that is not definitional, project to get rid of bias.</strong></p>
</li>
<li><p><strong>Equalize pairs.</strong></p>
</li>
</ol>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-15/9.png" alt></p>
<h3 id="Programming-Assignments"><a href="#Programming-Assignments" class="headerlink" title="Programming Assignments"></a>Programming Assignments</h3><h4 id="Operations-on-Word-Vectors-Debiasing"><a href="#Operations-on-Word-Vectors-Debiasing" class="headerlink" title="Operations on Word Vectors - Debiasing"></a>Operations on Word Vectors - Debiasing</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-15/10.png" alt></p>
<h4 id="Emojify"><a href="#Emojify" class="headerlink" title="Emojify"></a>Emojify</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-15/11.png" alt></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-15/12.png" alt></p>
<p><a href="https://github.com/bugstop/coursera-deep-learning-solutions" target="_blank">Solutions Manual</a></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (14) · Recurrent Neural Networks</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-14/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course E<br><strong>Sequence Models</strong> by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 1:</em></strong> <em>Recurrent Neural Networks</em></p>
<ol>
<li>Learn about recurrent neural networks. This type of model has been proven to perform extremely well on temporal data. It has several variants including LSTMs, GRUs and Bidirectional RNNs, which you are going to learn about in this section.</li>
</ol>
<a id="more"></a>
<h3 id="Recurrent-Neural-Networks"><a href="#Recurrent-Neural-Networks" class="headerlink" title="Recurrent Neural Networks"></a>Recurrent Neural Networks</h3><h4 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h4><ul>
<li><strong><em>x:</em></strong> x<sup>&lt;1&gt;</sup>, x<sup>&lt;2&gt;</sup>, x<sup>&lt;3&gt;</sup>, …, x<sup>&lt;t&gt;</sup>, …, x<sup>&lt;9&gt;</sup>,   T<sub>x</sub> = 9<br><em>Harry Potter and Hermione Granger invented a new spell.</em></li>
<li><strong><em>y:</em></strong> y<sup>&lt;1&gt;</sup>, y<sup>&lt;2&gt;</sup>, y<sup>&lt;3&gt;</sup>, …, y<sup>&lt;t&gt;</sup>, …, y<sup>&lt;9&gt;</sup>,   T<sub>y</sub> = 9<br>named-entity recognition: <em>1 1 0 1 1 0 0 0 0</em></li>
</ul>
<p>$\begin{matrix} \qquad \textit{x:} &amp; \textsf{Harry} &amp; \textsf{Potter} &amp; \textsf{and} &amp; \textsf{Hermione} &amp; \textsf{Granger} &amp; \textsf{invented} &amp; \textsf{a} &amp; \textsf{new} &amp; \textsf{spell} \\ &amp; x^{\left\lt 1\right\gt } &amp; x^{\left\lt 2\right\gt } &amp; x^{\left\lt 3\right\gt } &amp; x^{\left\lt 4\right\gt } &amp; x^{\left\lt 5\right\gt } &amp; x^{\left\lt 6\right\gt } &amp; x^{\left\lt 7\right\gt } &amp; x^{\left\lt 8\right\gt } &amp; x^{\left\lt 9\right\gt } \\ {\rm Vocabulary} &amp; \downarrow &amp; \downarrow &amp; \downarrow &amp; \large{\rm one \ hot}  &amp;&amp;&amp;&amp;&amp; \\ \left[\begin{matrix} \rm a \\ \rm aaron \\ \vdots \\ \rm and \\ \vdots \\ \rm harry \\ \vdots \\ \rm potter \\ \vdots \\ \rm zulu \end{matrix}\right] &amp; \left[\begin{matrix} 0 \\ 0 \\ \vdots \\ 0 \\ \vdots \\ 1 \\ \vdots \\ 0 \\ \vdots \\ 0 \end{matrix}\right] &amp; \left[\begin{matrix} 0 \\ 0 \\ \vdots \\ 0 \\ \vdots \\ 0 \\ \vdots \\ 1 \\ \vdots \\ 0 \end{matrix}\right] &amp; \left[\begin{matrix} 0 \\ 0 \\ \vdots \\ 1 \\ \vdots \\ 0 \\ \vdots \\ 0 \\ \vdots \\ 0 \end{matrix}\right] &amp; \cdots &amp; \cdots \end{matrix}$</p>
<p>use a new fake word <strong>&lt;UNK&gt;</strong> to represent words not in the vocabulary<br>use a toke <strong>&lt;EOS&gt;</strong> to represent the end of every sentence</p>
<h4 id="Recurrent-Neural-Network-Model"><a href="#Recurrent-Neural-Network-Model" class="headerlink" title="Recurrent Neural Network Model"></a>Recurrent Neural Network Model</h4><p><strong>Why not a standard network</strong></p>
<ul>
<li>inputs and outputs can be different lengths in different examples</li>
<li>does not share features learned across different positions of text</li>
</ul>
<p><strong>Recurrent Neural Network</strong></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-14/1.png" alt></p>
<p><strong><em>limitation:</em></strong> not using information later in the sequence → BRNN (Bidirectional Recurrent Neural Network)</p>
<h5 id="Forward-Propagation"><a href="#Forward-Propagation" class="headerlink" title="Forward Propagation"></a>Forward Propagation</h5><p>$\begin{aligned}a^{\left\lt 0\right\gt } &amp;= \overrightarrow {0} _{\strut} \\ a^{\left\lt 1\right\gt } &amp;= g\left( W_{aa} a^{\left\lt 0\right\gt } + W_{ax} x^{\left\lt 1\right\gt } +b_a \right) &amp;{\rm tanh / ReLU} \\ \hat{y}^{\left\lt 1\right\gt } &amp;= g\left( W_{ya} a^{\left\lt 1\right\gt } +b_y \right) &amp;{\rm sigmoid / softmax} \\ &amp;\ \ \vdots \\ a^{\left\lt t\right\gt } &amp;= g\left( W_{aa} a^{\left\lt t-1\right\gt } + W_{ax} x^{\left\lt t\right\gt } +b_a \right) \\ &amp;= g\left( W_{a} \left[ a^{\left\lt t-1\right\gt }, x^{\left\lt t\right\gt } \right] +b_a \right) &amp; W_a &amp;= \left[ \begin{array}{c|c} W_{aa} &amp; W_{ax} \end{array} \right] \\ \hat{y}^{\left\lt t\right\gt } &amp;= g\left( W_{ya} a^{\left\lt t\right\gt } +b_y \right) = g\left( W_{y} a^{\left\lt t\right\gt } +b_y \right) &amp; \left[ a^{\left\lt t-1\right\gt }, x^{\left\lt t\right\gt } \right] &amp;= \left[ \begin{array}{c} a^{\left\lt t-1\right\gt } \\ \hline x^{\left\lt t\right\gt } \end{array} \right] \end{aligned}$</p>
<h4 id="Backpropagation-Through-Time"><a href="#Backpropagation-Through-Time" class="headerlink" title="Backpropagation Through Time"></a>Backpropagation Through Time</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-14/2.png" alt></p>
<p>$\begin{aligned} &amp; L^{\left\lt t\right\gt } \left( \hat{y}^{\left\lt t\right\gt }, y^{\left\lt t\right\gt } \right) = -{y}^{\left\lt t\right\gt } \log \hat{y}^{\left\lt t\right\gt } - \left(1-{y}^{\left\lt t\right\gt } \right) \log \left( 1- \hat{y}^{\left\lt t\right\gt } \right) \\ &amp; L \left( \hat{y}, y\right) = \sum_{t=1}^{T_y} L^{\left\lt t\right\gt } \left( \hat{y}^{\left\lt t\right\gt }, y^{\left\lt t\right\gt } \right)  \end{aligned}$</p>
<h4 id="Different-Types-of-RNNs"><a href="#Different-Types-of-RNNs" class="headerlink" title="Different Types of RNNs"></a>Different Types of RNNs</h4><ul>
<li>many-to-many architecture</li>
<li>many-to-one architecture</li>
<li>one-to-many architecture</li>
<li>one-to-one architecture</li>
<li>many-to-many architecture <em>(different length)</em></li>
</ul>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-14/3.png" alt></p>
<h4 id="Language-Model-and-Sequence-Generation"><a href="#Language-Model-and-Sequence-Generation" class="headerlink" title="Language Model and Sequence Generation"></a>Language Model and Sequence Generation</h4><p>$P\left( y^{\left\lt 1\right\gt }, y^{\left\lt 2\right\gt }, \dots, y^{\left\lt T_y\right\gt }\right)$</p>
<ul>
<li><strong><em>training set:</em></strong> large corpus of text</li>
</ul>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-14/4.png" alt></p>
<p>$\begin{aligned} &amp; L^{\left\lt t\right\gt } \left( \hat{y}^{\left\lt t\right\gt }, y^{\left\lt t\right\gt } \right) = - \sum_i {y}^{\left\lt t\right\gt }_i \log \hat{y}^{\left\lt t\right\gt } _i \\ &amp; L \left( \hat{y}, y\right) = \sum_t L^{\left\lt t\right\gt } \left( \hat{y}^{\left\lt t\right\gt }, y^{\left\lt t\right\gt } \right)  \end{aligned}$</p>
<h4 id="Sampling-Novel-Sequences"><a href="#Sampling-Novel-Sequences" class="headerlink" title="Sampling Novel Sequences"></a>Sampling Novel Sequences</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-14/5.png" alt></p>
<h4 id="Vanishing-Gradients-with-RNNs"><a href="#Vanishing-Gradients-with-RNNs" class="headerlink" title="Vanishing Gradients with RNNs"></a>Vanishing Gradients with RNNs</h4><p>$\xleftarrow{\textrm{The}\ cat\ \textrm{which … …} \ was\ \textrm{full.}}$<br>$\xleftarrow{\textrm{The}\ cats\ \textrm{which … …} \ were\ \textrm{full.}}$</p>
<h4 id="Gated-Recurrent-Unit-GRU"><a href="#Gated-Recurrent-Unit-GRU" class="headerlink" title="Gated Recurrent Unit (GRU)"></a>Gated Recurrent Unit (GRU)</h4><p>$a ^{\left\lt t\right\gt } = \tanh \left( W_{a} \left[ a^{\left\lt t-1\right\gt }, x^{\left\lt t\right\gt } \right] +b_a \right)$</p>
<h5 id="Simplified-GRU"><a href="#Simplified-GRU" class="headerlink" title="Simplified GRU"></a>Simplified GRU</h5><ul>
<li><strong><em>c:</em></strong> memory cell, c<sup>&lt;t&gt;</sup> = a<sup>&lt;t&gt;</sup></li>
</ul>
<p>$\begin{aligned} \tilde{c} ^{\left\lt t\right\gt } &amp;= \tanh \left( W_{c} \left[ c^{\left\lt t-1\right\gt }, x^{\left\lt t\right\gt } \right] +b_c \right) \\ \Gamma_u &amp;= {\rm sigmoid} \left( W_u \left[ c^{\left\lt t-1\right\gt }, x^{\left\lt t\right\gt } \right] +b_u \right) &amp; {\approx 0 \ {\rm or} \ 1} \quad \textsf{Gate: update?} \\ c^{\left\lt t\right\gt } &amp;= \Gamma_u \odot \tilde{c}^{\left\lt t\right\gt }  + \left(1-\Gamma_u\right) \odot c^{\left\lt t-1\right\gt } \qquad &amp; \textsf{element-wise multiplication} \end{aligned}$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-14/6.png" alt></p>
<h5 id="Full-GRU"><a href="#Full-GRU" class="headerlink" title="Full GRU"></a>Full GRU</h5><p>$\begin{aligned} \tilde{c} ^{\left\lt t\right\gt } &amp;= \tanh \left( W_{c} \left[ \Gamma_r \odot c^{\left\lt t-1\right\gt }, x^{\left\lt t\right\gt } \right] +b_c \right) \\ \Gamma_u &amp;= {\rm sigmoid} \left( W_u \left[ c^{\left\lt t-1\right\gt }, x^{\left\lt t\right\gt } \right] +b_u \right) \\ \Gamma_r &amp;= {\rm sigmoid} \left( W_r \left[ c^{\left\lt t-1\right\gt }, x^{\left\lt t\right\gt } \right] +b_r \right) \\ c^{\left\lt t\right\gt } &amp;= \Gamma_u \odot \tilde{c}^{\left\lt t\right\gt } + \left(1-\Gamma_u\right) \odot c^{\left\lt t-1\right\gt } \\ {a} ^{\left\lt t\right\gt } &amp;= {c} ^{\left\lt t\right\gt } \end{aligned}$</p>
<h4 id="Long-Short-Term-Memory-LSTM"><a href="#Long-Short-Term-Memory-LSTM" class="headerlink" title="Long Short Term Memory (LSTM)"></a>Long Short Term Memory (LSTM)</h4><p>$\begin{aligned} \tilde{c} ^{\left\lt t\right\gt } &amp;= \tanh \left( W_{c} \left[ a^{\left\lt t-1\right\gt }, x^{\left\lt t\right\gt } \right] +b_c \right) \\ \Gamma_u &amp;= {\rm sigmoid} \left( W_u \left[ a^{\left\lt t-1\right\gt }, x^{\left\lt t\right\gt } \right] +b_u \right) &amp; \textsf{update gate} \\ \Gamma_f &amp;= {\rm sigmoid} \left( W_f \left[ a^{\left\lt t-1\right\gt }, x^{\left\lt t\right\gt } \right] +b_f \right) &amp; \textsf{forget gate} \\ \Gamma_o &amp;= {\rm sigmoid} \left( W_o \left[ a^{\left\lt t-1\right\gt }, x^{\left\lt t\right\gt } \right] +b_o \right) &amp; \textsf{output gate} \\ c^{\left\lt t\right\gt } &amp;= \Gamma_u \odot \tilde{c}^{\left\lt t\right\gt } + \Gamma_f \odot c^{\left\lt t-1\right\gt } \\ {a} ^{\left\lt t\right\gt } &amp;= \Gamma_o \odot \tanh \left( {c} ^{\left\lt t\right\gt } \right) \end{aligned}$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-14/7.png" alt></p>
<h4 id="Bidirectional-RNN-BRNN"><a href="#Bidirectional-RNN-BRNN" class="headerlink" title="Bidirectional RNN (BRNN)"></a>Bidirectional RNN (BRNN)</h4><p><strong>Acyclic Graph</strong></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-14/8.png" alt></p>
<p>$\hat{y}^{\left\lt t\right\gt } = g\left( W_y \left[ \overrightarrow {a}^{\left\lt t\right\gt } , \overleftarrow {a}^{\left\lt t\right\gt } \right] +b_y\right)$</p>
<h4 id="Deep-RNNs"><a href="#Deep-RNNs" class="headerlink" title="Deep RNNs"></a>Deep RNNs</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-14/9.png" alt></p>
<h3 id="Programming-Assignments"><a href="#Programming-Assignments" class="headerlink" title="Programming Assignments"></a>Programming Assignments</h3><h4 id="Building-a-Recurrent-Neural-Network-step-by-step"><a href="#Building-a-Recurrent-Neural-Network-step-by-step" class="headerlink" title="Building a Recurrent Neural Network - step by step"></a>Building a Recurrent Neural Network - step by step</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-14/10.png" alt></p>
<h4 id="Dinosaur-Island-Character-Level-Language-Modeling"><a href="#Dinosaur-Island-Character-Level-Language-Modeling" class="headerlink" title="Dinosaur Island - Character-Level Language Modeling"></a>Dinosaur Island - Character-Level Language Modeling</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-14/11.png" alt></p>
<h4 id="Jazz-Improvisation-with-LSTM"><a href="#Jazz-Improvisation-with-LSTM" class="headerlink" title="Jazz Improvisation with LSTM"></a>Jazz Improvisation with LSTM</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-14/12.png" alt></p>
<p><a href="https://github.com/bugstop/coursera-deep-learning-solutions" target="_blank">Solutions Manual</a></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (16) · Sequence Models</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course E<br><strong>Sequence Models</strong> by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 3:</em></strong> <em>Sequence Models &amp; Attention Mechanism</em></p>
<ol>
<li>Sequence models can be augmented using an attention mechanism. This algorithm will help your model understand where it should focus its attention given a sequence of inputs. This week, you will also learn about speech recognition and how to deal with audio data.</li>
</ol>
<a id="more"></a>
<h3 id="Various-Sequence-to-Sequence-Architectures"><a href="#Various-Sequence-to-Sequence-Architectures" class="headerlink" title="Various Sequence to Sequence Architectures"></a>Various Sequence to Sequence Architectures</h3><h4 id="Basic-Models"><a href="#Basic-Models" class="headerlink" title="Basic Models"></a>Basic Models</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/1.png" alt></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/2.png" alt></p>
<h4 id="Picking-the-Most-Likely-Sentence"><a href="#Picking-the-Most-Likely-Sentence" class="headerlink" title="Picking the Most Likely Sentence"></a>Picking the Most Likely Sentence</h4><p><strong>Conditional Language Model</strong></p>
<p>$P\left(y^{\left\lt 1 \right\gt},\,\dots,\,y^{\left\lt T_y \right\gt} | x^{\left\lt 1 \right\gt},\,\dots,\, x^{\left\lt T_x \right\gt}\right)$</p>
<p>${\rm argmax}_{y^{\left\lt 1 \right\gt},\,\dots,\,y^{\left\lt T_y \right\gt}} P\left(y^{\left\lt 1 \right\gt},\,\dots,\,y^{\left\lt T_y \right\gt} | x\right)$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/3.png" alt></p>
<h4 id="Beam-Search"><a href="#Beam-Search" class="headerlink" title="Beam Search"></a>Beam Search</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/4.png" alt></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/5.png" alt></p>
<h4 id="Refinements-to-Beam-Search"><a href="#Refinements-to-Beam-Search" class="headerlink" title="Refinements to Beam Search"></a>Refinements to Beam Search</h4><h5 id="Length-Normalization"><a href="#Length-Normalization" class="headerlink" title="Length Normalization"></a>Length Normalization</h5><p>$\begin{aligned} &amp; {\rm argmax}_y \prod_{t=1}^{T_y}  P\left(y^{\left\lt t \right\gt} | x,\,y^{\left\lt 1 \right\gt},\,\dots,\, y^{\left\lt t-1 \right\gt}\right) &amp; \textsf{ numerical underflow} \\ \Rightarrow \ &amp; {\rm argmax}_y \sum_{t=1}^{T_y} \log P\left(y^{\left\lt t \right\gt} | x,\,y^{\left\lt 1 \right\gt},\,\dots,\, y^{\left\lt t-1 \right\gt}\right) &amp; \textsf{short sentences} \\ \Rightarrow \ &amp; {\rm argmax}_y \dfrac{1}{T_y^{\,\alpha}} \sum_{t=1}^{T_y} \log P\left(y^{\left\lt t \right\gt} | x,\,y^{\left\lt 1 \right\gt},\,\dots,\, y^{\left\lt t-1 \right\gt}\right) &amp; \alpha \sim 0.7 \qquad \qquad \qquad \end{aligned}$</p>
<ul>
<li><strong><em>Beam Width</em></strong><ul>
<li>large B: better result, slower</li>
<li>small B: worse result, faster</li>
</ul>
</li>
</ul>
<h4 id="Error-Analysis-in-Beam-Search"><a href="#Error-Analysis-in-Beam-Search" class="headerlink" title="Error Analysis in Beam Search"></a>Error Analysis in Beam Search</h4><ul>
<li><p><strong>Jane visite l’Afrique en septembre.</strong> $\quad x$</p>
<ul>
<li><strong><em>Human:</em></strong> Jane visits Africa in September. $\quad y^\star$</li>
<li><strong><em>Algorithm:</em></strong>  Jane visited Africa last September. $\quad \hat{y}$</li>
</ul>
</li>
<li><p><strong>RNN / Bean Search</strong></p>
<ul>
<li><p>RNN computes $P\left(y|x\right)$</p>
<p>$\begin{cases}\begin{aligned} P\left(y^\star|x\right) &amp;&gt; P\left(\hat{y}|x\right) &amp; \textsf{beam search is at fault} \\ P\left(y^\star|x\right) &amp;\leq P\left(\hat{y}|x\right) &amp; \textsf{RNN model is at fault} \end{aligned}\end{cases}$</p>
</li>
<li><p>Figure out what faction of errors are due to beam search vs RNN model</p>
</li>
</ul>
</li>
</ul>
<h4 id="Bleu-Score"><a href="#Bleu-Score" class="headerlink" title="Bleu Score"></a>Bleu Score</h4><p><strong>Bilingual Evolution Understudy</strong></p>
<ul>
<li><p><strong>Le chat est sur le tapis.</strong></p>
<ul>
<li><p><strong><em>Reference 1:</em></strong> <strong>The</strong> cat is on <strong>the</strong> mat.</p>
</li>
<li><p><strong><em>Reference 2:</em></strong> There is a cat on <strong>the</strong> mat.</p>
</li>
<li><p><strong><em>Machine Translation 1:</em></strong> The the the the the the the.</p>
<ul>
<li><p>Precision</p>
<p>$\dfrac{\textsf{appear in reference}}{\textsf{word count}} = \dfrac{7}{7}$</p>
</li>
<li><p>Modified Precision</p>
<p>$\dfrac{\textsf{max count in reference}}{\textsf{Count(the)}} = \dfrac{\textsf{Count}_{\textsf{clip}}\textsf{(the)}}{\textsf{Count(the)}} = \dfrac{2}{7}$</p>
</li>
</ul>
</li>
<li><p><strong><em>Machine Translation 2:</em></strong> The cat the cat on the mat.</p>
<ul>
<li><p>Bigrams Modified Precision</p>
<p>$\begin{matrix} &amp; \textsf{Count} &amp; \textsf{Count}_{\textsf{clip}} &amp; \\ \textrm{the cat} &amp;2&amp;1&amp; \\ \textrm{cat the} &amp;1&amp;0&amp; \\ \textrm{cat on} &amp;1&amp;1&amp; \\ \textrm{on the} &amp;1&amp;1&amp; \\ \textrm{the mat} &amp;1&amp;1&amp; \\ &amp;6&amp;4&amp; P = 4/6  \end{matrix}$</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>$\begin{aligned} &amp; \textsf{unigram}_{\strut} \\ P_1 &amp;= \dfrac{\displaystyle\sum_{\textrm{unigram} \in\hat{y}} \textsf{Count}_{\textsf{clip}} \left(\textrm{unigram}\right)} {\displaystyle\sum_{\textrm{unigram} \in\hat{y}} \textsf{Count} \left(\textrm{unigram}\right)} \\\\ &amp; \textsf{n-gram}_{\strut} \\ P_n &amp;= \dfrac{\displaystyle\sum_{\textrm{n-gram} \in\hat{y}} \textsf{Count}_{\textsf{clip}} \left(\textrm{n-gram}\right)} {\displaystyle\sum_{\textrm{n-gram} \in\hat{y}} \textsf{Count} \left(\textrm{n-gram}\right)} \\\\ &amp; \textsf{combined bleu score}_{\strut} \\ P &amp;= {\rm BP} \exp \left( \dfrac{1}{4} \sum_n P_n \right) \\ &amp; \textrm{BP: brevity penalty} \\ {\rm BP} &amp;= \begin{cases} 1 &amp; \textrm{if  MT_length &gt; REF_length} \\ \exp \left(1- \dfrac{\textrm{REF_length}}{\textrm{MT_length}}\right) \quad &amp; \textrm{otherwise} \end{cases}\end{aligned}$</p>
<h4 id="Attention-Model-Intuition"><a href="#Attention-Model-Intuition" class="headerlink" title="Attention Model Intuition"></a>Attention Model Intuition</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/6.png" alt></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/7.png" alt></p>
<h4 id="Attention-Model"><a href="#Attention-Model" class="headerlink" title="Attention Model"></a>Attention Model</h4><p>$\begin{aligned} &amp; a ^{\left\lt t’ \right\gt} = \left( \overrightarrow {a}^{\left\lt t’ \right\gt}, \ \overleftarrow {a}^{\left\lt t’ \right\gt} \right) \\ &amp; \begin{aligned} \sum_{t’} {\alpha} ^{\left\lt 1,\,t’ \right\gt} = 1 \qquad &amp; {\alpha} ^{\left\lt t,\,t’ \right\gt} \textsf{ is the amount of “attention” } y  ^{\left\lt t \right\gt} \textsf{ should pay to } a^{\left\lt t’ \right\gt} \\ &amp; {\alpha} ^{\left\lt t,\,t’ \right\gt} = \dfrac{\exp \left( e^{\left\lt t,\,t’ \right\gt} \right)} {\sum_{t’=1}^{T_x} \exp \left( e^{\left\lt t,\,t’ \right\gt} \right)} \end{aligned} \\ \Rightarrow \ &amp; c ^{\left\lt 1 \right\gt} = \sum_{t’} {\alpha} ^{\left\lt 1,\,t’ \right\gt} a ^{\left\lt t’ \right\gt} \end{aligned}$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/8.png" alt></p>
<p><strong><em>quadratic time / cost</em></strong></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/9.png" alt></p>
<h3 id="Speech-recognition-Audio-data"><a href="#Speech-recognition-Audio-data" class="headerlink" title="Speech recognition - Audio data"></a>Speech recognition - Audio data</h3><h4 id="Speech-Recognition"><a href="#Speech-Recognition" class="headerlink" title="Speech Recognition"></a>Speech Recognition</h4><p>audio → frequency → end-to-end deep neuron network</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/10.png" alt></p>
<h5 id="CTC-Connectionist-Temporal-Classification"><a href="#CTC-Connectionist-Temporal-Classification" class="headerlink" title="CTC (Connectionist Temporal Classification)"></a>CTC (Connectionist Temporal Classification)</h5><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/11.png" alt></p>
<p><em>collapse repeated characters not separated by “blank”</em></p>
<h4 id="Trigger-Word-Detection"><a href="#Trigger-Word-Detection" class="headerlink" title="Trigger Word Detection"></a>Trigger Word Detection</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/12.png" alt></p>
<h3 id="Programming-Assignments"><a href="#Programming-Assignments" class="headerlink" title="Programming Assignments"></a>Programming Assignments</h3><h4 id="Neural-Machine-Translation-with-Attention"><a href="#Neural-Machine-Translation-with-Attention" class="headerlink" title="Neural Machine Translation with Attention"></a>Neural Machine Translation with Attention</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/13.png" alt></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/14.png" alt></p>
<h4 id="Trigger-word-detection"><a href="#Trigger-word-detection" class="headerlink" title="Trigger word detection"></a>Trigger word detection</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-16/15.png" alt></p>
<p><a href="https://github.com/bugstop/coursera-deep-learning-solutions" target="_blank">Solutions Manual</a></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (2) · Neural Networks Basics</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-2/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course A<br><strong>Neural Networks and Deep Learning</strong> by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 2:</em></strong> <em>Neural Networks Basics</em></p>
<ol>
<li>Build a logistic regression model, structured as a shallow neural network</li>
<li>Implement the main steps of an ML algorithm, including making predictions, derivative computation, and gradient descent.</li>
<li>Implement computationally efficient, highly vectorized, versions of models.</li>
<li>Understand how to compute derivatives for logistic regression, using a backpropagation mindset.</li>
<li>Become familiar with Python and Numpy</li>
<li>Work with iPython Notebooks</li>
<li>Be able to implement vectorization across multiple training examples</li>
</ol>
<a id="more"></a>
<h3 id="Logistic-Regression-as-a-Neural-Network"><a href="#Logistic-Regression-as-a-Neural-Network" class="headerlink" title="Logistic Regression as a Neural Network"></a>Logistic Regression as a Neural Network</h3><h4 id="Binary-Classification"><a href="#Binary-Classification" class="headerlink" title="Binary Classification"></a>Binary Classification</h4><ul>
<li><strong><em>y:</em></strong> 1<sup><em>(cat)</em></sup> vs 0<sup><em>(non cat)</em></sup></li>
<li><strong><em>image size:</em></strong> 64 × 64</li>
<li><strong><em>n<sub>x</sub>:</em></strong> 12288</li>
<li><strong><em>m:</em></strong> $\left\{ \left(x^{\left(1\right)},\ y^{\left(1\right)}\right),\  \left(x^{\left(2\right)},\ y^{\left(2\right)}\right),\ \dots ,\  \left(x^{\left(m\right)},\ y^{\left(m\right)}\right) \right\} \qquad x^{\left(i\right)}\in\mathbb{R}^{n_x},\ y^{\left(i\right)} \in\left\{0,1\right\}$</li>
</ul>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-2/image.png" alt="image"></p>
<p>$x = \underbrace{\left[ \begin{matrix} 255 &amp; 231 &amp; 42 &amp; \cdots &amp; 255 &amp; 134 &amp; 202 &amp; \cdots &amp; 231 &amp; 134 &amp; 93 &amp; \cdots \end{matrix} \right]^{\mathsf{T}}}_{n_x\ =\ 64\times64\times3\ =\ 12288}$</p>
<p>$X = \left[ \begin{matrix} \Big| &amp; \Big| &amp; \Big| &amp; &amp; \Big| \\ x^{\left(1\right)} &amp; x^{\left(2\right)} &amp; x^{\left(3\right)} &amp; \cdots &amp; x^{\left(m\right)} \\ \Big| &amp; \Big| &amp; \Big| &amp; &amp; \Big| \end{matrix} \right]  \qquad X\in\mathbb{R}^{n_x \times m}$</p>
<p>$Y = \left[ \begin{matrix} y^{\left(1\right)} &amp; y^{\left(2\right)} &amp; y^{\left(3\right)} &amp; \cdots &amp; y^{\left(m\right)} \end{matrix} \right]  \qquad Y\in\mathbb{R}^{1 \times m}$</p>
<h4 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h4><p>Given $x\in\mathbb{R}^{n_x}$, want $\hat{y} = P\left(y=1\ |\ x\right)$.<br><br><strong><em>Parameters:</em></strong> $w\in\mathbb{R}^{n_x},\ b\in\mathbb{R}^{n_x}$<br><br><strong><em>Output:</em></strong> $\hat{y}= \sigma\left( w^{\mathsf{T}}x+b \right) \qquad 0\leq\hat{y}\leq1$<br><br>&emsp;&emsp;&emsp;&emsp;$\sigma\left( z \right)={\rm sigmoid}\left(z\right) = \dfrac{1} {1 + e^{-z}}$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-2/sigmoid.png" alt="sigmoid"></p>
<h4 id="Logistic-Regression-Cost-Function"><a href="#Logistic-Regression-Cost-Function" class="headerlink" title="Logistic Regression Cost Function"></a>Logistic Regression Cost Function</h4><p>Given $\left\{ \left(x^{\left(1\right)},\ y^{\left(1\right)}\right),\  \left(x^{\left(2\right)},\ y^{\left(2\right)}\right),\ \dots ,\  \left(x^{\left(m\right)},\ y^{\left(m\right)}\right) \right\}$, want $\hat{y}^{\left(i\right)}=y^{\left(i\right)}$.</p>
<p><strong><em>Loss (error) function:</em></strong> $L\left(\hat{y},\,y\right)=-\left( y\log\hat{y} +\left(1-y\right) \log\left(1-\hat{y}\right) \right)$<br><br>&emsp;&emsp;&emsp;&emsp;<em>Notice:</em> $L\left(\hat{y},\,y\right) = \dfrac{1}{2}\left(\hat{y}-y\right)^2$ makes optimization problem <strong>non-convex.</strong></p>
<p><strong><em>Cost function:</em></strong> $\begin{aligned}J\left(w,\,b\right)= \dfrac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{\left(i\right)},\,y^{\left(i\right)}\right)= -\dfrac{1}{m} \sum_{i=1}^{m} \left( y^{\left(i\right)}\log\hat{y}^{\left(i\right)} +\left(1-y^{\left(i\right)}\right) \log\left(1-\hat{y}^{\left(i\right)}\right) \right)\end{aligned}$</p>
<p>Want to find $w, b$ to minimize $J\left(w,\,b\right)$.</p>
<h4 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h4><ol>
<li><p>initialize <strong>w, b</strong>​ to <strong>0​</strong></p>
</li>
<li><p>iterate until <strong>converge</strong> to global optimum &emsp; ( <strong><em>J(w, b)</em></strong> <em>is convex</em> )</p>
<p>$w:=w-\alpha \cdot \dfrac {\partial J\left( w,b\right)}{\partial w} \qquad b:=b-\alpha \cdot \dfrac {\partial J\left( w,b\right)}{\partial b}$</p>
</li>
</ol>
<h4 id="Derivatives-with-a-Computation-Graph"><a href="#Derivatives-with-a-Computation-Graph" class="headerlink" title="Derivatives with a Computation Graph"></a>Derivatives with a Computation Graph</h4><p>$J\left(a,b,c\right) = \underbrace{3\,(\underbrace{a + \underbrace{bc}_{u\,=\,bc}}_{v\,=\,a+u})}_{J\,=\,3v}$</p>
<ul>
<li><p><strong><em>forward propagation</em></strong> → cost function<br><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-2/fp.png" alt="left-to-right"></p>
</li>
<li><p><strong><em>back propagation</em></strong> → derivatives</p>
<p>Chain Rule: $\dfrac{dJ}{da} = \dfrac{dJ}{dv}\dfrac{dv}{da} = 3$, $\dfrac{dJ}{db} = \dfrac{dJ}{dv}\dfrac{dv}{du}\dfrac{du}{db} = 6$, $\dfrac{dJ}{dc} = \dfrac{dJ}{dv}\dfrac{dv}{du}\dfrac{du}{dc} = 9$</p>
<p>&emsp;&emsp;&emsp;&emsp;<em>p.s.</em> $\dfrac{d{\rm FinalOutputVar}}{d{\rm var}}$ in code is simplified as <code>dvar</code>, e.g., <code>dv = 3</code>, <code>da = 3</code>.<br><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-2/bp.png" alt="right-to-left"></p>
</li>
</ul>
<h4 id="Logistic-Regression-Gradient-Descent"><a href="#Logistic-Regression-Gradient-Descent" class="headerlink" title="Logistic Regression Gradient Descent"></a>Logistic Regression Gradient Descent</h4><p>$w_1 :=w_1 -\alpha \cdot dw_1 \qquad w_2 :=w_2 -\alpha \cdot dw_2 \qquad b:=b-\alpha \cdot db$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-2/lrgd.png" alt="example"></p>
<h4 id="Gradient-Descent-on-m-Examples"><a href="#Gradient-Descent-on-m-Examples" class="headerlink" title="Gradient Descent on m Examples"></a>Gradient Descent on m Examples</h4><p>$\begin{aligned} J\left(w,\,b\right) &amp;= \dfrac{1}{m} \sum_{i=1}^{m} L\left(a^{\left(i\right)},\,y^{\left(i\right)}\right) \\ \dfrac{\partial}{\partial w_1} J\left(w,\,b\right) &amp;= \dfrac{1}{m} \sum_{i=1}^{m}  \underbrace{\dfrac{\partial}{\partial w_1} L\left(a^{\left(i\right)},\,y^{\left(i\right)}\right)}_{dw_1^{\left(i\right)}} \end{aligned}$</p>
<h5 id="Algorithm-one-step-of-gradient-descent"><a href="#Algorithm-one-step-of-gradient-descent" class="headerlink" title="Algorithm (one step of gradient descent)"></a>Algorithm <em>(one step of gradient descent)</em></h5><p>$J=0; \ dw_1=0; \ dw_2=0; \ db=0$</p>
<p>For $i=1$ to $m$<br><br>&emsp;&emsp;$z^{\left(i\right)} = w^{\mathsf{T}} x^{\left(i\right)} +b$<br><br>&emsp;&emsp;$a^{\left(i\right)} = \sigma \left( x^{\left(i\right)} \right)$<br><br>&emsp;&emsp;$J +\!\!= - \left[ y^{\left(i\right)}\log a^{\left(i\right)} +\left(1-y^{\left(i\right)}\right) \log\left(1- a^{\left(i\right)}\right) \right]$<br><br>&emsp;&emsp;$dz^{\left(i\right)} = a^{\left(i\right)} - y^{\left(i\right)}$<br><br>&emsp;&emsp;$dw_1 +\!\!= x_1^{\left(i\right)} dz^{\left(i\right)}$<br><br>&emsp;&emsp;$dw_2 +\!\!= x_2^{\left(i\right)} dz^{\left(i\right)}$&emsp;&emsp;&emsp;&emsp;<em>( n = 2 )</em><br>&emsp;&emsp;$db +\!\!= dz^{\left(i\right)}$</p>
<p>$J /\!\!= m; \ w_1/\!\!= m; \ dw_2/\!\!= m; \ db/\!\!= m$</p>
<p>$w_1 :=w_1 -\alpha \cdot dw_1 \\ w_2 :=w_2 -\alpha \cdot dw_2 \\ b:=b-\alpha \cdot db$</p>
<p><strong>Weakness</strong></p>
<ul>
<li><strong><em>Efficiency:</em></strong> two for loops (m training samples, all features) → <strong><em>vectorization</em></strong></li>
</ul>
<h3 id="Python-and-Vectorization"><a href="#Python-and-Vectorization" class="headerlink" title="Python and Vectorization"></a>Python and Vectorization</h3><h4 id="Vectorization"><a href="#Vectorization" class="headerlink" title="Vectorization"></a>Vectorization</h4><p>$z = w^{\mathsf{T}}x+b$</p>
<p>$w = \left[ \begin{matrix} \vdots \\ \vdots \end{matrix} \right] \qquad x = \left[ \begin{matrix} \vdots \\ \vdots \end{matrix} \right]  \qquad w\in\mathbb{R}^{n_x}, \  x\in\mathbb{R}^{n_x}$</p>
<p><strong>non-vectorized</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">z = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_x):</span><br><span class="line">    z += w[i] * x[i]</span><br><span class="line">z += b</span><br></pre></td></tr></table></figure>
<p><strong>vectorized</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">z = np.dot(w, x) + b</span><br></pre></td></tr></table></figure>
<p><em>avoid using explicit for loops whenever possible</em></p>
<h5 id="Algorithm-one-for-loop"><a href="#Algorithm-one-for-loop" class="headerlink" title="Algorithm (one for-loop)"></a>Algorithm <em>(one for-loop)</em></h5><p>$J=0; \ dw=\texttt{np.zeros}\left(n_x, 1\right); \ db=0$</p>
<p>For $i=1$ to $m$<br><br>&emsp;&emsp;$z^{\left(i\right)} = w^{\mathsf{T}} x^{\left(i\right)} +b$<br><br>&emsp;&emsp;$a^{\left(i\right)} = \sigma \left( x^{\left(i\right)} \right)$<br><br>&emsp;&emsp;$J +\!\!= - \left[ y^{\left(i\right)}\log a^{\left(i\right)} +\left(1-y^{\left(i\right)}\right) \log\left(1- a^{\left(i\right)}\right) \right]$<br><br>&emsp;&emsp;$dz^{\left(i\right)} = a^{\left(i\right)} - y^{\left(i\right)}$<br><br>&emsp;&emsp;$dw +\!\!= x^{\left(i\right)} dz^{\left(i\right)}$<br><br>&emsp;&emsp;$db +\!\!= dz^{\left(i\right)}$</p>
<p>$J /\!\!= m; \ db/\!\!= m$</p>
<p>$w :=w -\alpha \cdot dw \\ b:=b-\alpha \cdot db$</p>
<h4 id="Vectorizing-Logistic-Regression"><a href="#Vectorizing-Logistic-Regression" class="headerlink" title="Vectorizing Logistic Regression"></a>Vectorizing Logistic Regression</h4><p>$z^{\left(i\right)} = w^{\mathsf{T}} x^{\left(i\right)} +b \qquad a^{\left(i\right)} = \sigma \left( x^{\left(i\right)} \right)$</p>
<p>$\begin{aligned}X= \left[ \begin{matrix} \Big| &amp; \Big| &amp; \Big| &amp; &amp; \Big| \\ x^{\left(1\right)} &amp; x^{\left(2\right)} &amp; x^{\left(3\right)} &amp; \cdots &amp; x^{\left(m\right)} \\ \Big| &amp; \Big| &amp; \Big| &amp; &amp; \Big| \end{matrix} \right] \qquad X\in\mathbb{R}^{n_x \times m}\end{aligned}$</p>
<p>$\begin{aligned}Y = \left[ \begin{matrix} y^{\left(1\right)} &amp; y^{\left(2\right)} &amp; y^{\left(3\right)} &amp; \cdots &amp; y^{\left(m\right)} \end{matrix} \right]  \qquad Y\in\mathbb{R}^{1 \times m}\end{aligned}$</p>
<p>$\begin{aligned}Z=\left[ \begin{matrix} z^{\left(1\right)} &amp; z^{\left(2\right)} &amp; z^{\left(3\right)} &amp; \cdots &amp; z^{\left(m\right)} \end{matrix} \right] &amp;=w^{\mathsf{T}}X+ \left[ \begin{matrix} b &amp; b &amp; b &amp; \cdots &amp; b \end{matrix} \right] \\ &amp;= \underbrace{\left[ \begin{matrix} w^{\mathsf{T}} x^{\left(1\right)} +b &amp; w^{\mathsf{T}} x^{\left(2\right)} +b &amp; w^{\mathsf{T}} x^{\left(3\right)} +b &amp; \cdots &amp; w^{\mathsf{T}} x^{\left(m\right)} +b \end{matrix} \right]}_{1 \times m} \end{aligned}$<br>$\begin{aligned}A= \left[ \begin{matrix} a^{\left(1\right)} &amp; a^{\left(2\right)} &amp; a^{\left(3\right)} &amp; \cdots &amp; a^{\left(m\right)} \end{matrix} \right]  = \sigma \left( Z \right)\end{aligned}$</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Z = np.dot(w.T, X) + b      <span class="comment"># broadcasting</span></span><br></pre></td></tr></table></figure>
<h4 id="Vectorizing-Logistic-Regression’s-Gradient-Output"><a href="#Vectorizing-Logistic-Regression’s-Gradient-Output" class="headerlink" title="Vectorizing Logistic Regression’s Gradient Output"></a>Vectorizing Logistic Regression’s Gradient Output</h4><p>$ dz^{\left(i\right)} = a^{\left(i\right)} - y^{\left(i\right)}$</p>
<p>$\begin{aligned}dZ=\left[ \begin{matrix} dz^{\left(1\right)} &amp; dz^{\left(2\right)} &amp; dz^{\left(3\right)} &amp; \cdots &amp; dz^{\left(m\right)} \end{matrix} \right] \end{aligned}$</p>
<p>$\begin{aligned}dZ=Z-Y&amp;=\left[ \begin{matrix} a^{\left(1\right)}-y^{\left(1\right)} &amp; a^{\left(2\right)}-y^{\left(2\right)} &amp; a^{\left(3\right)}-y^{\left(3\right)} &amp; \cdots &amp; a^{\left(m\right)}-y^{\left(m\right)} \end{matrix} \right] \end{aligned}$</p>
<p>$\begin{aligned}db=\dfrac{1}{m} \sum ^{m}_{i=1} dz^{\left(i\right)} \end{aligned}$</p>
<p>$\begin{aligned}dw &amp;=\dfrac{1}{m}\ X\ dZ^{\mathsf{T}}  \\ &amp;= \dfrac{1}{m} \left[ \begin{matrix} \Big| &amp; \Big| &amp; \Big| &amp; &amp; \Big| \\ x^{\left(1\right)} &amp; x^{\left(2\right)} &amp; x^{\left(3\right)} &amp; \cdots &amp; x^{\left(m\right)} \\ \Big| &amp; \Big| &amp; \Big| &amp; &amp; \Big| \end{matrix} \right] \left[ \begin{matrix} dz^{\left(1\right)} \\ dz^{\left(2\right)} \\ \vdots \\ dz^{\left(m\right)} \end{matrix} \right] \\&amp;= \dfrac{1}{m}\underbrace{ \left[ \begin{matrix} x^{\left(1\right)}dz^{\left(1\right)} + x^{\left(2\right)}dz^{\left(2\right)} + x^{\left(3\right)}dz^{\left(3\right)} + \dots + x^{\left(m\right)}dz^{\left(m\right)} \end{matrix} \right] }_{n\times1} \end{aligned}$</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dZ = A - Y</span><br><span class="line">db = np.<span class="built_in">sum</span>(dZ) / m</span><br><span class="line">dw = np.dot(X, dZ.T) / m</span><br></pre></td></tr></table></figure>
<h5 id="Algorithm-vectorized"><a href="#Algorithm-vectorized" class="headerlink" title="Algorithm (vectorized)"></a>Algorithm <em>(vectorized)</em></h5><p>$\begin{aligned} &amp; Z = w^{\mathsf{T}}X + b \\&amp; A = \sigma\left(Z\right) \\&amp; dZ = A -Y\end{aligned}$</p>
<p>$\begin{aligned}&amp;dw =\dfrac{1}{m}\ X\ dZ^{\mathsf{T}} \\&amp; db=\dfrac{1}{m} \sum ^{m}_{i=1} dz^{\left(i\right)}\end{aligned}$</p>
<p>$\begin{aligned}&amp;w := w -\alpha \cdot dw \\&amp; b :=b-\alpha \cdot db\end{aligned}$</p>
<p><em>still need a for loop to have iterations of gradient descent</em></p>
<h4 id="Explanation-of-Logistic-Regression-Cost-Function"><a href="#Explanation-of-Logistic-Regression-Cost-Function" class="headerlink" title="Explanation of Logistic Regression Cost Function"></a>Explanation of Logistic Regression Cost Function</h4><p><strong><em>maximize:</em></strong> $\begin{aligned}\hat{y} = P\left(y=1\ |\ x\right)\end{aligned}$</p>
<p>&emsp;&emsp;$\begin{aligned}\hat{y}= \sigma\left( w^{\mathsf{T}}x+b \right) \qquad \sigma\left( z \right)={\rm sigmoid}\left(z\right) = \dfrac{1} {1 + e^{-z}}\end{aligned}$</p>
<p>&emsp;&emsp;$\begin{aligned}\begin{cases} p\left(y|x\right) = \hat{y} \quad &amp;{\rm if} \ \  y=1 \\ p\left(y|x\right) = 1- \hat{y} \quad &amp;{\rm if} \ \  y=0 \end{cases} \quad \Longrightarrow \quad p\left(y|x\right) = \hat{y}^y \left(1-\hat{y}\right)^{1-y} \end{aligned}$</p>
<p>&emsp;&emsp;$\begin{aligned}\log p\left(y|x\right) = \log\left( \hat{y}^y \left(1-\hat{y}\right)^{1-y}\right) =y\log\hat{y} +\left(1-y\right) \log\left(1-\hat{y}\right) \end{aligned}$</p>
<p><strong><em>minimize:</em></strong> $\begin{aligned}L\left(\hat{y},\,y\right)=-\left( y\log\hat{y} +\left(1-y\right) \log\left(1-\hat{y}\right) \right)\end{aligned}$</p>
<p>&emsp;&emsp;$\begin{aligned} p\left({\rm labels\ in\ training\ set}\right) = \prod_{i=1}^{m} p\left(y^{\left(i\right)}|x^{\left(i\right)}\right)\end{aligned}$</p>
<p>&emsp;&emsp;$\begin{aligned} \log p\left({\rm labels\ in\ training\ set}\right) &amp;= \log \left( \prod_{i=1}^{m} p\left(y^{\left(i\right)}|x^{\left(i\right)}\right) \right) \\ &amp;= \sum_{i=1}^{m} \log\left(p\left(y^{\left(i\right)}|x^{\left(i\right)}\right)\right) \\ &amp;= -\sum_{i=1}^{m}L\left(\hat{y}^{\left(i\right)},\,y^{\left(i\right)}\right) \end{aligned}$</p>
<p><strong><em>minimize:</em></strong> $\begin{aligned} J\left(w,\,b\right)= \dfrac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{\left(i\right)},\,y^{\left(i\right)}\right)\end{aligned}$</p>
<h3 id="Programming-Assignments"><a href="#Programming-Assignments" class="headerlink" title="Programming Assignments"></a>Programming Assignments</h3><h4 id="Python-Basics-with-numpy"><a href="#Python-Basics-with-numpy" class="headerlink" title="Python Basics with numpy"></a>Python Basics with numpy</h4><h4 id="Logistic-Regression-with-a-Neural-Network-mindset"><a href="#Logistic-Regression-with-a-Neural-Network-mindset" class="headerlink" title="Logistic Regression with a Neural Network mindset"></a>Logistic Regression with a Neural Network mindset</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-2/i.png" alt="example"></p>
<p><a href="https://github.com/bugstop/coursera-deep-learning-solutions" target="_blank">Solutions Manual</a></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (3) · Shallow Neural Networks</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-3/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course A<br><strong>Neural Networks and Deep Learning</strong> by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 3:</em></strong> <em>Shallow Neural Networks</em></p>
<ol>
<li>Understand hidden units and hidden layers</li>
<li>Be able to apply a variety of activation functions in a neural network.</li>
<li>Build your first forward and backward propagation with a hidden layer</li>
<li>Apply random initialization to your neural network</li>
<li>Become fluent with Deep Learning notations and Neural Network Representations</li>
<li>Build and train a neural network with one hidden layer.</li>
</ol>
<a id="more"></a>
<h3 id="Shallow-Neural-Network"><a href="#Shallow-Neural-Network" class="headerlink" title="Shallow Neural Network"></a>Shallow Neural Network</h3><h4 id="Neural-Networks-Overview"><a href="#Neural-Networks-Overview" class="headerlink" title="Neural Networks Overview"></a>Neural Networks Overview</h4><ul>
<li><strong><em>n<sup>(i)</sup>:</em></strong> training samples</li>
<li><strong><em>n<sup>[i]</sup>:</em></strong> layers</li>
</ul>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-3/intro.png" alt="overview"></p>
<h4 id="Neural-Network-Representation"><a href="#Neural-Network-Representation" class="headerlink" title="Neural Network Representation"></a>Neural Network Representation</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-3/layer.png" alt="overview"></p>
<p><strong>2 Layer Neural Network</strong></p>
<p>$a^\left[0\right] = x = \left[ \begin{matrix} x_1 \\ x_2 \\ x_3 \end{matrix} \right] \qquad \underbrace{ a^\left[1\right] = \left[ \begin{matrix} a^\left[1\right]_1 \\ \vdots  \\ a^\left[2\right]_4 \end{matrix} \right] }_{w^\left[1\right]\in\mathbb{R}^{4 \times3}\\b^\left[1\right]\in\mathbb{R}^{4\times1}} \qquad \underbrace{ a^\left[2\right] = \hat{y}}_{w^\left[2\right]\in\mathbb{R}^{1\times4}\\b^\left[2\right]\in\mathbb{R}^{1\times1}}$</p>
<h4 id="Computing-a-Neural-Network’s-Output"><a href="#Computing-a-Neural-Network’s-Output" class="headerlink" title="Computing a Neural Network’s Output"></a>Computing a Neural Network’s Output</h4><p>$\begin{cases} z^\left[1\right]_1 = {w^\left[1\right]_1 }^{\mathsf{T}} x + b^\left[1\right]_1 \qquad &amp; a^\left[1\right]_1 = \sigma \left(z^\left[1\right]_1 \right) \\ z^\left[1\right]_2 = {w^\left[1\right]_2 }^{\mathsf{T}} x + b^\left[1\right]_2 \qquad &amp; a^\left[1\right]_2 = \sigma \left(z^\left[1\right]_2 \right) \\ z^\left[1\right]_3 = {w^\left[1\right]_3 }^{\mathsf{T}} x + b^\left[1\right]_3 \qquad &amp; a^\left[1\right]_3 = \sigma \left(z^\left[1\right]_3 \right) \\ z^\left[1\right]_4 = {w^\left[1\right]_4 }^{\mathsf{T}} x + b^\left[1\right]_4 \qquad &amp; a^\left[1\right]_4 = \sigma \left(z^\left[1\right]_4 \right) \end{cases}$</p>
<h5 id="vectorized"><a href="#vectorized" class="headerlink" title="vectorized"></a>vectorized</h5><p>$z^\left[1\right] = {\overbrace{\left[ \begin{matrix}  \rule{15pt}{0.4pt} \ {w^\left[1\right]_1}^{\mathsf{T}} \ \rule{15pt}{0.4pt} \\ \rule{15pt}{0.4pt} \ {w^\left[1\right]_2}^{\mathsf{T}} \ \rule{15pt}{0.4pt}  \\ \rule{15pt}{0.4pt} \ {w^\left[1\right]_3}^{\mathsf{T}} \ \rule{15pt}{0.4pt} \\ \rule{15pt}{0.4pt} \ {w^\left[1\right]_4}^{\mathsf{T}} \ \rule{15pt}{0.4pt} \end{matrix} \right]}^{W^\left[1\right]}}_{4\times3} \left[ \begin{matrix} x_1 \\ x_2  \\ x_3 \end{matrix} \right] + {\overbrace{ \left[ \begin{matrix} b^\left[1\right]_1 \\ b^\left[1\right]_2 \\ b^\left[1\right]_3 \\ b^\left[1\right]_4 \end{matrix} \right]}^{b^\left[1\right]}}_{4\times1} = \left[ \begin{matrix} {w^\left[1\right]_1 }^{\mathsf{T}} x + b^\left[1\right]_1 \\ {w^\left[1\right]_2 }^{\mathsf{T}} x + b^\left[1\right]_2 \\ {w^\left[1\right]_3 }^{\mathsf{T}} x + b^\left[1\right]_3 \\ {w^\left[1\right]_4 }^{\mathsf{T}} x + b^\left[1\right]_4 \end{matrix} \right] = \left[ \begin{matrix} z^\left[1\right]_1 \\ z^\left[1\right]_2 \\ z^\left[1\right]_3 \\ z^\left[1\right]_4 \end{matrix} \right]$</p>
<p>$a^\left[1\right] = = \left[ \begin{matrix} a^\left[1\right]_1 \\ a^\left[1\right]_2 \\ a^\left[1\right]_3 \\ a^\left[1\right]_4 \end{matrix} \right] = \sigma \left(z^\left[1\right] \right)$</p>
<p>$\begin{cases}  z^\left[1\right] = W^\left[1\right] a^\left[0\right]  + b^\left[1\right] \qquad &amp; a^\left[1\right] = \sigma \left(z^\left[1\right] \right) \qquad &amp; {\rm hidden\ layer} \\ z^\left[2\right] = W^\left[2\right] a^\left[1\right]  + b^\left[2\right] \qquad \hat{y} =&amp;a^\left[2\right] = \sigma \left(z^\left[2\right] \right) \qquad &amp; {\rm output\ layer} \end{cases}$</p>
<h4 id="Vectorizing-across-Multiple-Examples"><a href="#Vectorizing-across-Multiple-Examples" class="headerlink" title="Vectorizing across Multiple Examples"></a>Vectorizing across Multiple Examples</h4><p>For $i=1$ to $m$<br><br>&emsp;&emsp;$z^{\left[1\right]\left(i\right)} = W^\left[1\right] x^{\left(i\right)} + b^\left[1\right]$<br><br>&emsp;&emsp;$a^{\left[1\right]\left(i\right)} = \sigma \left(z^{\left[1\right]\left(i\right)} \right)$<br><br>&emsp;&emsp;$z^{\left[2\right]\left(i\right)} = W^\left[2\right] a^{\left[1\right]\left(i\right)}  + b^\left[2\right]$<br><br>&emsp;&emsp;$a^{\left[2\right]\left(i\right)} = \sigma \left(z^{\left[2\right]\left(i\right)} \right)$</p>
<h5 id="vectorized-1"><a href="#vectorized-1" class="headerlink" title="vectorized"></a>vectorized</h5><p>$X = \left[ \begin{matrix} \Big| &amp; \Big| &amp; \Big| &amp; &amp; \Big| \\ x^{\left(1\right)} &amp; x^{\left(2\right)} &amp; x^{\left(3\right)} &amp; \cdots &amp; x^{\left(m\right)} \\ \Big| &amp; \Big| &amp; \Big| &amp; &amp; \Big| \end{matrix} \right]  \qquad X\in\mathbb{R}^{n_x \times m}$</p>
<p>$Z^{\left[1\right]} = \left[ \begin{matrix} \Big| &amp; \Big| &amp; &amp; \Big| \\ z^{\left[1\right]\left(1\right)} &amp; z^{\left[1\right]\left(2\right)} &amp; \cdots &amp; z^{\left[1\right]\left(m\right)} \\ \Big|  &amp; \Big| &amp; &amp; \Big| \end{matrix} \right]  \qquad Z^{\left[1\right]} \in\mathbb{R}^{n_{\rm units} \times m}$</p>
<p>$A^{\left[1\right]} = \left[ \begin{matrix} \Big| &amp; \Big| &amp; &amp; \Big| \\ a^{\left[1\right]\left(1\right)} &amp; a^{\left[1\right]\left(2\right)} &amp; \cdots &amp; a^{\left[1\right]\left(m\right)} \\ \Big|  &amp; \Big| &amp; &amp; \Big| \end{matrix} \right]  \qquad A^{\left[1\right]} \in\mathbb{R}^{n_{\rm units} \times m}$</p>
<p>$\begin{cases}\begin{aligned} &amp; Z^\left[1\right] = W^\left[1\right] X + b^\left[1\right] \\ &amp; A^\left[1\right] = g^\left[1\right] \left(Z^\left[1\right] \right) \\ &amp; Z^\left[2\right] = W^\left[2\right] A^\left[1\right]  + b^\left[2\right] \\ &amp; A^\left[2\right] = g^\left[2\right] \left(Z^\left[2\right] \right) \end{aligned}\end{cases}$</p>
<h4 id="Activation-Functions"><a href="#Activation-Functions" class="headerlink" title="Activation Functions"></a>Activation Functions</h4><ul>
<li><p><strong><em>sigmoid:</em></strong> $a= \sigma \left(z\right) = \dfrac{1}{1+e^{-z}}$</p>
</li>
<li><p><strong><em>hyperbolic tangent:</em></strong> $a = \tanh\left(z\right) = \dfrac{e^z-e^{-z}}{e^z+e^{-z}}$&emsp;&emsp;zero mean<br><strong>hyperbolic tangent</strong> is almost always <strong><em>strictly</em> superior</strong> than <strong>sigmoid</strong> activation function except for the <strong>output layer</strong> of a <strong>binary classification</strong></p>
</li>
<li><p><strong><em>rectified linear unit:</em></strong> $a= {\rm ReLU} \left(z\right) = \max\left(0,\,z\right)$&emsp;&emsp;derivative &gt;&gt; 0<br><strong>default,</strong> most commonly used</p>
</li>
<li><p><strong><em>leaky ReLU:</em></strong> $a= {\rm LeakyReLU} \left(z\right) = \max\left(\epsilon z,\,z\right), \quad \epsilon \ll 1,\ \sim 0.01 ^{\rm \ learning\ rate}$</p>
</li>
</ul>
<h4 id="Why-Need-Non-Linear-Activation-Functions"><a href="#Why-Need-Non-Linear-Activation-Functions" class="headerlink" title="Why Need Non-Linear Activation Functions"></a>Why Need Non-Linear Activation Functions</h4><p>if use linear activation functions (identity activation functions)</p>
<p>$\begin{aligned}a^\left[1\right]=z^\left[1\right]&amp;=W^\left[1\right]x+b^\left[1\right]\\a^\left[2\right]=z^\left[2\right]&amp;=W^\left[2\right]a^\left[1\right]+b^\left[2\right]\\&amp;=W^\left[2\right]\left(W^\left[1\right]x+b^\left[1\right]\right)+b^\left[2\right]\\&amp;=\left(W^\left[2\right]W^\left[1\right]\right)x+\left(W^\left[2\right]b^\left[1\right]+b^\left[2\right]\right)\\&amp;=W^\star x+b^\star\end{aligned}$</p>
<p>$a^\left[i\right]$ is <strong><em>always linear</em></strong></p>
<p><strong>do <em>not</em></strong> use <strong>linear activation function</strong> except for the <strong>output layer</strong> of a <strong>regression</strong> problem</p>
<h4 id="Derivatives-of-Activation-Functions"><a href="#Derivatives-of-Activation-Functions" class="headerlink" title="Derivatives of Activation Functions"></a>Derivatives of Activation Functions</h4><h5 id="Sigmoid-activation-functions"><a href="#Sigmoid-activation-functions" class="headerlink" title="Sigmoid activation functions"></a>Sigmoid activation functions</h5><p>$g\left(z\right) = \sigma \left(z\right) = \dfrac{1}{1+e^{-z}}$</p>
<p>$g’ \left(z\right) = \dfrac{d}{dz} g\left(z\right) = \dfrac{1}{1+e^{-z}}\left(1-\dfrac{1}{1+e^{-z}}\right) = \underbrace{ g\left(z\right)\left(1-g\left(z\right)\right)} _{=\,a\,\left(1-a\right)}$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-3/q5f2.png" alt="sigmoid"></p>
<h5 id="Hyperbolic-tangent-activation-functions"><a href="#Hyperbolic-tangent-activation-functions" class="headerlink" title="Hyperbolic tangent activation functions"></a>Hyperbolic tangent activation functions</h5><p>$g\left(z\right) = \tanh\left(z\right) = \dfrac{e^z-e^{-z}}{e^z+e^{-z}}$</p>
<p>$g’ \left(z\right) = \dfrac{d}{dz} g\left(z\right) = 1-\left( \tanh\left(z\right)\right)^2  = \underbrace{ 1-g^2 \left(z\right)} _{=\,1\,-\,a^2}$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-3/q5f1.png" alt="tanh"></p>
<h5 id="ReLU-activation-functions"><a href="#ReLU-activation-functions" class="headerlink" title="ReLU activation functions"></a>ReLU activation functions</h5><p>$g\left(z\right) =  {\rm ReLU} \left(z\right) = \max\left(0,\,z\right)$</p>
<p>$g’ \left(z\right) = \dfrac{d}{dz} g\left(z\right) = \begin{cases}0 \qquad {\rm if}\ \ z &lt; 0 \\ 1 \qquad {\rm if}\ \ z \geq 0 \end{cases}$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-3/q5f3.png" alt="relu"></p>
<h5 id="Leaky-ReLU-activation-functions"><a href="#Leaky-ReLU-activation-functions" class="headerlink" title="Leaky-ReLU activation functions"></a>Leaky-ReLU activation functions</h5><p>$g\left(z\right) = {\rm LeakyReLU} \left(z\right) = \max\left(\epsilon z,\,z\right)$</p>
<p>$g’ \left(z\right) = \dfrac{d}{dz} g\left(z\right) = \begin{cases}\epsilon \qquad {\rm if}\ \ z &lt; 0 \\ 1 \qquad {\rm if}\ \ z \geq 0 \end{cases}$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-3/q5f4.png" alt="lrelu"></p>
<h4 id="Gradient-Descent-for-Neural-Networks"><a href="#Gradient-Descent-for-Neural-Networks" class="headerlink" title="Gradient Descent for Neural Networks"></a>Gradient Descent for Neural Networks</h4><ul>
<li><strong><em>Parameters:</em></strong> ${W^\left[1\right]}_{n^\left[1\right] \times n^\left[0\right]},\ {b^\left[1\right]}_{n^\left[1\right] \times 1},\ {W^\left[2\right]}_{n^\left[2\right] \times n^\left[1\right]},\ {b^\left[2\right]}_{n^\left[2\right] \times 1} \qquad n_x=n^\left[0\right],\ n^\left[1\right],\ n^\left[2\right]=1$</li>
<li><strong><em>Cost Function:</em></strong> $J\left( {W^\left[1\right]},\ {b^\left[1\right]},\ {W^\left[2\right]},\ {b^\left[2\right]} \right) = \dfrac{1}{m} \sum_{i=1}^{m} L( \underbrace{\hat{y}^{\left(i\right)}}_{a^\left[2\right]},\,y^{\left(i\right)})$</li>
</ul>
<p><sup>Gradient Decent</sup> Repeat:<br>&emsp;&emsp;compute predictions $\hat{y}^{\left(i\right)}, \ \ i=1, \,\dots,\,m$<br>&emsp;&emsp;compute derivatives  $dW^\left[1\right]=\dfrac{\partial J}{\partial W^\left[1\right]},\,db^\left[1\right]=\dfrac{\partial J}{\partial b^\left[1\right]},\,\dots$<br>&emsp;&emsp;update $W^\left[1\right]:=W^\left[1\right]-\alpha dW^\left[1\right],\ \ b^\left[1\right]:=b^\left[1\right]-\alpha db^\left[1\right],\,\dots$</p>
<h5 id="Formulas"><a href="#Formulas" class="headerlink" title="Formulas"></a>Formulas</h5><p>$\begin{array}{lc|cl} \textsf{forward propagation} &amp; \ &amp; \quad &amp; \textsf{back propagation} \\ \\ {\begin{cases}\begin{aligned} Z^\left[1\right] &amp;= W^\left[1\right] X + b^\left[1\right] \\ A^\left[1\right] &amp;= g^\left[1\right] \left(Z^\left[1\right] \right) \\ Z^\left[2\right] &amp;= W^\left[2\right] A^\left[1\right]  + b^\left[2\right] \\ A^\left[2\right] &amp;= g^\left[2\right] \left(Z^\left[2\right] \right) \end{aligned}\end{cases}} &amp; &amp; &amp; {\begin{cases}\begin{aligned} dZ^\left[2\right] &amp;= A^\left[2\right] - Y \\ dW^\left[2\right] &amp;= \dfrac{1}{m} dZ^\left[2\right] {A^\left[1\right]}^{\mathsf{T}} \\ db^\left[2\right] &amp;= \dfrac{1}{m} \texttt{np.sum(} dZ^\left[2\right] \texttt{, axis=1, keepdims=True)} \\ dZ^\left[1\right] &amp;= \overbrace{ {W^\left[2\right] }^{\mathsf{T}} dZ^\left[2\right]  }^{\left(n^\left[1\right],\ m\right)} \odot \overbrace{ g’ ^\left[1\right] \left(Z^\left[1\right]\right) }^{\left(n^\left[1\right],\ m\right)}\\ dW^\left[1\right] &amp;= \dfrac{1}{m} dZ^\left[1\right] {X}^{\mathsf{T}} \\ db^\left[1\right] &amp;= \dfrac{1}{m} \texttt{np.sum(} dZ^\left[1\right] \texttt{, axis=1, keepdims=True)} \end{aligned}\end{cases}} \end{array}$</p>
<!--|                     Forward Propagation                      |                       Back Propagation                       |-->
<!--| :----------------------------------------------------------: | :----------------------------------------------------------: |-->
<!--| ${\begin{aligned} Z^\left[1\right] &= W^\left[1\right] X + b^\left[1\right] \\ A^\left[1\right] &= g^\left[1\right] \left(Z^\left[1\right] \right) \\ Z^\left[2\right] &= W^\left[2\right] A^\left[1\right]  + b^\left[2\right] \\ A^\left[2\right] &= g^\left[2\right] \left(Z^\left[2\right] \right) \end{aligned}}$ | $\begin{aligned} dZ^\left[2\right] &= A^\left[2\right] - Y \\ dW^\left[2\right] &= \dfrac{1}{m} dZ^\left[2\right] {A^\left[1\right]}^{\mathsf{T}} \\ db^\left[2\right] &= \dfrac{1}{m} \texttt{np.sum(} dZ^\left[2\right] \texttt{, axis=1, keepdims=True)} \\ dZ^\left[1\right] &= {W^\left[2\right]}^{\mathsf{T}} dZ^\left[2\right]\odot g' ^\left[1\right] \left(Z^\left[1\right]\right)  \\ dW^\left[1\right] &= \dfrac{1}{m} dZ^\left[1\right] {X}^{\mathsf{T}} \\ db^\left[1\right] &= \dfrac{1}{m} \texttt{np.sum(} dZ^\left[1\right] \texttt{, axis=1, keepdims=True)} \end{aligned}$ |-->
<p>&emsp;&emsp;<strong><em>Notice:</em></strong> $\odot$ represents <strong>element-wise</strong> product</p>
<h4 id="Backpropagation-Intuition"><a href="#Backpropagation-Intuition" class="headerlink" title="Backpropagation Intuition"></a>Backpropagation Intuition</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-3/1.png" alt="1"><br><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-3/2.png" alt="2"></p>
<p>$z^\left[1\right] \rightarrow a^\left[1\right] \rightarrow  z^\left[2\right] \rightarrow a^\left[2\right] \rightarrow L$</p>
<p>$dz^\left[2\right]=a^\left[2\right] -y \rightarrow \begin{aligned} dW^\left[2\right] &amp; = dz^\left[2\right] {a^\left[1\right] }^{\mathsf{T}} \\ db^\left[2\right] &amp; = dz^\left[2\right] \end{aligned} \rightarrow  \overbrace{ dz^\left[1\right]  }^{\left(n^\left[1\right],\ 1\right)} = \overbrace{ {W^\left[2\right] }^{\mathsf{T}} dz^\left[2\right]  }^{\left(n^\left[1\right],\ 1\right)}   \odot \overbrace{g’ ^\left[1\right] \left(z^\left[1\right]\right) }^{\left(n^\left[1\right],\ 1\right)}  \rightarrow \begin{aligned} dW^\left[2\right] &amp; = dz^\left[1\right] {x}^{\mathsf{T}} \\ db^\left[1\right] &amp; = dz^\left[1\right] \end{aligned}$</p>
<h5 id="vectorized-2"><a href="#vectorized-2" class="headerlink" title="vectorized"></a>vectorized</h5><p>$dZ^\left[2\right]=A^\left[2\right] -Y \rightarrow \begin{aligned} dW^\left[2\right] &amp; = \dfrac{1}{m} dZ^\left[2\right] {A^\left[1\right] }^{\mathsf{T}} \\ db^\left[2\right] &amp; = \dfrac{1}{m} \texttt{np.sum(}\,  dZ^\left[2\right] \,\texttt{…)}\end{aligned} $<br>&emsp;&emsp;$\rightarrow \overbrace{ dZ^\left[1\right] }^{\left(n^\left[1\right],\ m\right)}  = \overbrace{ {W^\left[2\right] }^{\mathsf{T}} dZ^\left[2\right]  }^{\left(n^\left[1\right],\ m\right)} \odot \overbrace{ g’ ^\left[1\right] \left(Z^\left[1\right]\right) }^{\left(n^\left[1\right],\ m\right)}  \rightarrow \begin{aligned} dW^\left[2\right] &amp; = dZ^\left[1\right] {X}^{\mathsf{T}} \\ db^\left[1\right] &amp; = \dfrac{1}{m} \texttt{np.sum(}\, dZ^\left[1\right]  \,\texttt{…)} \end{aligned}$</p>
<h4 id="Random-Initialization"><a href="#Random-Initialization" class="headerlink" title="Random Initialization"></a>Random Initialization</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-3/i.png" alt="init"></p>
<h5 id="Zero-initialization"><a href="#Zero-initialization" class="headerlink" title="Zero initialization"></a>Zero initialization</h5><p>$\begin{aligned}W^\left[1\right] &amp;= \left[ \begin{matrix} 0 &amp; 0 \\ 0 &amp; 0 \end{matrix} \right]\\ W^\left[2\right] &amp;= \left[ \begin{matrix} 0 &amp; 0 \end{matrix} \right] \end{aligned} \Rightarrow a^\left[1\right]_1 = a^\left[1\right]_2 \Rightarrow dz^\left[1\right]_1 = dz^\left[1\right]_2 \Rightarrow W^\left[1\right] = \left[ \begin{matrix} a &amp; b \\ a &amp; b \end{matrix} \right]  \Rightarrow \cdots \Rightarrow W^\left[1\right] = \left[ \begin{matrix} a’ &amp; b’ \\ a’ &amp; b’ \end{matrix} \right] $</p>
<p>&emsp;&emsp;get <strong>all hidden units</strong> computing exactly <strong><em>same</em></strong> function</p>
<h5 id="Random-initialization"><a href="#Random-initialization" class="headerlink" title="Random initialization"></a>Random initialization</h5><p>$ \begin{aligned} W^\left[1\right] &amp;= \texttt{np.random.rand((2, 2)) }\star\texttt{ 0.01} \\ b^\left[1\right] &amp;= \texttt{np.zeros((2, 1))} \\ W^\left[2\right] &amp;= \texttt{np.random.rand((1, 2)) }\star\texttt{ 0.01} \\ b^\left[2\right] &amp;= \texttt{0} \end{aligned}$</p>
<p><strong>why <code>* 0.01</code> in shallow neural network</strong></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-3/w.png" alt="init"></p>
<h3 id="Programming-Assignments"><a href="#Programming-Assignments" class="headerlink" title="Programming Assignments"></a>Programming Assignments</h3><h4 id="Planar-Data-Classification-with-a-Hidden-Layer"><a href="#Planar-Data-Classification-with-a-Hidden-Layer" class="headerlink" title="Planar Data Classification with a Hidden Layer"></a>Planar Data Classification with a Hidden Layer</h4><p><a href="https://github.com/bugstop/coursera-deep-learning-solutions" target="_blank">Solutions Manual</a></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (4) · Deep Neural Networks</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-4/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course A<br><strong>Neural Networks and Deep Learning</strong> by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 4:</em></strong> <em>Deep Neural Networks</em></p>
<ol>
<li>See deep neural networks as successive blocks put one after each other</li>
<li>Build and train a deep L-layer Neural Network</li>
<li>Analyze matrix and vector dimensions to check neural network implementations.</li>
<li>Understand how to use a cache to pass information from forward propagation to back propagation.</li>
<li>Understand the role of hyperparameters in deep learning</li>
</ol>
<a id="more"></a>
<h3 id="Deep-Neural-Network"><a href="#Deep-Neural-Network" class="headerlink" title="Deep Neural Network"></a>Deep Neural Network</h3><h4 id="Deep-L-Layer-neural-network"><a href="#Deep-L-Layer-neural-network" class="headerlink" title="Deep L-Layer neural network"></a>Deep L-Layer neural network</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-4/l.png" alt="L"></p>
<ul>
<li><strong><em>L:</em></strong> number of layers</li>
<li><strong><em>n<sup>[l]</sup>:</em></strong> number of units in layer l</li>
<li><strong><em>a<sup>[l]</sup> = g<sup>[l]</sup>(z<sup>[l]</sup>):</em></strong> activations in layer l</li>
<li><strong><em>W<sup>[l]</sup>:</em></strong> weights for z<sup>[l]</sup></li>
<li><strong><em>b<sup>[l]</sup>:</em></strong> biases for z<sup>[l]</sup></li>
</ul>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-4/4.png" alt="L=4"></p>
<p>$n^{\left[0\right]} = n_x = 3, \ n^{\left[1\right]} = 5, \ n^{\left[2\right]} = 5, \ n^{\left[3\right]} = 3, \ n^{\left[4\right]} = n^{\left[L\right]} = 1 $</p>
<h4 id="Forward-Propagation-in-a-Deep-Network"><a href="#Forward-Propagation-in-a-Deep-Network" class="headerlink" title="Forward Propagation in a Deep Network"></a>Forward Propagation in a Deep Network</h4><p>$\begin{matrix} \begin{aligned} x&amp;=a^{\left[0\right]} \\ z^{\left[1\right]}&amp;=W^{\left[1\right]}a^{\left[0\right]}+b^{\left[1\right]} \\ a^{\left[1\right]}&amp;=g^{\left[1\right]}\left(z^{\left[1\right]}\right) \end{aligned} &amp; \begin{aligned} z^{\left[2\right]}&amp;=W^{\left[2\right]}a^{\left[1\right]}+b^{\left[2\right]} \\ a^{\left[2\right]}&amp;=g^{\left[2\right]}\left(z^{\left[2\right]}\right) \end{aligned} &amp; \begin{aligned} z^{\left[3\right]}&amp;=W^{\left[3\right]}a^{\left[2\right]}+b^{\left[3\right]} \\ a^{\left[3\right]}&amp;=g^{\left[3\right]}\left(z^{\left[3\right]}\right) \end{aligned} &amp; \begin{aligned} z^{\left[4\right]}&amp;=W^{\left[4\right]}a^{\left[3\right]}+b^{\left[4\right]} \\ a^{\left[4\right]}&amp;=g^{\left[4\right]}\left(z^{\left[4\right]}\right) \\ \hat{y}&amp;=a^{\left[4\right]} \end{aligned} \end{matrix}$</p>
<p>$\Rightarrow \begin{cases} \begin{aligned} z^{\left[l\right]}&amp;=W^{\left[l\right]}a^{\left[l-1\right]}+b^{\left[l\right]} \\ a^{\left[l\right]}&amp;=g^{\left[l\right]}\left(z^{\left[l\right]}\right) \end{aligned} \qquad \texttt{for l = 1, 2, …, L} \end{cases}$</p>
<h5 id="vectorized"><a href="#vectorized" class="headerlink" title="vectorized"></a>vectorized</h5><p>$\begin{matrix} \begin{aligned} X&amp;=A^{\left[0\right]} \\ Z^{\left[1\right]}&amp;=W^{\left[1\right]}A^{\left[0\right]}+b^{\left[1\right]} \\ A^{\left[1\right]}&amp;=g^{\left[1\right]}\left(Z^{\left[1\right]}\right) \end{aligned} &amp; \begin{aligned} Z^{\left[2\right]}&amp;=W^{\left[2\right]}A^{\left[1\right]}+b^{\left[2\right]} \\ A^{\left[2\right]}&amp;=g^{\left[2\right]}\left(Z^{\left[2\right]}\right) \end{aligned} &amp; \begin{aligned} Z^{\left[3\right]}&amp;=W^{\left[3\right]}A^{\left[2\right]}+b^{\left[3\right]} \\ A^{\left[3\right]}&amp;=g^{\left[3\right]}\left(Z^{\left[3\right]}\right) \end{aligned} &amp; \begin{aligned} Z^{\left[4\right]}&amp;=W^{\left[4\right]}A^{\left[3\right]}+b^{\left[4\right]} \\ A^{\left[4\right]}&amp;=g^{\left[4\right]}\left(Z^{\left[4\right]}\right) \\ \hat{Y}&amp;=A^{\left[4\right]} \end{aligned} \end{matrix}$</p>
<p>$\Rightarrow \begin{cases} \begin{aligned} Z^{\left[l\right]}&amp;=W^{\left[l\right]}A^{\left[l-1\right]}+b^{\left[l\right]} \\ A^{\left[l\right]}&amp;=g^{\left[l\right]}\left(Z^{\left[l\right]}\right) \end{aligned} \qquad \texttt{for l = 1, 2, …, L} \end{cases}$</p>
<h4 id="Getting-Your-Matrix-Dimensions-Right"><a href="#Getting-Your-Matrix-Dimensions-Right" class="headerlink" title="Getting Your Matrix Dimensions Right"></a>Getting Your Matrix Dimensions Right</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-4/5.png" alt="L=5"></p>
<p>$n_x=n^{\left[0\right]} = 2, \ n^{\left[1\right]} = 3, \ n^{\left[2\right]} = 5, \ n^{\left[3\right]} = 4, \ n^{\left[4\right]} = 2, \ n^{\left[5\right]} = 1 \ $</p>
<p>$\left. \begin{aligned} \overbrace{ z^{\left[1\right]} }^{n^{\left[1\right]} \times 1  \\ =3\times1} = \overbrace{ W^{\left[1\right]} }^{n^{\left[1\right]} \times n^{\left[0\right]} \\ =3\times2} \cdot \overbrace{ x\strut }^{n^{\left[0\right]} \times 1 \\ =2\times1} + \overbrace{ b^{\left[1\right]} }^{n^{\left[1\right]} \times 1  \\ =3\times1} \\ \underbrace{ Z^{\left[1\right]} }_{n^{\left[1\right]} \times m} = \underbrace{ W^{\left[1\right]} }_{n^{\left[1\right]} \times n^{\left[0\right]}} \cdot \underbrace{ X }_{n^{\left[0\right]} \times m} + \underbrace{ b^{\left[1\right]} }_{n^{\left[1\right]} \times 1} \end{aligned} \ \ \right\} \quad\Rightarrow\quad \begin{cases} \begin{aligned} Z^{\left[l\right]}&amp;:\ \left(n^{\left[l\right]} ,\, m\right) \\ A^{\left[l\right]}&amp;:\ \left(n^{\left[l\right]} ,\, m\right) \\ dZ^{\left[l\right]}&amp;:\ \left(n^{\left[l\right]} ,\, m\right) \\ dA^{\left[l\right]}&amp;:\ \left(n^{\left[l\right]} ,\, m\right) \end{aligned} \end{cases} \,,\quad \begin{cases} \begin{aligned} W^{\left[l\right]}&amp;:\ \left(n^{\left[l\right]} ,\, n^{\left[l-1\right]}\right) \\ b^{\left[l\right]}&amp;:\ \left(n^{\left[l\right]} ,\, 1\right) \,{}_\texttt{broadcasting} \\ dW^{\left[l\right]}&amp;:\ \left(n^{\left[l\right]} ,\, n^{\left[l-1\right]}\right) \\ db^{\left[l\right]}&amp;:\ \left(n^{\left[l\right]} ,\, 1\right) \,{}_\texttt{broadcasting} \end{aligned} \end{cases}$</p>
<h4 id="Building-Blocks-of-Deep-Neural-Networks"><a href="#Building-Blocks-of-Deep-Neural-Networks" class="headerlink" title="Building Blocks of Deep Neural Networks"></a>Building Blocks of Deep Neural Networks</h4><p><strong>one layer</strong></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-4/b.png" alt="one layer"></p>
<p><strong>one iteration</strong></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-4/bl.png" alt="one iteration"></p>
<h4 id="Forward-and-Backward-Propagation"><a href="#Forward-and-Backward-Propagation" class="headerlink" title="Forward and Backward Propagation"></a>Forward and Backward Propagation</h4><h5 id="Forward-Propagation"><a href="#Forward-Propagation" class="headerlink" title="Forward Propagation"></a>Forward Propagation</h5><ul>
<li>input a<sup>[l-1]</sup></li>
<li>output a<sup>[l]</sup>, cache z<sup>[l]</sup>, (W<sup>[l]</sup>, b<sup>[l]</sup>)</li>
</ul>
<p>$\begin{array}{lc|cl} {}^\textsf{Forward Propagation} &amp; &amp; &amp; \textsf{vectorized}_\strut \\ {\begin{cases}\begin{aligned} z^\left[l\right] &amp;= W^\left[l\right] a^\left[l-1\right] + b^\left[l\right] \\ a^\left[l\right] &amp;= g^\left[l\right] \left(z^\left[l\right] \right) \end{aligned}\end{cases}} &amp; &amp; &amp; {\begin{cases}\begin{aligned} Z^\left[l\right] &amp;= W^\left[l\right] A^\left[l-1\right] + b^\left[l\right] \\ A^\left[l\right] &amp;= g^\left[l\right] \left(Z^\left[l\right] \right)\end{aligned}\end{cases}} \end{array}$</p>
<h5 id="Backward-Propagation"><a href="#Backward-Propagation" class="headerlink" title="Backward Propagation"></a>Backward Propagation</h5><ul>
<li>input da<sup>[l]</sup></li>
<li>output da<sup>[l-1]</sup>, dW<sup>[l]</sup>, db<sup>[l]</sup>)</li>
</ul>
<p>$\begin{array}{lc|cl} {}^\textsf{Backward Propagation} &amp; &amp; &amp; \textsf{vectorized}_\strut \\ {\begin{cases}\begin{aligned} dz^\left[l\right] &amp;= da^\left[l\right] \odot {g^\left[l\right]}’ \left(z^\left[l\right] \right) \\ dW^\left[l\right] &amp;= dz^\left[l\right] { a^\left[l-1\right] }^{\mathsf{T}} \\ db^\left[l\right] &amp;= dz^\left[l\right] \\ da^\left[l-1\right] &amp;= { W^\left[l\right] }^{\mathsf{T}} dz^\left[l\right] \end{aligned}\end{cases}} &amp; &amp; &amp; {\begin{cases}\begin{aligned} dZ^\left[l\right] &amp;= dA^\left[l\right] \odot {g^\left[l\right]}’ \left(Z^\left[l\right] \right) \\ dW^\left[l\right] &amp;= \dfrac{1}{m} dZ^\left[l\right] { A^\left[l-1\right] }^{\mathsf{T}} \\ db^\left[l\right] &amp;= \dfrac{1}{m} \texttt{np.sum(} dZ^\left[l\right] \texttt{, axis=1, keepdims=True)} \\ dA^\left[l-1\right] &amp;= { W^\left[l\right] }^{\mathsf{T}} dZ^\left[l\right] \end{aligned}\end{cases}} \end{array}$</p>
<p><strong>initialize</strong></p>
<p>$\begin{aligned} a^\left[0\right] &amp;= x \qquad &amp; A^\left[0\right] &amp;= X \\ da^\left[L\right] &amp;= - \dfrac{y}{a} + \dfrac{1-y}{1-a} \qquad &amp; dA^\left[L\right] &amp;= \sum_{i=1}^{m} \left(- \dfrac{y ^\left(i\right)}{a ^\left(i\right)} + \dfrac{1-y ^\left(i\right)}{1-a ^\left(i\right)}\right) \end{aligned}$</p>
<h4 id="Parameters-vs-Hyperparameters"><a href="#Parameters-vs-Hyperparameters" class="headerlink" title="Parameters vs Hyperparameters"></a>Parameters vs Hyperparameters</h4><ul>
<li><strong>Parameters</strong><ul>
<li>W<sup>[1]</sup>, b<sup>[1]</sup>, W<sup>[2]</sup>, b<sup>[2]</sup>, …</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Hyperparameters</strong><ul>
<li>learning rate α</li>
<li># iterations</li>
<li># hidden layers L</li>
<li># hidden units n<sup>[1]</sup>, n<sup>[2]</sup>, …</li>
<li>activation function</li>
<li>momentum</li>
<li>mini batch size</li>
<li>regularization parameters</li>
</ul>
</li>
</ul>
<h3 id="Programming-Assignments"><a href="#Programming-Assignments" class="headerlink" title="Programming Assignments"></a>Programming Assignments</h3><h4 id="Building-your-Deep-Neural-Network-Step-by-Step"><a href="#Building-your-Deep-Neural-Network-Step-by-Step" class="headerlink" title="Building your Deep Neural Network: Step by Step"></a>Building your Deep Neural Network: Step by Step</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-4/1.png" alt="example"></p>
<h4 id="Deep-Neural-Network-Application"><a href="#Deep-Neural-Network-Application" class="headerlink" title="Deep Neural Network - Application"></a>Deep Neural Network - Application</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-4/2.png" alt="example"></p>
<p><a href="https://github.com/bugstop/coursera-deep-learning-solutions" target="_blank">Solutions Manual</a></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (5) · Practical Aspects of Deep Learning</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-5/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course B<br><strong>Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization</strong><br>by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 1:</em></strong> <em>Practical Aspects of Deep Learning</em></p>
<ol>
<li>Recall that different types of initializations lead to different results</li>
<li>Recognize the importance of initialization in complex neural networks.</li>
<li>Recognize the difference between train/dev/test sets</li>
<li>Diagnose the bias and variance issues in your model</li>
<li>Learn when and how to use regularization methods such as dropout or L2 regularization.</li>
<li>Understand experimental issues in deep learning such as Vanishing or Exploding gradients and learn how to deal with them</li>
<li>Use gradient checking to verify the correctness of your backpropagation implementation</li>
</ol>
<a id="more"></a>
<h3 id="Setting-Up-your-Machine-Learning-Application"><a href="#Setting-Up-your-Machine-Learning-Application" class="headerlink" title="Setting Up your Machine Learning Application"></a>Setting Up your Machine Learning Application</h3><h4 id="Train-Dev-Test-Sets"><a href="#Train-Dev-Test-Sets" class="headerlink" title="Train / Dev / Test Sets"></a>Train / Dev / Test Sets</h4><p>learning rate, # iterations, # hidden units, activation function, …</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-5/tdt.png" alt="set"></p>
<p><strong>Size</strong></p>
<ul>
<li>Previous era: 70%-30% or 60%-20%-20%</li>
<li>Big data era: 98%-1%-1%, smaller dev and test sets</li>
</ul>
<p><strong>Mismatched Distribution</strong></p>
<ul>
<li>make sure dev and test sets come from same distribution</li>
<li>not having a test set might be okay (only dev set)</li>
</ul>
<h4 id="Bias-Variance"><a href="#Bias-Variance" class="headerlink" title="Bias / Variance"></a>Bias / Variance</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-5/c.png" alt="set"></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-5/h.png" alt="set"></p>
<h4 id="Basic-Recipe-for-Machine-Learning"><a href="#Basic-Recipe-for-Machine-Learning" class="headerlink" title="Basic Recipe for Machine Learning"></a>Basic Recipe for Machine Learning</h4><ol>
<li><p><strong>High bias?</strong> (training set performance)</p>
<p>→ bigger network, longer time, (architecture), …</p>
</li>
<li><p><strong>High variance?</strong> (dev set performance)</p>
<p>→ more data, regularization, (architecture), …</p>
</li>
</ol>
<h4 id="Regularizing-your-Neural-Network"><a href="#Regularizing-your-Neural-Network" class="headerlink" title="Regularizing your Neural Network"></a>Regularizing your Neural Network</h4><h4 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h4><h5 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h5><p>$\min_{w,b}J\left(w,b\right) \qquad w \in \mathbb{R}^{n_x}, \ b \in \mathbb{R}$</p>
<p>$\begin{aligned} J\left(w,b\right) = \dfrac{1}{m} \sum_{i=1}^{m} L\left( \hat{y} ^\left(i\right),\, y^\left(i\right) \right) &amp;+ \dfrac{\lambda}{2m} \left|\left| w \right| \right| ^2 \quad \color{lightgray} { \overbrace{ + \dfrac{\lambda}{2m} b^2} ^{\rm omit} }\\ L_2 \textsf{ Regulariztion} \qquad \left|\left| w \right| \right| ^2 &amp;= \sum_{j=1}^{n_x} w_j^2 = w^{\mathsf{T}} w \end{aligned}$</p>
<ul>
<li><strong><em>λ:</em></strong> regularization parameter</li>
</ul>
<h5 id="Neural-Network"><a href="#Neural-Network" class="headerlink" title="Neural Network"></a>Neural Network</h5><p>$\begin{aligned} J\left( W^{\left[1\right]},b^{\left[1\right]}, \dots,W^{\left[L\right]},b^{\left[L\right]}\right) = \dfrac{1}{m} \sum_{i=1}^{m} L &amp; \left( \hat{y} ^\left(i\right),\, y^\left(i\right) \right) + \dfrac{\lambda}{2m} \sum_{l=1}^{L} \left|\left| W^{\left[l\right]} \right| \right| ^2_F \\ \textsf{ Frobenius norm} \qquad \left|\left| W ^{\left[ l \right]} \right| \right| ^2_F &amp;= \sum_{i=1}^{n ^{\left[ l \right]}} \sum_{j=1}^{n ^{\left[ l-1 \right]}} \left( {w_{ij} ^{\left[ l \right]}} \right) ^2 \qquad W \in \mathbb{R}^{n^{\left[ L \right]} \times n^{\left[ L-1 \right]}} \end{aligned}$</p>
<p><strong>Weight Decay</strong></p>
<p>$\begin{aligned} dW^\left[l\right] &amp;= \overbrace{\dfrac{1}{m} \, dZ^\left[l\right] { A^\left[l-1\right] }^{\mathsf{T}}} ^{\textsf{backpropagation}} + \dfrac{\lambda}{m} W^\left[l\right] \\ W^\left[l\right] &amp;= W^\left[l\right] - \alpha\ dW^\left[l\right] = \underbrace{ \left(1 - \dfrac{\alpha \, \lambda}{m} \right) W^\left[l\right]} _{\textsf{weight decay}} - \alpha \left( {\dfrac{1}{m} \, dZ^\left[l\right] { A^\left[l-1\right] }^{\mathsf{T}}} \right) \end{aligned}$</p>
<h4 id="Why-Regularization-Reduces-Overfitting"><a href="#Why-Regularization-Reduces-Overfitting" class="headerlink" title="Why Regularization Reduces Overfitting?"></a>Why Regularization Reduces Overfitting?</h4><ul>
<li>variance reduction<br><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-5/ou.png" alt="1"></li>
<li>g(z) <em>(every layer)</em> is roughly linear<br><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-5/1.png" alt="2"></li>
</ul>
<h4 id="Dropout-Regularization"><a href="#Dropout-Regularization" class="headerlink" title="Dropout Regularization"></a>Dropout Regularization</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-5/d.png" alt="dropout"></p>
<p><strong>Inverted Dropout</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># layer 3</span></span><br><span class="line">keep_prob = <span class="number">0.8</span></span><br><span class="line">d3 = np.random.rand(a3.shape[<span class="number">0</span>], a3.shape[<span class="number">1</span>]) &lt; keep_prob</span><br><span class="line">a3 = a3 * d3</span><br><span class="line">a3 /= keep_prob  <span class="comment"># expected value of a3 remains the same</span></span><br></pre></td></tr></table></figure>
<p><strong><em>Notice:</em></strong> do not use dropout at test time</p>
<h4 id="Understanding-Dropout"><a href="#Understanding-Dropout" class="headerlink" title="Understanding Dropout"></a>Understanding Dropout</h4><p><strong><em>Intuition:</em></strong> can’t rely on any <em>one</em> feature, so have to spread out weights<br><strong>shrink the squared norm of the weights</strong></p>
<h4 id="Other-Regularization-Methods"><a href="#Other-Regularization-Methods" class="headerlink" title="Other Regularization Methods"></a>Other Regularization Methods</h4><ul>
<li>data augmentation</li>
<li>early stopping<br><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-5/s.png" alt="es"><br><strong>Orthorganization</strong><ul>
<li>Optimize cost function $J$</li>
<li>Not overfit</li>
</ul>
</li>
</ul>
<h3 id="Setting-Up-Your-Optimization-Problem"><a href="#Setting-Up-Your-Optimization-Problem" class="headerlink" title="Setting Up Your Optimization Problem"></a>Setting Up Your Optimization Problem</h3><h4 id="Normalizing-Inputs"><a href="#Normalizing-Inputs" class="headerlink" title="Normalizing Inputs"></a>Normalizing Inputs</h4><ol>
<li>subtract mean<br>$x:=x-\mu \qquad \mu= \frac{1}{m} \sum_{i=1}^{m} x^{\left( i \right)}$</li>
<li>normalize variance<br>$x:= x / \sigma \qquad \sigma ^2 = \frac{1}{m} \sum_{i=1}^{m} { x^{\left( i \right)} } ^2$</li>
<li>use same μ, σ<sup>2</sup> to normalize test set<br>$x := \dfrac{x- \mu}{\sigma}$</li>
</ol>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-5/4.png" alt="c"></p>
<h4 id="Vanishing-Exploding-Gradients"><a href="#Vanishing-Exploding-Gradients" class="headerlink" title="Vanishing / Exploding Gradients"></a>Vanishing / Exploding Gradients</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-5/x.png" alt="c"></p>
<p>$W^{\left[1\right]},\ W^{\left[2\right]},\ W^{\left[3\right]},\ \dots, \ W^{\left[L\right]} \qquad {\rm set} \ \ g\left(z\right)=z, \ b^{\left[l\right]} =0$</p>
<p>$\Rightarrow y= W^{\left[L\right]}W^{\left[L-1\right]}W^{\left[L-2\right]}\cdots W^{\left[2\right]}W^{\left[1\right]}x$</p>
<p>$\begin{aligned} {\rm assume} \ \ W^{\left[l\right]}= \left[ \begin{matrix} 1.5&amp;0\\0&amp;1.5 \end{matrix} \right], \qquad \ \ &amp;y= W^{\left[L\right]} \left[ \begin{matrix} 1.5&amp;0\\0&amp;1.5 \end{matrix} \right] ^{L-1} x \quad \sim 1.5^L \\ {\rm assume} \ \ W^{\left[l\right]}= \left[ \begin{matrix} 0.5&amp;0\\0&amp;0.5 \end{matrix} \right], \qquad \ \ &amp;y= W^{\left[L\right]} \left[ \begin{matrix} 0.5&amp;0\\0&amp;0.5 \end{matrix} \right] ^{L-1} x \quad \sim 0.5^L \end{aligned}$</p>
<p><strong>activations</strong> and <strong>gradients</strong> increasing or decreasing <strong><em>exponentially</em></strong> as a function of <strong>L</strong></p>
<h4 id="Weight-Initialization-for-Deep-Networks"><a href="#Weight-Initialization-for-Deep-Networks" class="headerlink" title="Weight Initialization for Deep Networks"></a>Weight Initialization for Deep Networks</h4><h5 id="Single-Neuron"><a href="#Single-Neuron" class="headerlink" title="Single Neuron"></a>Single Neuron</h5><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-5/sn.png" alt="single"></p>
<p>$z= w_1x_1 + w_2x_2 + \dots + w_nx_n \ \ \color{lightgray} {+ b}$</p>
<p>larger n → smaller w<sub>i</sub> $\Rightarrow {\rm Var}\left( w_i \right) = \frac{1}{n} $</p>
<p>$\begin{aligned} {\rm ReLU:} \qquad &amp; W^{\left[l\right]}= \texttt{np.random.randn(shape) * np.sqrt(} \dfrac{2}{n^{\left[l-1\right]}} \texttt{)} \\ {\rm tanh:} \qquad &amp; W^{\left[l\right]}= \texttt{np.random.randn(shape) * np.sqrt(} \dfrac{1}{n^{\left[l-1\right]}} \texttt{)} \\ &amp; W^{\left[l\right]}= \texttt{np.random.randn(shape) * np.sqrt(} \dfrac{2}{n^{\left[l-1\right]} + n^{\left[l\right]}} \texttt{)}  \end{aligned}$</p>
<h4 id="Numerical-Approximation-of-Gradients"><a href="#Numerical-Approximation-of-Gradients" class="headerlink" title="Numerical Approximation of Gradients"></a>Numerical Approximation of Gradients</h4><p>$\begin{aligned} &amp; f’\left(\theta\right) = \lim_{\epsilon\rightarrow 0} \dfrac{f\left(\theta+\epsilon\right)-f\left(\theta-\epsilon\right)}{2\epsilon} \quad\Rightarrow\quad &amp; \dfrac{f\left(\theta+\epsilon\right)-f\left(\theta-\epsilon\right)}{2\epsilon}\approx g\left(\theta\right) \quad &amp; {\sim O\left(\epsilon^2\right)} \\ &amp; &amp; \color{lightgray} {\dfrac{f\left(\theta+\epsilon\right)-f\left(\theta\right)}{\epsilon}\approx g\left(\theta\right) }\quad &amp; \color{lightgray} {\sim O\left(\epsilon\right)} \end{aligned}$</p>
<h4 id="Gradient-Checking"><a href="#Gradient-Checking" class="headerlink" title="Gradient Checking"></a>Gradient Checking</h4><ol>
<li><p>take $W^{\left[1\right]},b^{\left[1\right]}, \dots,W^{\left[L\right]},b^{\left[L\right]}$ and reshape into a big vector $\Theta$</p>
<p>$J\left(W^{\left[1\right]},b^{\left[1\right]}, \dots,W^{\left[L\right]},b^{\left[L\right]}\right)=J\left(\Theta\right)$</p>
</li>
<li><p>take $dW^{\left[1\right]},db^{\left[1\right]}, \dots,dW^{\left[L\right]},db^{\left[L\right]}$ and reshape into a big vector $d\Theta$</p>
</li>
<li><p><strong><em>grad check:</em></strong> is $d\Theta$ the gradient of the cos function $J\left(\Theta\right)=J\left(\theta_1,\theta_2,\dots\right)$</p>
<p>$\begin{aligned}\texttt{for each i:} &amp; \\ \qquad d\theta_{approx}^{\left[i\right]} &amp;= \dfrac{J\left(\theta_1,\theta_i+\epsilon,\dots,\theta_2,\dots\right)-J\left(\theta_1,\theta_i-\epsilon,\dots,\theta_2,\dots\right)}{2\epsilon} \\ &amp;\approx d\theta^{\left[i\right]}=\dfrac{\partial J}{\partial \theta_i} \qquad\qquad\qquad\qquad \epsilon\sim 10^{-7} \end{aligned}$</p>
<p><strong>check Euclidean distance</strong></p>
<p>$\dfrac{\left|\left| d\theta_{approx}-d\theta \right| \right| _2}{\left|\left| d\theta_{approx} \right| \right| _2 + \left|\left| d\theta \right| \right| _2} \sim\epsilon$</p>
</li>
</ol>
<h4 id="Gradient-Checking-Implementation-Notes"><a href="#Gradient-Checking-Implementation-Notes" class="headerlink" title="Gradient Checking Implementation Notes"></a>Gradient Checking Implementation Notes</h4><ul>
<li>do not use in training, only to debug</li>
<li>if algorithm fails grad check, look at components to identify bug</li>
<li>remember regularization</li>
<li>does not work with dropout</li>
<li>run at random initialization; again after some training</li>
</ul>
<h3 id="Programming-Assignment"><a href="#Programming-Assignment" class="headerlink" title="Programming Assignment"></a>Programming Assignment</h3><h4 id="Initialization"><a href="#Initialization" class="headerlink" title="Initialization"></a>Initialization</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-5/p1.png" alt></p>
<h4 id="Regularization-1"><a href="#Regularization-1" class="headerlink" title="Regularization"></a>Regularization</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-5/p2.png" alt></p>
<h4 id="Gradient-Checking-1"><a href="#Gradient-Checking-1" class="headerlink" title="Gradient Checking"></a>Gradient Checking</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-5/p3.png" alt></p>
<p><a href="https://github.com/bugstop/coursera-deep-learning-solutions" target="_blank">Solutions Manual</a></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (7) · Hyperparameter Tuning</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course B<br><strong>Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization</strong><br>by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 3:</em></strong> <em>Hyperparameter Tuning, Batch Normalization and Programming Frameworks</em></p>
<ol>
<li>Master the process of hyperparameter tuning</li>
</ol>
<a id="more"></a>
<h3 id="Hyperparameter-Tuning"><a href="#Hyperparameter-Tuning" class="headerlink" title="Hyperparameter Tuning"></a>Hyperparameter Tuning</h3><h4 id="Tuning-Process"><a href="#Tuning-Process" class="headerlink" title="Tuning Process"></a>Tuning Process</h4><ul>
<li><strong>hyperparameter</strong></li>
<li><strong><em>α</em></strong><ul>
<li><strong>β</strong> ~ 0.9</li>
<li>β<sub>1</sub>, β<sub>2</sub>, ε = 0.9, 0.999, 10<sup>-8</sup></li>
<li><em># layers</em></li>
<li><strong># hidden units</strong></li>
<li><em>learning rate decay</em></li>
<li><strong>mini-batch size</strong></li>
</ul>
</li>
</ul>
<p>try <strong>random values,</strong> don’t use a <em>grid;</em><br><strong>coarse to fine</strong> search</p>
<h4 id="Using-an-Appropriate-Scale-to-Pick-Hyperparameters"><a href="#Using-an-Appropriate-Scale-to-Pick-Hyperparameters" class="headerlink" title="Using an Appropriate Scale to Pick Hyperparameters"></a>Using an Appropriate Scale to Pick Hyperparameters</h4><p>α ~ 10<sup>a</sup> ~ 10<sup>b</sup></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = np.random.uniform(a, b)</span><br><span class="line">alpha = <span class="number">10</span> ** r</span><br></pre></td></tr></table></figure>
<p>β ~ 0.9 ~ 0.999… → 1-10<sup>b</sup> ~ 1-10<sup>a</sup></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r = np.random.uniform(a, b)</span><br><span class="line">beta = <span class="number">1</span> - <span class="number">10</span> ** r</span><br></pre></td></tr></table></figure>
<h4 id="Hyperparameters-Tuning-in-Practice-Pandas-vs-Caviar"><a href="#Hyperparameters-Tuning-in-Practice-Pandas-vs-Caviar" class="headerlink" title="Hyperparameters Tuning in Practice: Pandas vs. Caviar"></a>Hyperparameters Tuning in Practice: Pandas vs. Caviar</h4><ul>
<li><strong><em>Pandas:</em></strong> babysitting one model</li>
<li><strong><em>Caviar:</em></strong> training many models in parallel</li>
</ul>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><h4 id="Normalizing-Activations-in-a-Network"><a href="#Normalizing-Activations-in-a-Network" class="headerlink" title="Normalizing Activations in a Network"></a>Normalizing Activations in a Network</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/1.png" alt="c"></p>
<p>$\qquad \begin{aligned}\mu &amp;= \frac{1}{m} \sum_{i=1}^{m} x^{\left( i \right)} \\\sigma ^2 &amp;= \frac{1}{m} \sum_{i=1}^{m} { x^{\left( i \right)} } ^2 \\ x &amp;= \dfrac{x- \mu}{\sigma} \end{aligned}$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/2.png" alt="c"></p>
<p><strong>normalize z<sup>[l]</sup></strong></p>
<p>Given some intermediate values $z^{\left[l\right]\left(i\right)} = z^{\left( 1 \right)},\,z^{\left( 2 \right)},\,\dots,\,z^{\left( m \right)}$</p>
<p>$\qquad \begin{aligned}\mu &amp;= \frac{1}{m} \sum_{i=1}^{m} z^{\left( i \right)} \\ \sigma ^2 &amp;= \frac{1}{m} \sum_{i=1}^{m} {\left( z^{\left( i \right)} -\mu \right)} ^2 \\ z^{\left( i \right)}_{\rm norm} &amp;= \dfrac{z^{\left( i \right)}- \mu}{\sqrt{ \sigma^2 + \varepsilon }} \\ \tilde{z}^{\left( i \right)} &amp;= \gamma z^{\left( i \right)}_{\rm norm} + \beta \end{aligned}$</p>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;<em>γ, β are learnable parameters of your model</em></p>
<p>use $\tilde{z}^{\left[l\right]\left(i\right)}$ instead of $z^{\left[l\right]\left(i\right)}$</p>
<h4 id="Fitting-Batch-Norm-into-a-Neural-Network"><a href="#Fitting-Batch-Norm-into-a-Neural-Network" class="headerlink" title="Fitting Batch Norm into a Neural Network"></a>Fitting Batch Norm into a Neural Network</h4><p>$x \xrightarrow{ W^{\left[1\right]},\,b^{\left[1\right]} } z^{\left[1\right]} \xrightarrow[\small {}^\textsf{Batch Norm}]{ \gamma^{\left[1\right]},\,\beta^{\left[1\right]} } \tilde{z}^{\left[1\right]} \xrightarrow[\small {}^{g^{\left[1\right]}}]{} a^{\left[1\right]}  \xrightarrow{ W^{\left[2\right]},\,b^{\left[2\right]} } z^{\left[2\right]} \xrightarrow[\small {}^\textsf{Batch Norm}]{ \gamma^{\left[2\right]},\,\beta^{\left[2\right]} } \tilde{z}^{\left[2\right]} \xrightarrow[\small {}^{g^{\left[2\right]}}]{} a^{\left[2\right]} \xrightarrow{} \cdots$</p>
<p><strong>Parameters:</strong> $\begin{aligned} &amp; W^{\left[1\right]},\,b^{\left[1\right]} ,\, W^{\left[2\right]},\,b^{\left[2\right]} ,\, \dots,\, W^{\left[l\right]},\,b^{\left[l\right]} \\  &amp; \gamma^{\left[1\right]},\,\beta^{\left[1\right]} ,\, \gamma^{\left[2\right]},\,\beta^{\left[2\right]} ,\, \dots,\, \gamma^{\left[l\right]},\,\beta^{\left[l\right]} \end{aligned}$</p>
<h5 id="working-with-mini-batches"><a href="#working-with-mini-batches" class="headerlink" title="working with mini-batches"></a>working with mini-batches</h5><p>$\begin{aligned} &amp; X^{\left\{1\right\}} \xrightarrow{ W^{\left[1\right]},\,b^{\left[1\right]} } Z^{\left[1\right]} \xrightarrow[\small {}^\textsf{Batch Norm}]{ \gamma^{\left[1\right]},\,\beta^{\left[1\right]} } \tilde{Z}^{\left[1\right]} \xrightarrow[\small {}^{g^{\left[1\right]}}]{} A^{\left[1\right]}  \xrightarrow{ W^{\left[2\right]},\,b^{\left[2\right]} } Z^{\left[2\right]} \xrightarrow[\small {}^\textsf{Batch Norm}]{ \gamma^{\left[2\right]},\,\beta^{\left[2\right]} } \tilde{Z}^{\left[2\right]} \xrightarrow[\small {}^{g^{\left[2\right]}}]{} A^{\left[2\right]} \xrightarrow{} \cdots \\ &amp; X^{\left\{2\right\}} \xrightarrow{ W^{\left[1\right]},\,b^{\left[1\right]} } Z^{\left[1\right]} \xrightarrow[\small {}^\textsf{Batch Norm}]{ \gamma^{\left[1\right]},\,\beta^{\left[1\right]} } \tilde{Z}^{\left[1\right]} \xrightarrow[\small {}^{g^{\left[1\right]}}]{} A^{\left[1\right]}  \xrightarrow{ W^{\left[2\right]},\,b^{\left[2\right]} } Z^{\left[2\right]} \xrightarrow[\small {}^\textsf{Batch Norm}]{ \gamma^{\left[2\right]},\,\beta^{\left[2\right]} } \tilde{Z}^{\left[2\right]} \xrightarrow[\small {}^{g^{\left[2\right]}}]{} A^{\left[2\right]} \xrightarrow{} \cdots \\ &amp; \cdots \end{aligned}$</p>
<p>&emsp;&emsp;<strong><em>Notice:</em></strong> b<sup>[l]</sup> can be eliminated (or always be zero) since it is subtracted out during batch normalization</p>
<p>&emsp;&emsp;$\begin{aligned} &amp; z^{\left[l\right]} = W^{\left[l\right]}a^{\left[l-1\right]} \\ &amp; \tilde{z}^{\left[l\right]} = \gamma^{\left[l\right]} z^{\left( l \right)}_{\rm norm} +\beta^{\left[l\right]} \end{aligned}$</p>
<p><strong>Parameters:</strong> $W^{\left[1\right]} \in \mathbb{R}^{n^{\left[ l \right]} \times n^{\left[ l-1 \right]}} ,\quad \gamma^{\left[l\right]} \in \mathbb{R}^{n^{\left[ l \right]} \times 1} ,\quad \beta^{\left[l\right]} \in \mathbb{R}^{n^{\left[ l \right]} \times 1}$</p>
<p>for t = 1, 2, …, num_mini_batches</p>
<p>&emsp;&emsp;forward prop on X<sup>{t}</sup></p>
<p>&emsp;&emsp;&emsp;&emsp;in each hidden layer, use BN to replace z<sup>[l]</sup> with z̃<sup>[l]</sup></p>
<p>&emsp;&emsp;back prop  to compute dW<sup>[l]</sup>, dγ<sup>[l]</sup>, dβ<sup>[l]</sup></p>
<p>&emsp;&emsp;update parameters</p>
<p>&emsp;&emsp;$\qquad \begin{aligned} &amp; W^{\left[l\right]} := W^{\left[l\right]} - dW^{\left[l\right]} \\ &amp; \gamma^{\left[l\right]} := \gamma^{\left[l\right]} - d\gamma^{\left[l\right]} \\ &amp; \beta^{\left[l\right]} := \beta^{\left[l\right]} - d\beta^{\left[l\right]} \end{aligned}$</p>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<em>works with Momentum / RMSProp / Adam</em></p>
<h4 id="Why-does-Batch-Norm-Work"><a href="#Why-does-Batch-Norm-Work" class="headerlink" title="Why does Batch Norm Work?"></a>Why does Batch Norm Work?</h4><p><strong>covariate shift</strong></p>
<p>batch norm limits the amount to which updating the parameters in the earlier layers can affect the distribution of values that the layer now sees and therefore has to learn on</p>
<p><strong>regularization</strong></p>
<p>similar to dropout, batch norm adds some noise to each hidden layer’s activations which has a <em>slight</em> effect</p>
<h4 id="Batch-Norm-at-Test-Time"><a href="#Batch-Norm-at-Test-Time" class="headerlink" title="Batch Norm at Test Time"></a>Batch Norm at Test Time</h4><p><strong>on mini-batches:</strong></p>
<p>$\qquad \begin{aligned}\mu^{\left[l\right]} &amp;= \frac{1}{m} \sum_{i=1}^{m} z^{\left[l\right]\left(i\right)} \\ {\sigma ^2} ^{\left[l\right]} &amp;= \frac{1}{m} \sum_{i=1}^{m} {\left( z^{\left[l\right]\left(i\right)} -\mu ^{\left[l\right]} \right)} ^2 \\ z^{\left[l\right]\left(i\right)}_{\rm norm} &amp;= \dfrac{z^{\left[l\right]\left(i\right)}- \mu ^{\left[l\right]}}{\sqrt{ {\sigma ^2} ^{\left[l\right]} + \varepsilon }} \\ \tilde{z}^{\left[l\right]\left(i\right)} &amp;= \gamma^{\left[l\right]}  z^{\left[l\right]\left(i\right)}_{\rm norm} + \beta ^{\left[l\right]} \end{aligned}$</p>
<p><strong>at test time:</strong></p>
<p>μ, σ<sup>2</sup> is estimated using a exponentially weighted average (across the mini-batches)</p>
<p>$\qquad \begin{aligned}\mu ^{\left[l\right]} &amp;= \frac{1}{T} \sum_{t=1}^{T} \mu^{\left\{t\right\} \left[l\right]} \\ {\sigma ^2} ^{\left[l\right]} &amp;= \frac{1}{T} \sum_{t=1}^{T} {\sigma ^2}^{\left\{t\right\} \left[l\right]} \\ z^{\left[l\right]\left(i\right)}_{\rm norm} &amp;= \dfrac{z^{\left[l\right]\left(i\right)}- \mu ^{\left[l\right]}}{\sqrt{ {\sigma ^2} ^{\left[l\right]} + \varepsilon }} \\ \tilde{z}^{\left[l\right]\left(i\right)} &amp;= \gamma^{\left[l\right]}  z^{\left[l\right]\left(i\right)}_{\rm norm} + \beta ^{\left[l\right]} \end{aligned}$</p>
<h3 id="Multi-Class-Classification"><a href="#Multi-Class-Classification" class="headerlink" title="Multi-Class Classification"></a>Multi-Class Classification</h3><h4 id="Softmax-Regression"><a href="#Softmax-Regression" class="headerlink" title="Softmax Regression"></a>Softmax Regression</h4><p><strong>C = #classes</strong> = 4 → <strong>n<sup>[L]</sup> = C</strong> = 4 → ŷ ∈ R<sup>4×1</sup></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/3.png" alt="c"></p>
<p>$\begin{aligned} z^{\left[L\right]} &amp;= W^{\left[L\right]} a^{\left[L-1\right]} + b^{\left[L\right]} \\ &amp; \textsf{Activation Function}^{\strut} \\ t &amp;= e^{ z^{\left[L\right]} } , \qquad t \in \mathbb{R}^{4 \times 1} \\ a^{\left[L\right]} &amp;= \dfrac{e^{ z^{\left[L\right]} }}{\sum_{i=1}^{4} t_i} , \qquad a_i^{\left[L\right]} = \dfrac{t_i}{\sum_{i=1}^{4} t_i} \end{aligned}$</p>
<p>$\Rightarrow {\rm softmax:}\ \ a^{\left[L\right]}_{\Tiny{(C,1)}} = g^{\left[L\right]} \left( z^{\left[L\right]}_{\Tiny{(C,1)}} \right)$</p>
<p><strong><em>softmax regression generalizes logistic regression to C classes</em></strong></p>
<h4 id="Training-a-Softmax-Classifier"><a href="#Training-a-Softmax-Classifier" class="headerlink" title="Training a Softmax Classifier"></a>Training a Softmax Classifier</h4><h5 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h5><p>$\begin{aligned}&amp; y= \left[\begin{matrix} 0\\1\\0\\0 \end{matrix}\right] \quad a^{\left[L\right]} = \hat{y}= \left[\begin{matrix} 0.3\\0.2\\0.1\\0.4 \end{matrix}\right] \qquad C=4 \\ &amp; \ \ \ \ \qquad\qquad\qquad\qquad\qquad\Downarrow \\ &amp; L\left(\hat{y},\,y\right) = -\sum_{j=1}^{4} y_j \log \hat{y}_j = -\log \hat{y}_2 \Rightarrow \hat{y}_2 \uparrow \\ &amp; J\left( W^{\left[1\right]},b^{\left[1\right]}, \dots,W^{\left[L\right]},b^{\left[L\right]} \right) = \dfrac{1}{m} \sum_{i=1}^{m} L\left(\hat{y}^{\left(i\right)},\,y^{\left(i\right)}\right) \end{aligned}$</p>
<h5 id="Gradient-Decent"><a href="#Gradient-Decent" class="headerlink" title="Gradient Decent"></a>Gradient Decent</h5><p>$dz^{\left[L\right]} = \dfrac{\partial J}{\partial z^{\left[L\right]}} = \hat{y}-y$</p>
<h3 id="Introduction-to-Programming-Frameworks"><a href="#Introduction-to-Programming-Frameworks" class="headerlink" title="Introduction to Programming Frameworks"></a>Introduction to Programming Frameworks</h3><h4 id="Deep-Learning-Frameworks"><a href="#Deep-Learning-Frameworks" class="headerlink" title="Deep Learning Frameworks"></a>Deep Learning Frameworks</h4><ul>
<li>ease of programming</li>
<li>running speed</li>
<li>truly open</li>
</ul>
<h4 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h4><p><a href="Deep-Learning-Andrew-Ng-7/tensorflow.ipynb">tensorflow.ipynb</a></p>
<h3 id="Programming-Assignments"><a href="#Programming-Assignments" class="headerlink" title="Programming Assignments"></a>Programming Assignments</h3><h4 id="TensorFlow-1"><a href="#TensorFlow-1" class="headerlink" title="TensorFlow"></a>TensorFlow</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-7/4.png" alt="t"></p>
<p><a href="https://github.com/bugstop/coursera-deep-learning-solutions" target="_blank">Solutions Manual</a></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (8) · ML Strategy · I</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-8/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course C<br><strong>Structuring Machine Learning Projects</strong> by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 1:</em></strong> <em>ML Strategy (1)</em></p>
<ol>
<li>Understand why Machine Learning strategy is important</li>
<li>Apply satisficing and optimizing metrics to set up your goal for ML projects</li>
<li>Choose a correct train/dev/test split of your dataset</li>
<li>Understand how to define human-level performance</li>
<li>Use human-level perform to define your key priorities in ML projects</li>
<li>Take the correct ML Strategic decision based on observations of performances and dataset</li>
</ol>
<a id="more"></a>
<h3 id="Introduction-to-ML-Strategy"><a href="#Introduction-to-ML-Strategy" class="headerlink" title="Introduction to ML Strategy"></a>Introduction to ML Strategy</h3><h4 id="Why-ML-Strategy"><a href="#Why-ML-Strategy" class="headerlink" title="Why ML Strategy?"></a>Why ML Strategy?</h4><ul>
<li>collect more data</li>
<li>collect more diverse training set</li>
<li>train algorithm longer with gradient descent</li>
<li>try Adam instead of GD</li>
<li>try bigger / smaller network</li>
<li>try dropout</li>
<li>add L<sub>2</sub> regularization</li>
<li>network architecture<ul>
<li>activation functions</li>
<li># hidden units</li>
<li>…</li>
</ul>
</li>
</ul>
<h4 id="Orthogonalization"><a href="#Orthogonalization" class="headerlink" title="Orthogonalization"></a>Orthogonalization</h4><ul>
<li>fit training set well on cost function<ul>
<li>bigger network</li>
<li>Adam</li>
</ul>
</li>
<li>fit dev set well on cost function<ul>
<li>regularization</li>
<li>bigger training set</li>
</ul>
</li>
<li>fit test set well on cost function<ul>
<li>bigger dev set</li>
</ul>
</li>
<li>performs well in real world<ul>
<li>change dev set</li>
<li>change cost function</li>
</ul>
</li>
</ul>
<h3 id="Setting-up-your-Goal"><a href="#Setting-up-your-Goal" class="headerlink" title="Setting up your Goal"></a>Setting up your Goal</h3><h4 id="Single-Number-Evaluation-Metric"><a href="#Single-Number-Evaluation-Metric" class="headerlink" title="Single Number Evaluation Metric"></a>Single Number Evaluation Metric</h4><ul>
<li><strong>Precision</strong><br>% are real cat of examples recognized as cat</li>
<li><strong>Recall</strong><br>% of actual cats are correctly recognized</li>
<li><strong>F<sub>1</sub> score</strong><br>harmonic mean of precision and recall<br>$F_1 = \dfrac{2}{\dfrac{1}{P}+\dfrac{1}{R}}$</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Classifier</th>
<th style="text-align:center">Precision</th>
<th style="text-align:center">Recall</th>
<th style="text-align:center">F<sub>1</sub> Score</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>A</strong></td>
<td style="text-align:center">95 %</td>
<td style="text-align:center">90 %</td>
<td style="text-align:center"><strong>92.4 %</strong></td>
</tr>
<tr>
<td style="text-align:center"><strong>B</strong></td>
<td style="text-align:center">98 %</td>
<td style="text-align:center">85 %</td>
<td style="text-align:center">91.0 %</td>
</tr>
</tbody>
</table>
</div>
<p><em>dev set + single number evaluation metric speed up iterating process</em></p>
<h4 id="Satisficing-and-Optimizing-Metric"><a href="#Satisficing-and-Optimizing-Metric" class="headerlink" title="Satisficing and Optimizing Metric"></a>Satisficing and Optimizing Metric</h4><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Classifier</th>
<th style="text-align:center">Accuracy</th>
<th style="text-align:center">Running Time</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>A</strong></td>
<td style="text-align:center">90 %</td>
<td style="text-align:center">80 ms</td>
</tr>
<tr>
<td style="text-align:center"><strong>B</strong></td>
<td style="text-align:center"><strong>92 %</strong></td>
<td style="text-align:center"><strong><em>95 ms</em></strong></td>
</tr>
<tr>
<td style="text-align:center"><strong>C</strong></td>
<td style="text-align:center">95 %</td>
<td style="text-align:center">1500 ms</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><strong><em>optimizing</em></strong></td>
<td style="text-align:center"><strong><em>satisficing</em></strong></td>
</tr>
</tbody>
</table>
</div>
<p><strong>maximize accuracy</strong> subject to <strong><em>running time &lt; 100 ms</em></strong></p>
<ul>
<li><strong><em>N metric:</em></strong> 1 optimizing, N-1 satisficing</li>
</ul>
<h4 id="Train-Dev-Test-Distributions"><a href="#Train-Dev-Test-Distributions" class="headerlink" title="Train / Dev / Test Distributions"></a>Train / Dev / Test Distributions</h4><p>make dev and test sets obey same distribution ← randomly shuffle into dev / test</p>
<p>choose a dev set and test set to reflect data you expect to get in the future and consider important to do well on</p>
<h4 id="Size-of-Dev-and-Test-Sets"><a href="#Size-of-Dev-and-Test-Sets" class="headerlink" title="Size of Dev and Test Sets"></a>Size of Dev and Test Sets</h4><p>train / dev / test</p>
<ul>
<li>~ 1k examples: 70%-30% or 60%-20%-20%</li>
<li>~ 1m examples: 98%-1%-1%, smaller dev and test sets</li>
</ul>
<p><em>set test set to be big enough to give high confidence in the overall performance of the system (no test set might be okay)</em></p>
<h4 id="When-to-Change-Dev-Test-Sets-and-Metrics"><a href="#When-to-Change-Dev-Test-Sets-and-Metrics" class="headerlink" title="When to Change Dev / Test Sets and Metrics"></a>When to Change Dev / Test Sets and Metrics</h4><p>Metric + Dev: prefers A <em>(misprediction)</em><br>You / Users: prefers B</p>
<p>$\begin{aligned}{\rm classification}\ &amp;{\rm error}  _{\strut} \\ \textsf{Algorithm A: }&amp; 3\%\ {\rm error} \textsf{ but contains pornographies} \\ \textsf{Algorithm B: }&amp; 5\%\ {\rm error} _{\strut} \\ \textsf{Error: }&amp; \dfrac{1}{m_{dev}} \sum_{i=1}^{m_{dev}} L\left\{ y_{\rm pred}^{\left(i\right)} \neq y^{\left(i\right)} \right\} \\ \textsf{New Error: }&amp; \dfrac{1}{ \sum_{i=1}^{m_{dev}} \omega^{\left(i\right)}} \sum_{i=1}^{m_{dev}} \omega^{\left(i\right)} L\left\{ y_{\rm pred}^{\left(i\right)} \neq y^{\left(i\right)} \right\} \\ &amp; \qquad\qquad \omega^{\left(i\right)}= \begin{cases} 1 \ \ &amp;{\rm if}\ x^{\left(i\right)}\ {\rm is}\ {\rm non}!!-!!{\rm porn} \\ 10 &amp;{\rm if}\ x^{\left(i\right)}\ {\rm is}\ {\rm porn} \end{cases} \end{aligned}$</p>
<ol>
<li><strong><em>Place the target:</em></strong> define a metric to evaluate classifiers</li>
<li><strong><em>Shoot at target:</em></strong> worry separately about how to do well on this metric</li>
</ol>
<p><em>if doing well on metric + dev/test set does not correspond to doing well on application, change metric and/or dev/test set</em></p>
<h3 id="Comparing-to-Human-Level-Performance"><a href="#Comparing-to-Human-Level-Performance" class="headerlink" title="Comparing to Human-Level Performance"></a>Comparing to Human-Level Performance</h3><h4 id="Why-Human-Level-Performance"><a href="#Why-Human-Level-Performance" class="headerlink" title="Why Human-Level Performance?"></a>Why Human-Level Performance?</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-8/1.png" alt="c"></p>
<p>as long as machine learning is worse than humans, you can:</p>
<ul>
<li>get labeled data from humans</li>
<li>gain insight from manual error analysis</li>
<li>better analysis of bias / variance</li>
</ul>
<h4 id="Avoidable-Bias"><a href="#Avoidable-Bias" class="headerlink" title="Avoidable Bias"></a>Avoidable Bias</h4><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Humans Error</th>
<th style="text-align:center">Train Error</th>
<th style="text-align:center">Dev Error</th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1 %</td>
<td style="text-align:center">8 %</td>
<td style="text-align:center">10 %</td>
<td style="text-align:center">Focus on <strong>Bias</strong></td>
</tr>
<tr>
<td style="text-align:center">7.5 %</td>
<td style="text-align:center">8 %</td>
<td style="text-align:center">10 %</td>
<td style="text-align:center">Focus on <strong>Variance</strong></td>
</tr>
</tbody>
</table>
</div>
<h5 id="human-level-error-as-a-proxy-for-Bayes-error"><a href="#human-level-error-as-a-proxy-for-Bayes-error" class="headerlink" title="human-level error as a proxy for Bayes error"></a>human-level error as a proxy for Bayes error</h5><p><strong><em>bias:</em></strong> compare to 0% error<br><strong><em>avoidable bias:</em></strong> minimum level of error that you cannot get below<br>&emsp;&emsp;<em>(cannot do better than Bayes error unless overfitting)</em></p>
<h4 id="Understanding-Human-Level-Performance"><a href="#Understanding-Human-Level-Performance" class="headerlink" title="Understanding Human-Level Performance"></a>Understanding Human-Level Performance</h4><p><strong>human-level error</strong> as a proxy for <strong><em>Bayes error</em></strong></p>
<h4 id="Surpassing-Human-Level-Performance"><a href="#Surpassing-Human-Level-Performance" class="headerlink" title="Surpassing Human-Level Performance"></a>Surpassing Human-Level Performance</h4><ul>
<li>Structed Data &emsp; (↔ not Natural Perception)</li>
<li>Lots of Data</li>
</ul>
<h4 id="Improving-your-Model-Performance"><a href="#Improving-your-Model-Performance" class="headerlink" title="Improving your Model Performance"></a>Improving your Model Performance</h4><h5 id="two-fundamental-assumptions-of-supervised-learning"><a href="#two-fundamental-assumptions-of-supervised-learning" class="headerlink" title="two fundamental assumptions of supervised learning"></a>two fundamental assumptions of supervised learning</h5><ol>
<li>you can fit the training set pretty well (avoidable bias)</li>
<li>the training set performance generalizes pretty well to the dev / test set (variance)</li>
</ol>
<h5 id="reducing-avoidable-bias-and-variance"><a href="#reducing-avoidable-bias-and-variance" class="headerlink" title="reducing (avoidable) bias and variance"></a>reducing (avoidable) bias and variance</h5><p>$\textsf{human-leval error } \leftarrow avoidable\ bias \rightarrow \textsf{ training error } \leftarrow variance \rightarrow \textsf{ dev error}$</p>
<ul>
<li><strong>Avoidable Bias</strong><ul>
<li>Train bigger model</li>
<li>Train longer / better optimization algorithms (momentum, RMSProp, Adam)</li>
<li>NN architecture / hyperparameters search (RNN, CNN)</li>
</ul>
</li>
<li><strong>Variance</strong><ul>
<li>More data</li>
<li>Regularization (L<sub>2</sub>, dropout, data augmentation)</li>
<li>NN architecture / hyperparameters search</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (6) · Optimization Algorithms</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-6/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course B<br><strong>Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization</strong><br>by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 2:</em></strong> <em>Optimization Algorithms</em></p>
<ol>
<li>Remember different optimization methods such as (Stochastic) Gradient Descent, Momentum, RMSProp and Adam</li>
<li>Use random minibatches to accelerate the convergence and improve the optimization</li>
<li>Know the benefits of learning rate decay and apply it to your optimization</li>
</ol>
<a id="more"></a>
<h3 id="Optimization-Algorithms"><a href="#Optimization-Algorithms" class="headerlink" title="Optimization Algorithms"></a>Optimization Algorithms</h3><h4 id="Mini-Batch-Gradient-Descent"><a href="#Mini-Batch-Gradient-Descent" class="headerlink" title="Mini-Batch Gradient Descent"></a>Mini-Batch Gradient Descent</h4><p>$X_{n_x \times m} = \left[ \underbrace{ \overbrace{ \begin{matrix} x^{\left(1\right)} &amp; x^{\left(2\right)} &amp; \cdots &amp; x^{\left(1000\right)} \end{matrix} }^{\rm mini-batch} }_{ X^{\left\{1\right\} } } \begin{matrix} | \end{matrix} \underbrace{ \begin{matrix} x^{\left(1001\right)} &amp; \cdots &amp; | &amp; \cdots &amp; | &amp;\cdots &amp; x^{\left(m\right)} \end{matrix} }_{X^{ \left\{2\right\} } \qquad X^{ \left\{3\right\} } \qquad\cdots } \right]$</p>
<p>$Y_{1 \times m} = \left[ \underbrace{ \overbrace{ \begin{matrix} y^{\left(1\right)} &amp; y^{\left(2\right)} &amp; \cdots &amp; y^{\left(1000\right)} \end{matrix} }^{\rm mini-batch} }_{ Y^{\left\{1\right\} } } \begin{matrix} | \end{matrix} \underbrace{ \begin{matrix} y^{\left(1001\right)} &amp; \cdots &amp; | &amp; \cdots &amp; | &amp;\cdots &amp; y^{\left(m\right)} \end{matrix} }_{Y^{ \left\{2\right\} } \qquad Y^{ \left\{3\right\} } \qquad\cdots } \right]$</p>
<ul>
<li><p><strong><em>mini-batch t:</em></strong> X<sup>{t}</sup>, Y<sup>{t}</sup></p>
</li>
<li><p><strong><em>mini-batch gradient descent</em></strong></p>
<p>for t = 1, 2, …, 5000:&emsp;&emsp;<em>(if m = 5,000,000)</em></p>
<p>&emsp;&emsp;forward prop on X<sup>{t}</sup></p>
<p>&emsp;&emsp;$\qquad \begin{aligned} Z^{\left[1\right]}&amp;=W^{\left[1\right]}X^{\left\{t\right\}}+b^{\left[1\right]} \\ A^{\left[1\right]}&amp;=g^{\left[1\right]}\left(Z^{\left[1\right]}\right) \\ \cdots \\Z^{\left[l\right]}&amp;=W^{\left[l\right]}A^{\left[l-1\right]}+b^{\left[l\right]} \\ A^{\left[l\right]}&amp;=g^{\left[l\right]}\left(Z^{\left[l\right]}\right) \end{aligned} \qquad \begin{aligned}\\ \\ \\ \\ l = 1, \ 2,\ \dots,\ L \\ \textsf{vectorized}\end{aligned}$</p>
<p>&emsp;&emsp;compute cost function J</p>
<p>&emsp;&emsp;$\qquad \begin{aligned} J^{\left\{t\right\}} = \dfrac{1}{1000} \sum_{i=1}^{m} L &amp; \left( \hat{y} ^\left(i\right),\, y^\left(i\right) \right) + \dfrac{\lambda}{2\cdot1000} \sum_{l=1}^{L} \left|\left| W^{\left[l\right]} \right| \right| ^2_F \end{aligned}$</p>
<p>&emsp;&emsp;back prop to compute gradients of J<sup>{t}</sup> and update weights</p>
<p>&emsp;&emsp;$\qquad \begin{aligned} &amp; W^{\left[l\right]} := W^{\left[l\right]} - dW^{\left[l\right]} \\ &amp; b^{\left[l\right]} := b^{\left[l\right]} - db^{\left[l\right]}\end{aligned}$</p>
<p>$\rightarrow$ <strong><em>1 epoch</em></strong></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-6/e.png" alt="epoch"></p>
</li>
</ul>
<h4 id="Understanding-Mini-Batch-Gradient-Descent"><a href="#Understanding-Mini-Batch-Gradient-Descent" class="headerlink" title="Understanding Mini-Batch Gradient Descent"></a>Understanding Mini-Batch Gradient Descent</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-6/c.png" alt="c"></p>
<ul>
<li><em>if mini-batch</em> <strong><em>size = m:</em></strong> batch gradient decent<ul>
<li>(X<sup>{1}</sup>, Y<sup>{1}</sup>) = (X, Y) → too long per iteration</li>
</ul>
</li>
<li><em>if mini-batch</em> <strong><em>size = 1:</em></strong> stochastic gradient descent<ul>
<li>(X<sup>{1}</sup>, Y<sup>{1}</sup>) = (X<sup>(1)</sup>, Y<sup>(1)</sup>) → lose speedup from vectorization</li>
</ul>
</li>
<li><strong><em>in between:</em></strong> fastest learning<ul>
<li>vectorization</li>
<li>make progress without entire training set</li>
</ul>
</li>
</ul>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-6/m.png" alt="1-m"></p>
<ul>
<li><strong><em>small training set</em></strong> <em>(2000):</em> use batch gradient descent</li>
<li><strong><em>typical mini-batch size:</em></strong> 64, 128, 256, 512</li>
<li>make sure mini-batches fit in memory</li>
</ul>
<h4 id="Exponentially-Weighted-Averages"><a href="#Exponentially-Weighted-Averages" class="headerlink" title="Exponentially Weighted Averages"></a>Exponentially Weighted Averages</h4><p>$\begin{aligned} V_0 &amp;= 0 \\ V_1 &amp;= 0.9V_0 + 0.1 \theta_1 \\ V_2 &amp;= 0.9V_1 + 0.1 \theta_2 \\ &amp;\vdots \\ V_n &amp;= 0.9V_{n-1} + 0.1 \theta_n \end{aligned}$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-6/t.png" alt="t"></p>
<p>$V_t = \beta V_{t-1} + \left( 1-\beta \right) \theta_t$</p>
<ul>
<li><strong><em>large β:</em></strong> adapt slower</li>
<li><strong><em>small β:</em></strong> more noisy</li>
</ul>
<h4 id="Understanding-Exponentially-Weighted-Averages"><a href="#Understanding-Exponentially-Weighted-Averages" class="headerlink" title="Understanding Exponentially Weighted Averages"></a>Understanding Exponentially Weighted Averages</h4><p>$V_{100} = 0.1\ \theta_{100} +0.1\times0.9\ \theta_{99} +0.1\times0.9^2\ \theta_{98} + \cdots +0.1\times0.9^{10}\ \theta_{90} \quad \underbrace{\color {grey} {+ 0.1\times0.9^{11}\ \theta_{89} + \cdots}} _{\rm omit\ when\ \left(1-\varepsilon\right) ^{1/\varepsilon} &lt; \frac{1}{e} , \ \varepsilon = 1-\beta}$</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vθ = <span class="number">0</span></span><br><span class="line">repeat:</span><br><span class="line">    get <span class="built_in">next</span> θt</span><br><span class="line">    vθ = β * vθ + (<span class="number">1</span>-β) * θt</span><br></pre></td></tr></table></figure>
<h4 id="Bias-Correction-in-Exponentially-Weighted-Averages"><a href="#Bias-Correction-in-Exponentially-Weighted-Averages" class="headerlink" title="Bias Correction in Exponentially Weighted Averages"></a>Bias Correction in Exponentially Weighted Averages</h4><p>$\begin{array}{lc|cl} \begin{aligned} V_0 &amp;= 0 \qquad\Leftarrow \\ V_1 &amp;= 0.98V_0 + 0.02 \theta_1 = 0.02 \theta_1 \\ V_2 &amp;= 0.9V_1 + 0.1 = 0.02 \theta_1= 0.0196 \theta_1 + 0.02 \theta_1 \end{aligned} &amp; &amp; &amp; \begin{aligned} &amp; {\rm use} \ \ V_t / \left( 1-\beta^t\right) \\ \Rightarrow \ \ &amp; V_2 = \dfrac{ 0.0196 \theta_1 + 0.02 \theta_1 }{0.0396} \end{aligned} \end{array}$</p>
<h4 id="Gradient-Descent-with-Momentum"><a href="#Gradient-Descent-with-Momentum" class="headerlink" title="Gradient Descent with Momentum"></a>Gradient Descent with Momentum</h4><p>on iteration t:</p>
<p>&emsp;&emsp;compute $dW,\ dB$ on current <em>mini-</em>batch</p>
<p>&emsp;&emsp;$V_{dW} = \beta_1 V_{dW} + \left( 1-\beta_1 \right) dW \quad {\color{gray} {= \beta_1 V_{dW} + dW}}$</p>
<p>&emsp;&emsp;$V_{db} = \beta_1 V_{db} + \left( 1-\beta_1 \right) db \quad {\color{gray} {= \beta_1 V_{db} + db}}$</p>
<p>&emsp;&emsp;$W:=W-\alpha V_{dW}, \quad b:=b-\alpha V_{db}$</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-6/md.png" alt="momentum"></p>
<h4 id="Root-Mean-Square-Prop-RMSProp"><a href="#Root-Mean-Square-Prop-RMSProp" class="headerlink" title="Root Mean Square Prop (RMSProp)"></a>Root Mean Square Prop (RMSProp)</h4><p>on iteration t:</p>
<p>&emsp;&emsp;compute $dW,\ dB$ on current <em>mini-</em>batch</p>
<p>&emsp;&emsp;$S_{dW} = \beta_2 S_{dW} + \left(1-\beta_2\right) dW^2$ &emsp;<em>element-wise</em></p>
<p>&emsp;&emsp;$S_{db} = \beta_2 S_{db} + \left(1-\beta_2 \right) db^2$</p>
<p>&emsp;&emsp;$W:=W-\alpha\dfrac{dW}{\sqrt{S_{dW}} + \varepsilon}, \quad b:=b-\alpha\dfrac{db}{\sqrt{S_{db}} + \varepsilon}, \qquad \left(\, \varepsilon \sim 10^{-8} \ \Rightarrow \ \neq 0 \,\right)$</p>
<h4 id="Adaptive-Moment-Estimation-Adam-Optimization-Algorithm"><a href="#Adaptive-Moment-Estimation-Adam-Optimization-Algorithm" class="headerlink" title="Adaptive Moment Estimation (Adam) Optimization Algorithm"></a>Adaptive Moment Estimation (Adam) Optimization Algorithm</h4><p>initialize $V_{dW}=0, \ S_{dW}=0, \ V_{db}=0, \ S_{db}=0$</p>
<p>on iteration t:</p>
<p>&emsp;&emsp;compute $dW,\ dB$ on current <em>mini-</em>batch</p>
<p>&emsp;&emsp;$V_{dW} = \beta_1 V_{dW} + \left( 1-\beta_1 \right) dW \qquad\ \ V_{db} = \beta_1 V_{db} + \left( 1-\beta_1 \right) db$</p>
<p>&emsp;&emsp;$S_{dW} = \beta_2 S_{dW} + \left(1-\beta_2\right) dW^2 \qquad S_{db} = \beta_2 S_{db} + \left(1-\beta_2 \right) db^2$</p>
<p>&emsp;&emsp;$V_{dW}^{\,^{\rm corrected}} = V_{dW} / \left( 1- \beta_1^{\ t} \right) \qquad\qquad V_{db}^{\,^{\rm corrected}} = V_{db} / \left( 1- \beta_1^{\ t} \right)$</p>
<p>&emsp;&emsp;$S_{dW}^{\,^{\rm corrected}} = V_{dW} / \left( 1- \beta_2^{\ t} \right) \qquad\qquad\ S_{db}^{\,^{\rm corrected}} = S_{db} / \left( 1- \beta_2^{\ t} \right)$</p>
<p>&emsp;&emsp;$W:=W-\alpha\dfrac{V_{dW}^{\,^{\rm corrected}}}{\sqrt{S_{dW}^{\,^{\rm corrected}} } + \varepsilon} \qquad\quad\ \ b:=b-\alpha\dfrac{V_{db}^{\,^{\rm corrected}}}{\sqrt{S_{db}^{\,^{\rm corrected}} } + \varepsilon}$</p>
<h5 id="Hyperparameters-Choice"><a href="#Hyperparameters-Choice" class="headerlink" title="Hyperparameters Choice"></a>Hyperparameters Choice</h5><ul>
<li><strong><em>α:</em></strong> needs to be tuned</li>
<li><strong><em>β<sub>1</sub>:</em></strong> 0.9</li>
<li><strong><em>β<sub>2</sub>:</em></strong> 0.999</li>
<li><strong><em>ε:</em></strong> 10<sup>-8</sup></li>
</ul>
<h4 id="Learning-Rate-Decay"><a href="#Learning-Rate-Decay" class="headerlink" title="Learning Rate Decay"></a>Learning Rate Decay</h4><p>$\alpha = \dfrac{1}{1 + \underbrace{\rm decay{\small -}rate}_\textsf{hyperparameter} \times {\rm epoch{\small -}number}} \cdot \alpha_0$</p>
<p>$\alpha = \lambda ^{\rm epoch{\small -}number} \cdot \alpha_0, \quad \lambda &lt; 1 \ \ \sim 0.95$</p>
<p>$\alpha =\dfrac{\overbrace{\gamma_{const}}^\textsf{hyperparameter}}{\sqrt{\rm epoch{\small -}number}}\cdot\alpha_0\qquad\textsf{or}\quad =\dfrac{\gamma_{const}}{\sqrt{t}}\cdot\alpha_0$</p>
<p>$\alpha = f_\textsf{discrete staircase}$</p>
<h4 id="The-Problem-of-Local-Optima"><a href="#The-Problem-of-Local-Optima" class="headerlink" title="The Problem of Local Optima"></a>The Problem of Local Optima</h4><h5 id="Local-Optima-×"><a href="#Local-Optima-×" class="headerlink" title="Local Optima ×"></a>Local Optima ×</h5><p><strong>Saddle Point</strong></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-6/z.png" alt="Local Optima"></p>
<h5 id="Plateaus-√"><a href="#Plateaus-√" class="headerlink" title="Plateaus √"></a>Plateaus √</h5><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-6/p.png" alt="Plateau"></p>
<ul>
<li>unlikely to get stuck in a bad local optima</li>
<li>plateaus can make learning slow</li>
</ul>
<h3 id="Programming-Assignments"><a href="#Programming-Assignments" class="headerlink" title="Programming Assignments"></a>Programming Assignments</h3><h4 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-6/3.png" alt="optimization"></p>
<p><a href="https://github.com/bugstop/coursera-deep-learning-solutions" target="_blank">Solutions Manual</a></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning (9) · ML Strategy · II</title>
    <url>/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-9/</url>
    <content><![CDATA[<p>Deep Learning Specialization, Course C<br><strong>Structuring Machine Learning Projects</strong> by deeplearning.ai, <strong><em>Andrew Ng,</em></strong> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info">Coursera</a></p>
<p><strong><em>Week 2:</em></strong> <em>ML Strategy (2)</em></p>
<ol>
<li>Understand what multi-task learning and transfer learning are</li>
<li>Recognize bias, variance and data-mismatch by looking at the performances of your algorithm on train/dev/test sets</li>
</ol>
<a id="more"></a>
<h3 id="Error-Analysis"><a href="#Error-Analysis" class="headerlink" title="Error Analysis"></a>Error Analysis</h3><h4 id="Carrying-out-Error-Analysis"><a href="#Carrying-out-Error-Analysis" class="headerlink" title="Carrying out Error Analysis"></a>Carrying out Error Analysis</h4><p><strong><em>Error analysis:</em></strong> Should you try to make your cat classifier do better on dogs?</p>
<ul>
<li>get ~ 100 mislabeled dev set examples</li>
<li>count up how many are dogs (5%? / 50%?) <strong>→ ceiling on  performance</strong></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Image</th>
<th style="text-align:center">Dogs</th>
<th style="text-align:center">Great Cats</th>
<th style="text-align:center">Blurry</th>
<th style="text-align:center">Incorrectly Labeled</th>
<th style="text-align:center">Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">✓</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">pitbull</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">✓</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center"></td>
<td style="text-align:center">✓</td>
<td style="text-align:center">✓</td>
<td style="text-align:center"></td>
<td style="text-align:center">rainy</td>
</tr>
<tr>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
</tr>
<tr>
<td style="text-align:center"><strong>% of total</strong></td>
<td style="text-align:center">8%</td>
<td style="text-align:center"><strong>43%</strong></td>
<td style="text-align:center"><strong>61%</strong></td>
<td style="text-align:center">6%</td>
<td style="text-align:center">&emsp;</td>
</tr>
</tbody>
</table>
</div>
<h4 id="Cleaning-up-Incorrectly-Labeled-Data"><a href="#Cleaning-up-Incorrectly-Labeled-Data" class="headerlink" title="Cleaning up Incorrectly Labeled Data"></a>Cleaning up Incorrectly Labeled Data</h4><ul>
<li>deep learning algorithms are quite robust to <strong>random</strong> errors in the training set</li>
<li>goal of dev set is to help you select between two classifiers A &amp; B</li>
<li>apply same process to your dev and test sets to make sure they continue to come from the same distribution</li>
<li>consider examining examples your algorithm got right as well as ones it got wrong</li>
<li>train and dev/test data may now come from slightly different distributing</li>
</ul>
<h4 id="Build-your-First-System-Quickly-and-then-Iterate"><a href="#Build-your-First-System-Quickly-and-then-Iterate" class="headerlink" title="Build your First System Quickly and then Iterate"></a>Build your First System Quickly and then Iterate</h4><ul>
<li>Set up dev / test set and metric</li>
<li>Build initial system quickly</li>
<li>Use bias / variance analysis and error analysis to prioritize next steps</li>
</ul>
<h3 id="Mismatched-Training-and-Dev-Test-Set"><a href="#Mismatched-Training-and-Dev-Test-Set" class="headerlink" title="Mismatched Training and Dev / Test Set"></a>Mismatched Training and Dev / Test Set</h3><h4 id="Training-and-Testing-on-Different-Distributions"><a href="#Training-and-Testing-on-Different-Distributions" class="headerlink" title="Training and Testing on Different Distributions"></a>Training and Testing on Different Distributions</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-9/1.png" alt="1"></p>
<ul>
<li><p><strong>Option 1</strong> ×</p>
<p>set up the dev set to optimize for a different distribution of data than what you actually care about.</p>
</li>
<li><p><strong>Option 2</strong> ✓</p>
<p>aiming the target where you want it to be</p>
</li>
</ul>
<h4 id="Bias-and-Variance-with-Mismatched-Data-Distributions"><a href="#Bias-and-Variance-with-Mismatched-Data-Distributions" class="headerlink" title="Bias and Variance with Mismatched Data Distributions"></a>Bias and Variance with Mismatched Data Distributions</h4><blockquote>
<p>increase in dev error <strong><em>(1)</em></strong> is because the algorithm didn’t see the data in the dev set <strong><em>(variance problem)</em></strong> or <strong><em>(2)</em></strong> is because the dev set data is just different <strong><em>(distribution problem)</em></strong></p>
</blockquote>
<p><strong><em>training-dev set:</em></strong> same distribution as training set, but not used for training</p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-9/2.png" alt="t-d"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:right">~ 0% Human Error&emsp;&emsp;</th>
<th style="text-align:center">Avoidable Bias</th>
<th style="text-align:center">Variance</th>
<th style="text-align:center">Data Mismatch</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>Training Error</strong>&emsp;&emsp;</td>
<td style="text-align:center">10 %</td>
<td style="text-align:center">1 %</td>
<td style="text-align:center">1 %</td>
</tr>
<tr>
<td style="text-align:right"><strong>Training-Dev Error</strong>&emsp;&emsp;</td>
<td style="text-align:center">11 %</td>
<td style="text-align:center">9 %</td>
<td style="text-align:center">1.5 %</td>
</tr>
<tr>
<td style="text-align:right"><strong>Dev Error</strong>&emsp;&emsp;</td>
<td style="text-align:center">12 %</td>
<td style="text-align:center">10 %</td>
<td style="text-align:center">10 %</td>
</tr>
</tbody>
</table>
</div>
<p>$\qquad \begin{aligned} \textrm{Human Level Error} &amp; \quad 4\% \\ &amp; \quad \updownarrow \qquad \textsf{avoidable bias} \\ \textrm{Training Set Error} &amp; \quad 7\% \\ &amp; \quad \updownarrow \qquad \textsf{variance} \\ \textrm{Training-Dev Set Error} &amp; \quad 10\% \\ &amp; \quad \updownarrow \qquad \textsf{data mismatch} \\ \textrm{Dev Set Error} &amp; \quad 6\% \\ &amp; \quad \updownarrow \qquad \textsf{degree of overfitting to dev set} \\ \textrm{Test Set Error} &amp; \quad 6\%  \end{aligned}$</p>
<h4 id="Addressing-Data-Mismatch"><a href="#Addressing-Data-Mismatch" class="headerlink" title="Addressing Data Mismatch"></a>Addressing Data Mismatch</h4><ul>
<li>carry out manual error analysis to try to understand difference between training and dev / test sets</li>
<li>make training data more similar; or collect more data similar to dev / test sets</li>
</ul>
<h5 id="Artificial-Data-Synthesis"><a href="#Artificial-Data-Synthesis" class="headerlink" title="Artificial Data Synthesis"></a>Artificial Data Synthesis</h5><p><strong><em>be careful:</em></strong> <em>overfit subsets</em></p>
<p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-9/3.png" alt="3"></p>
<h3 id="Learning-from-Multiple-Tasks"><a href="#Learning-from-Multiple-Tasks" class="headerlink" title="Learning from Multiple Tasks"></a>Learning from Multiple Tasks</h3><h4 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-9/4.png" alt="t"></p>
<p><strong>pre-training → fine-tuning</strong></p>
<ul>
<li>initialize the last layer’s weights W<sup>[L]</sup>, b<sup>[L]</sup></li>
<li>retrain the one last 1~2 layers (with small data set)<br>or retrain all the parameters in the network (with large data set)</li>
</ul>
<p><strong>when transfer learning makes sense</strong></p>
<ul>
<li>task A and B have the same input x</li>
<li>a lot more data for task A than task B</li>
<li>low level features from A could be helpful for learning B</li>
</ul>
<h4 id="Multi-Task-Learning"><a href="#Multi-Task-Learning" class="headerlink" title="Multi-Task Learning"></a>Multi-Task Learning</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-9/5.png" alt="t"></p>
<p>$\begin{aligned} \hat{y}^{\left(i\right)}_{\Tiny{4\times1}} = \frac{1}{m}\sum_{i=1}^{m}\sum_{j=1}^{4}L\left( \hat{y}^{\left(i\right)}_j,\,y^{\left(i\right)}_j \right) \end{aligned}$</p>
<p>one image can have multiple labels (unlike softmax regression)</p>
<p>multi-task learning works even if some of the images are labeled only some of the objects (sum over j with 0/1 label only)</p>
<p><strong>when multi-task learning makes sense</strong></p>
<ul>
<li>training on a set of tasks that could benefit from having shared lower-level features</li>
<li>usually, amount of data for each data is quite similar</li>
<li>can train a big enough neural network to do well on all the tasks</li>
</ul>
<h3 id="End-to-End-Deep-Learning"><a href="#End-to-End-Deep-Learning" class="headerlink" title="End-to-End Deep Learning"></a>End-to-End Deep Learning</h3><h4 id="What-is-End-to-End-Deep-Learning"><a href="#What-is-End-to-End-Deep-Learning" class="headerlink" title="What is End-to-End Deep Learning?"></a>What is End-to-End Deep Learning?</h4><p><img src="/post/Open-Course/Deep-Learning/Deep-Learning-Andrew-Ng-9/6.png" alt="e"></p>
<p><strong><em>Key question: Do you have sufficient data to learn the function of the complexity needed to map from X to Y?</em></strong></p>
<h4 id="Whether-to-Use-End-to-End-Deep-Learning"><a href="#Whether-to-Use-End-to-End-Deep-Learning" class="headerlink" title="Whether to Use End-to-End Deep Learning"></a>Whether to Use End-to-End Deep Learning</h4><ul>
<li><strong>Pros</strong><ul>
<li>let the data speak</li>
<li>less hand-designing of components needed</li>
</ul>
</li>
<li><strong>Cons</strong><ul>
<li>may need large amount of data</li>
<li>excludes potentially useful hand-designed components</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>GitHub · Changing Author Info</title>
    <url>/post/Programming/Git/GitHub-Changing-Author-Info/</url>
    <content><![CDATA[<p>Before running this script, you’ll need:</p>
<ul>
<li>The old email address that appears in the author/committer fields that you want to change</li>
<li>The correct name and email address that you would like such commits to be attributed to</li>
</ul>
<a id="more"></a>
<p><br></p>
<h5 id="Create-a-fresh-bare-clone-of-your-repository"><a href="#Create-a-fresh-bare-clone-of-your-repository" class="headerlink" title="Create a fresh, bare clone of your repository"></a>Create a fresh, bare clone of your repository</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone --bare https://hostname/user/repo.git</span><br><span class="line">cd repo.git</span><br></pre></td></tr></table></figure>
<p><br></p>
<h5 id="Copy-and-paste-the-script-replacing-the-following-variables-based-on-the-information-you-gathered"><a href="#Copy-and-paste-the-script-replacing-the-following-variables-based-on-the-information-you-gathered" class="headerlink" title="Copy and paste the script, replacing the following variables based on the information you gathered"></a>Copy and paste the script, replacing the following variables based on the information you gathered</h5><ul>
<li><code>OLD_EMAIL</code></li>
<li><code>CORRECT_NAME</code></li>
<li><code>CORRECT_EMAIL</code></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;sh</span><br><span class="line"></span><br><span class="line">git filter-branch --env-filter &#39;</span><br><span class="line"></span><br><span class="line">OLD_EMAIL&#x3D;&quot;your-old-email@example.com&quot;</span><br><span class="line">CORRECT_NAME&#x3D;&quot;Your Correct Name&quot;</span><br><span class="line">CORRECT_EMAIL&#x3D;&quot;your-correct-email@example.com&quot;</span><br><span class="line"></span><br><span class="line">if [ &quot;$GIT_COMMITTER_EMAIL&quot; &#x3D; &quot;$OLD_EMAIL&quot; ]</span><br><span class="line">then</span><br><span class="line">    export GIT_COMMITTER_NAME&#x3D;&quot;$CORRECT_NAME&quot;</span><br><span class="line">    export GIT_COMMITTER_EMAIL&#x3D;&quot;$CORRECT_EMAIL&quot;</span><br><span class="line">fi</span><br><span class="line">if [ &quot;$GIT_AUTHOR_EMAIL&quot; &#x3D; &quot;$OLD_EMAIL&quot; ]</span><br><span class="line">then</span><br><span class="line">    export GIT_AUTHOR_NAME&#x3D;&quot;$CORRECT_NAME&quot;</span><br><span class="line">    export GIT_AUTHOR_EMAIL&#x3D;&quot;$CORRECT_EMAIL&quot;</span><br><span class="line">fi</span><br><span class="line">&#39; --tag-name-filter cat -- --branches --tags</span><br></pre></td></tr></table></figure>
<p><br></p>
<h5 id="Review-the-new-Git-history-for-errors"><a href="#Review-the-new-Git-history-for-errors" class="headerlink" title="Review the new Git history for errors."></a>Review the new Git history for errors.</h5><p><br></p>
<h5 id="Push-the-corrected-history-to-GitHub-Enterprise"><a href="#Push-the-corrected-history-to-GitHub-Enterprise" class="headerlink" title="Push the corrected history to GitHub Enterprise:"></a>Push the corrected history to GitHub Enterprise:</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git push --force --tags origin &#x27;refs/heads/*&#x27;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Programming</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning (10) · Recommender Systems</title>
    <url>/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-10/</url>
    <content><![CDATA[<p>Stanford University, <strong>Machine Learning,</strong> <em>Andrew Ng,</em> <a href="https://www.coursera.org/learn/machine-learning/home/info">Coursera</a></p>
<p><strong><em>Week 9:</em></strong> Anomaly Detection, Recommender Systems <sup> <code>Part 2</code></sup></p>
<h3 id="Recommender-Systems"><a href="#Recommender-Systems" class="headerlink" title="Recommender Systems"></a>Recommender Systems</h3><h4 id="Predicting-Movie-Ratings"><a href="#Predicting-Movie-Ratings" class="headerlink" title="Predicting Movie Ratings"></a>Predicting Movie Ratings</h4><h5 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h5><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Movie</th>
<th style="text-align:center">Alice (1)</th>
<th style="text-align:center">Bob (2)</th>
<th style="text-align:center">Carol (3)</th>
<th style="text-align:center">Dave (4)</th>
<th style="text-align:center">$x_1$</th>
<th style="text-align:center">$x_2$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$x^\left(1\right)$</td>
<td style="text-align:center">5</td>
<td style="text-align:center">5</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center"><strong>0.9</strong></td>
<td style="text-align:center"><strong>0</strong></td>
</tr>
<tr>
<td style="text-align:center">$x^\left(2\right)$</td>
<td style="text-align:center">5</td>
<td style="text-align:center">?</td>
<td style="text-align:center">?</td>
<td style="text-align:center">0</td>
<td style="text-align:center"><strong>1.0</strong></td>
<td style="text-align:center"><strong>0.01</strong></td>
</tr>
<tr>
<td style="text-align:center">$x^\left(3\right)$</td>
<td style="text-align:center">?</td>
<td style="text-align:center">4</td>
<td style="text-align:center">0</td>
<td style="text-align:center">?</td>
<td style="text-align:center"><strong>0.99</strong></td>
<td style="text-align:center"><strong>0</strong></td>
</tr>
<tr>
<td style="text-align:center">$x^\left(4\right)$</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">5</td>
<td style="text-align:center">4</td>
<td style="text-align:center"><strong>0.1</strong></td>
<td style="text-align:center"><strong>1.0</strong></td>
</tr>
<tr>
<td style="text-align:center">$x^\left(5\right)$</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">5</td>
<td style="text-align:center">?</td>
<td style="text-align:center"><strong>0</strong></td>
<td style="text-align:center"><strong>0.9</strong></td>
</tr>
</tbody>
</table>
</div>
<a id="more"></a>
<h5 id="Content-Based-Recommendations"><a href="#Content-Based-Recommendations" class="headerlink" title="Content-Based Recommendations"></a>Content-Based Recommendations</h5><p>For each user $j$, learn a parameter $\theta^\left(j\right) \in\mathbb{R}^{n+1}$. Predict user $j$ as rating movie $i$ with $\left( \theta^\left(j\right) \right)^\mathsf{T} x^\left(i\right)$ stars.</p>
<p>$\qquad y^\left(1,\,3\right) = \left( \theta^\left(1\right) \right)^\mathsf{T} x^\left(3\right) = \begin{bmatrix} 0\\5\\0 \end{bmatrix} ^\mathsf{T} \begin{bmatrix} 1\\0.99\\0 \end{bmatrix} = 4.95$</p>
<p><strong>Problem Formulation</strong></p>
<ul>
<li>$n_u$: number of users</li>
<li>$n_m$: mumber of movies</li>
<li>$m^\left(j\right)$: number of movies rated by user $j$</li>
<li>$r\left(i,\,j\right)$: $1$ if user $j$ has rated movie $i$</li>
<li>$y^\left(i,\,j\right)$: rating given by user $j$ to movie $i$, defined only if $r\left(i,\,j\right)=1$</li>
<li>$\theta^\left(j\right)$: parameter vector for user $j$</li>
<li>$x^\left(i\right)$: feature vector for movie $i$</li>
</ul>
<p>For user $j$, movie $i$, predicted rating: $\left( \theta^\left(j\right) \right)^\mathsf{T} \left( x^\left(i\right) \right)$<br><br>To learn $\theta^\left(j\right)$:<br><br>$\qquad \displaystyle\min_{\theta^\left(j\right)} \: \dfrac{1}{2\,{\color{lightgrey} {m^\left(j\right)} }} \displaystyle\sum_{i:\:r\left(i,\,j\right)=1} \left( { \theta^\left(j\right) }^\mathsf{T} x^\left(i\right) -y^\left(i,\,j\right) \right)^2 +\dfrac{\lambda}{2\,{\color{lightgrey} {m^\left(j\right)} }} \displaystyle\sum_{k=1}^{n} \left(\theta_k^\left(j\right)\right)^2$<br><br>To learn $\theta^\left(1\right) ,\, \theta^\left(2\right) ,\, \dots ,\, \theta^\left(n_u\right)$:<br><br>$\qquad \displaystyle\min_{\theta^\left(1\right) ,\, \dots ,\, \theta^\left(n_u\right)} \: \dfrac{1}{2} \displaystyle\sum_{j=1}^{n_u} \displaystyle\sum_{i:\:r\left(i,\,j\right)=1} \left( { \theta^\left(j\right) }^\mathsf{T} x^\left(i\right) -y^\left(i,\,j\right) \right)^2 +\dfrac{\lambda}{2} \displaystyle\sum_{j=1}^{n_u} \displaystyle\sum_{k=1}^{n} \left(\theta_k^\left(j\right)\right)^2$<br><br>Gradient descent update:<br>$\qquad \begin{aligned} &amp; \theta_k^\left(j\right) := \theta_k^\left(j\right) - \alpha \left( \sum_{i:\:r\left(i,\,j\right)=1} \left( { \theta^\left(j\right) }^\mathsf{T} x^\left(i\right) -y^\left(i,\,j\right) \right) x_k^\left(i\right) \right) &amp; \textrm{for }k=0 \\ &amp; \theta_k^\left(j\right) := \theta_k^\left(j\right) - \alpha \left( \sum_{i:\:r\left(i,\,j\right)=1} \left( { \theta^\left(j\right) }^\mathsf{T} x^\left(i\right) -y^\left(i,\,j\right) \right) x_k^\left(i\right) +\lambda\,\theta_k^\left(j\right) \right) &amp; \textrm{for }k\neq0 \end{aligned}$</p>
<h4 id="Collaborative-Filtering"><a href="#Collaborative-Filtering" class="headerlink" title="Collaborative Filtering"></a>Collaborative Filtering</h4><h5 id="Collaborative-Filtering-1"><a href="#Collaborative-Filtering-1" class="headerlink" title="Collaborative Filtering"></a>Collaborative Filtering</h5><p>Given $\theta^\left(1\right) ,\, \theta^\left(2\right) ,\, \dots ,\, \theta^\left(n_u\right)$<br><br>To learn $x^\left(i\right)$:<br><br>$\qquad \displaystyle\min_{x^\left(i\right)} \: \dfrac{1}{2} \displaystyle\sum_{j:\:r\left(i,\,j\right)=1} \left( { \theta^\left(j\right) }^\mathsf{T} x^\left(i\right) -y^\left(i,\,j\right) \right)^2 +\dfrac{\lambda}{2} \displaystyle\sum_{k=1}^{n} \left(x_k^\left(i\right)\right)^2$<br><br>To learn $x^\left(1\right) ,\, x^\left(2\right) ,\, \dots ,\, x^\left(n_m\right)$:<br><br>$\qquad \displaystyle\min_{x^\left(1\right) ,\, \dots ,\, x^\left(n_m\right)} \: \dfrac{1}{2} \displaystyle\sum_{i=1}^{n_m} \displaystyle\sum_{j:\:r\left(i,\,j\right)=1} \left( { \theta^\left(j\right) }^\mathsf{T} x^\left(i\right) -y^\left(i,\,j\right) \right)^2 +\dfrac{\lambda}{2} \displaystyle\sum_{i=1}^{n_m} \displaystyle\sum_{k=1}^{n} \left(x_k^\left(i\right)\right)^2$</p>
<ul>
<li>Given $x^\left(1\right) ,\, x^\left(2\right) ,\, \dots ,\, x^\left(n_m\right)$, can estimate $\theta^\left(1\right) ,\, \theta^\left(2\right) ,\, \dots ,\, \theta^\left(n_u\right)$</li>
<li>Given $\theta^\left(1\right) ,\, \theta^\left(2\right) ,\, \dots ,\, \theta^\left(n_u\right)$, can estimate $x^\left(1\right) ,\, x^\left(2\right) ,\, \dots ,\, x^\left(n_m\right)$</li>
</ul>
<p>$\textsf{Guess } \theta \rightarrow x \rightarrow \theta \rightarrow x \rightarrow \theta \rightarrow x \rightarrow \cdots \textsf{until converge}$</p>
<h5 id="Collaborative-Filtering-Algorithm"><a href="#Collaborative-Filtering-Algorithm" class="headerlink" title="Collaborative Filtering Algorithm"></a>Collaborative Filtering Algorithm</h5><ul>
<li><p>Given $x^\left(1\right) ,\, x^\left(2\right) ,\, \dots ,\, x^\left(n_m\right)$, estimate $\theta^\left(1\right) ,\, \theta^\left(2\right) ,\, \dots ,\, \theta^\left(n_u\right)$:</p>
<p>$\qquad \displaystyle\min_{\theta^\left(1\right) ,\, \dots ,\, \theta^\left(n_u\right)} \: \dfrac{1}{2} \displaystyle\sum_{j=1}^{n_u} \displaystyle\sum_{i:\:r\left(i,\,j\right)=1} \left( { \theta^\left(j\right) }^\mathsf{T} x^\left(i\right) -y^\left(i,\,j\right) \right)^2 +\dfrac{\lambda}{2} \displaystyle\sum_{j=1}^{n_u} \displaystyle\sum_{k=1}^{n} \left(\theta_k^\left(j\right)\right)^2$</p>
</li>
<li><p>Given $\theta^\left(1\right) ,\, \theta^\left(2\right) ,\, \dots ,\, \theta^\left(n_u\right)$, estimate $x^\left(1\right) ,\, x^\left(2\right) ,\, \dots ,\, x^\left(n_m\right)$:</p>
<p>$\qquad \displaystyle\min_{x^\left(1\right) ,\, \dots ,\, x^\left(n_m\right)} \: \dfrac{1}{2} \displaystyle\sum_{i=1}^{n_m} \displaystyle\sum_{j:\:r\left(i,\,j\right)=1} \left( { \theta^\left(j\right) }^\mathsf{T} x^\left(i\right) -y^\left(i,\,j\right) \right)^2 +\dfrac{\lambda}{2} \displaystyle\sum_{i=1}^{n_m} \displaystyle\sum_{k=1}^{n} \left(x_k^\left(i\right)\right)^2$</p>
</li>
</ul>
<p>Minimizing $x^\left(1\right) ,\, x^\left(2\right) ,\, \dots ,\, x^\left(n_m\right)$ and $\theta^\left(1\right) ,\, \theta^\left(2\right) ,\, \dots ,\, \theta^\left(n_u\right)$ simultaneously:<br><br>$\qquad \displaystyle\min_{ \substack{ x^\left(1\right) ,\,\dots,\, x^\left(n_m\right) , \\ \theta^\left(1\right) ,\,\dots,\, \theta^\left(n_u\right) } } J\left( x^\left(1\right) ,\,\dots,\, x^\left(n_m\right) ,\, \theta^\left(1\right) ,\,\dots,\, \theta^\left(n_u\right) \right)$ $\qquad x \in \mathbb{R}^n ,\ \theta \in \mathbb{R}^n$<br><br>$\qquad J\left( x^\left(1\right) ,\,\dots,\, x^\left(n_m\right) ,\, \theta^\left(1\right) ,\,\dots,\, \theta^\left(n_u\right) \right) = \dfrac{1}{2} \displaystyle\sum_{\left(i,\,j\right):\:r\left(i,\,j\right)=1} \left( { \theta^\left(j\right) }^\mathsf{T} x^\left(i\right) -y^\left(i,\,j\right) \right)^2 +\dfrac{\lambda}{2} \displaystyle\sum_{i=1}^{n_m} \displaystyle\sum_{k=1}^{n} \left(x_k^\left(i\right)\right)^2 +\dfrac{\lambda}{2} \displaystyle\sum_{j=1}^{n_u} \displaystyle\sum_{k=1}^{n} \left(\theta_k^\left(j\right)\right)^2$</p>
<p><strong>Collaborative Filtering Algorithm</strong></p>
<ol>
<li><p>Initialize $x^\left(1\right) ,\,\dots,\, x^\left(n_m\right) ,\, \theta^\left(1\right) ,\,\dots,\, \theta^\left(n_u\right)$ to small random values.</p>
</li>
<li><p>Minimize $J\left( x^\left(1\right) ,\,\dots,\, x^\left(n_m\right) ,\, \theta^\left(1\right) ,\,\dots,\, \theta^\left(n_u\right) \right)$ using gradient descent (or advanced optimization algorithms).</p>
<p>$\qquad \begin{aligned} &amp; x_k^\left(i\right) := x_k^\left(i\right) - \alpha \left( \sum_{j:\:r\left(i,\,j\right)=1} \left( { \theta^\left(j\right) }^\mathsf{T} x^\left(i\right) -y^\left(i,\,j\right) \right) x_k^\left(i\right) +\lambda\,x_k^\left(i\right) \right) &amp; \textrm{for every } j=1,\,\dots,\,n_u \\ &amp; \theta_k^\left(j\right) := \theta_k^\left(j\right) - \alpha \left( \sum_{i:\:r\left(i,\,j\right)=1} \left( { \theta^\left(j\right) }^\mathsf{T} x^\left(i\right) -y^\left(i,\,j\right) \right) x_k^\left(i\right) +\lambda\,\theta_k^\left(j\right) \right) &amp; \textrm{for every } i=1,\,\dots,\,n_m \end{aligned}$</p>
</li>
<li><p>For a user with parameters $\theta$ and a movie with <em>learned</em> features $x$, predict a star rating of $\theta^\mathsf{T}x$.</p>
</li>
</ol>
<h4 id="Low-Rank-Matrix-Factorization"><a href="#Low-Rank-Matrix-Factorization" class="headerlink" title="Low-Rank Matrix Factorization"></a>Low-Rank Matrix Factorization</h4><h5 id="Vectorization-Low-Rank-Matrix-Factorization"><a href="#Vectorization-Low-Rank-Matrix-Factorization" class="headerlink" title="Vectorization: Low-Rank Matrix Factorization"></a>Vectorization: Low-Rank Matrix Factorization</h5><p>$X = \begin{bmatrix} \substack{\rule{25pt}{0.5pt}\\\\} \ \left( x^\left(1\right) \right) ^\mathsf{T} \ \substack{\rule{25pt}{0.5pt}\\\\} \\ \substack{\rule{25pt}{0.5pt}\\\\} \ \left( x^\left(2\right) \right) ^\mathsf{T} \ \substack{\rule{25pt}{0.5pt}\\\\} \\ \vdots \\ \substack{\rule{25pt}{0.5pt}\\\\} \ \left( x^\left(n_m\right) \right) ^\mathsf{T} \ \substack{\rule{25pt}{0.5pt}\\\\} \end{bmatrix} \qquad\qquad \Theta = \begin{bmatrix} \substack{\rule{25pt}{0.5pt}\\\\} \ \left( \theta^\left(1\right) \right) ^\mathsf{T} \ \substack{\rule{25pt}{0.5pt}\\\\} \\ \substack{\rule{25pt}{0.5pt}\\\\} \ \left( \theta^\left(2\right) \right) ^\mathsf{T} \ \substack{\rule{25pt}{0.5pt}\\\\} \\ \vdots \\ \substack{\rule{25pt}{0.5pt}\\\\} \ \left( \theta^\left(n_u\right) \right) ^\mathsf{T} \ \substack{\rule{25pt}{0.5pt}\\\\} \end{bmatrix}$</p>
<p>Predicted ratings: $X\Theta^\mathsf{T}$</p>
<p><strong>Finding Related Movies</strong></p>
<p>small distance $\left| x^\left(i\right) - x^\left(j\right) \right|$ $\rightarrow$ “similar” movies</p>
<h5 id="Implementational-Detail-Mean-Normalization"><a href="#Implementational-Detail-Mean-Normalization" class="headerlink" title="Implementational Detail: Mean Normalization"></a>Implementational Detail: Mean Normalization</h5><p>users who have not rated any movies</p>
<p>$\qquad \displaystyle\min_{ \substack{ x^\left(1\right) ,\,\dots,\, x^\left(n_m\right) , \\ \theta^\left(1\right) ,\,\dots,\, \theta^\left(n_u\right) } } \dfrac{\lambda}{2} \displaystyle\sum_{j=1}^{n_u} \displaystyle\sum_{k=1}^{n} \left(\theta_k^\left(j\right)\right)^2 \:\Rightarrow\: \theta=\vec{0} \:\Rightarrow\: \theta^\mathsf{T}x=0$</p>
<p><strong>Mean Normalization</strong></p>
<p>$Y=\begin{bmatrix} 5&amp;5&amp;0&amp;0&amp;? \\ 5&amp;?&amp;?&amp;0&amp;? \\ ?&amp;4&amp;0&amp;?&amp;? \\ 0&amp;0&amp;5&amp;4&amp;? \\ 0&amp;0&amp;5&amp;0&amp;? \end{bmatrix} \qquad\qquad \mu=\begin{bmatrix} 2.5\\2.5\\2\\2.25\\1.25 \end{bmatrix} \:\rightarrow\: Y=\begin{bmatrix} 2.5&amp;2.5&amp;-2.5&amp;-2.5&amp;? \\ 2.5&amp;?&amp;?&amp;-2.5&amp;? \\ ?&amp;2&amp;-2&amp;?&amp;? \\ -2.25&amp;-2.25&amp;2.75&amp;1.75&amp;? \\ -1.25&amp;-1.25&amp;3.75&amp;-1.25&amp;? \end{bmatrix} \:\rightarrow\: \textsf{learn } \theta^\left(j\right),\,x^\left(i\right)$</p>
<p>For user $j$ on movie $i$, predict $\left(\theta^\left(j\right)\right)\left(x^\left(i\right)\right)+\mu_i$<br><br>$\qquad$new users: $\theta=\vec{0} \:\Rightarrow\: \left(\theta^\left(j\right)\right)\left(x^\left(i\right)\right)+\mu_i = \mu_i$</p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning (1) · Linear Regression · I</title>
    <url>/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-1/</url>
    <content><![CDATA[<p>Stanford University, <strong>Machine Learning,</strong> <em>Andrew Ng,</em> <a href="https://www.coursera.org/learn/machine-learning/home/info">Coursera</a></p>
<p><strong><em>Week 1:</em></strong> Introduction, Linear Regression with One Variable</p>
<h3 id="Machine-Learning-Introduction"><a href="#Machine-Learning-Introduction" class="headerlink" title="Machine Learning Introduction"></a>Machine Learning Introduction</h3><p>Machine learning is the field of study that gives computers the ability to learn without being explicitly programmed.</p>
<p><strong><em>Definition:</em></strong> a computer program is said to learn from <strong>experience E</strong> with respect to some <strong>task T</strong> and some performance <strong>measure P,</strong> if its performance on T, as measured by P, improves with experience E.</p>
<a id="more"></a>
<h4 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h4><ul>
<li><strong>Supervised Learning</strong><br><em>Given the “right answer” for each of our examples</em><ul>
<li><strong>Regression:</strong> Predict real-valued output</li>
<li><strong>Classification:</strong> Predict discrete-valued output</li>
</ul>
</li>
<li><strong>Unsupervised Learning</strong><ul>
<li><strong>Clustering</strong></li>
<li><strong>Non-clustering</strong> <em>(The Cocktail Party Algorithm)</em></li>
</ul>
</li>
<li><strong>Reinforcement Learning</strong></li>
<li><strong>Recommender Systems</strong></li>
</ul>
<h3 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h3><ul>
<li><strong>Model Representation</strong><ul>
<li><strong>m</strong> = number of training examples</li>
<li><strong>x’</strong>s = <em>input</em> variable / features</li>
<li><strong>y’</strong>s = <em>output</em> variable / <em>target</em> variable</li>
<li><strong>(x<sup>(i)</sup>, y<sup>(i)</sup>)</strong> = i<sup>th</sup> training example</li>
</ul>
</li>
</ul>
<h4 id="Linear-Regression-with-One-Variable-univariate-linear-regression"><a href="#Linear-Regression-with-One-Variable-univariate-linear-regression" class="headerlink" title="Linear Regression with One Variable (univariate linear regression)"></a>Linear Regression with One Variable <em>(univariate linear regression)</em></h4><p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-1/ModelRepresentation.png" alt="Model Representation"></p>
<ul>
<li><p><strong><em>Parameters:</em></strong> $\theta _{0},\theta _{1}$</p>
</li>
<li><p><strong><em>Hypothesis:</em></strong> $h_{\theta }\left( x\right) =\theta _{0}+\theta _{1}x$</p>
</li>
<li><p><strong><em>Cost Function:</em></strong> $J\left( \theta _{0},\theta _{1}\right) =  \dfrac {1}{2m} \sum ^{m}_{i=1}\left( h_{\theta }\left( x^{\left(i\right)}\right) -y^{\left(i\right)}\right) ^{2} $ <em>(squared error function)</em></p>
</li>
<li><p><strong><em>Goal:</em></strong> $\min _{\theta _{0},\theta _{1}}J\left( \theta _{0},\theta _{1}\right) $ <em>(minimize the cost function)</em></p>
</li>
</ul>
<h3 id="Parameter-Learning"><a href="#Parameter-Learning" class="headerlink" title="Parameter Learning"></a>Parameter Learning</h3><p>$\min _{\theta _{0},\theta _{1},…,\theta _{n}}J\left( \theta _{0},\theta _{1},…,\theta _{n}\right) $ </p>
<h4 id="Gradient-Descent-Outline"><a href="#Gradient-Descent-Outline" class="headerlink" title="Gradient Descent Outline"></a>Gradient Descent Outline</h4><ul>
<li>Start with some $\theta _{0},\theta _{1}$</li>
<li>Keep changing $\theta _{0},\theta _{1}$ to reduce $J\left( \theta _{0},\theta _{1}\right) $ until end up at a <em>(local)</em> minimum</li>
</ul>
<h4 id="Gradient-Descent-Algorithm"><a href="#Gradient-Descent-Algorithm" class="headerlink" title="Gradient Descent Algorithm"></a>Gradient Descent Algorithm</h4><p><strong><em>repeat until convergence:</em></strong><br>&emsp;&emsp;$\theta _{j}:=\theta _{j}-\alpha \cdot \dfrac {\partial }{\partial \theta _{j}}J\left( \theta _{0},\theta _{1}\right)$&emsp;&emsp;<em>for $j=0$ and $j=1$</em></p>
<ul>
<li><strong>Simultaneously</strong> Update θ<sub>0</sub> and θ<sub>1</sub></li>
<li><p><strong>Learning Rate</strong> $\alpha$</p>
<ul>
<li><strong>too small:</strong> slow</li>
<li><strong>too large:</strong> overshoot <em>(fail to converge / diverge)</em></li>
</ul>
<p><em>As we approach a local minimum, the derivative term will automatically get smaller, and so gradient descent will automatically take smaller steps, no need to decrease α over time.</em></p>
</li>
</ul>
<h4 id="Gradient-Descent-For-Linear-Regression"><a href="#Gradient-Descent-For-Linear-Regression" class="headerlink" title="Gradient Descent For Linear Regression"></a>Gradient Descent For Linear Regression</h4><p><strong><em>“Batch” Gradient Decent:</em></strong> Each step uses all training examples</p>
<p>$\begin{equation} \begin{aligned} \dfrac {\partial }{\partial \theta _{j}}J\left( \theta _{0},\theta _{1}\right) &amp; = \dfrac {\partial }{\partial \theta _{j}} \dfrac {1}{2m} \sum ^{m}_{i=1}\left( h_{\theta }\left( x^{\left(i\right)}\right) -y^{\left(i\right)}\right) ^{2} \\&amp; = \dfrac {\partial }{\partial \theta _{j}} \dfrac {1}{2m} \sum ^{m}_{i=1}\left( \theta _{0}+\theta _{1}x^{\left(i\right)} -y^{\left(i\right)}\right) ^{2} \end{aligned} \end{equation}$</p>
<p>$\begin{aligned} \theta _{0}=\dfrac {\partial }{\partial \theta _{0}}J\left( \theta _{0},\theta _{1}\right) = \dfrac {1}{m} \sum ^{m}_{i=1}\left( h_{\theta }\left( x^{\left(i\right)}\right) -y^{\left(i\right)}\right) \end{aligned}$</p>
<p>$\begin{aligned} \theta _{1}=\dfrac {\partial }{\partial \theta _{1}}J\left( \theta _{0},\theta _{1}\right) = \dfrac {1}{m} \sum ^{m}_{i=1}\left( h_{\theta }\left( x^{\left(i\right)}\right) -y^{\left(i\right)}\right) \cdot x^{\left(i\right)} \end{aligned}$</p>
<p><strong><em>repeat until convergence:</em></strong><br>&emsp;&emsp;$\begin{aligned} \theta _{0}:=\theta _{0}-\alpha \cdot \dfrac {1}{m} \sum ^{m}_{i=1}\left( h_{\theta }\left( x^{\left(i\right)}\right) -y^{\left(i\right)}\right) \end{aligned}$<br>&emsp;&emsp;$\begin{aligned} \theta _{1}:=\theta _{1}-\alpha \cdot \dfrac {1}{m} \sum ^{m}_{i=1}\left( h_{\theta }\left( x^{\left(i\right)}\right) -y^{\left(i\right)}\right) \cdot x^{\left(i\right)} \end{aligned}$&emsp;&emsp;<strong><em>simultaneously</em></strong></p>
<p><em>The cost function for linear regression is always going to be a convex function that doesn’t have any local optima except for the one global optimum.</em></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning (2) · Linear Regression · II</title>
    <url>/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-2/</url>
    <content><![CDATA[<p>Stanford University, <strong>Machine Learning,</strong> <em>Andrew Ng,</em> <a href="https://www.coursera.org/learn/machine-learning/home/info">Coursera</a></p>
<p><strong><em>Week 2:</em></strong> Multivariate Linear Regression</p>
<h3 id="Linear-Regression-with-Multiple-Variables"><a href="#Linear-Regression-with-Multiple-Variables" class="headerlink" title="Linear Regression with Multiple Variables"></a>Linear Regression with Multiple Variables</h3><ul>
<li><strong><em>m:</em></strong> number of training examples</li>
<li><strong><em>n:</em></strong> number of features</li>
<li><strong><em>x<sup>(i)</sup>:</em></strong> input features of i<sup>th</sup> training example</li>
<li><strong><em>x<sub>j</sub><sup>(i)</sup>:</em></strong> value of feature j in i<sup>th</sup> training example</li>
</ul>
<a id="more"></a>
<h4 id="Multivariate-Linear-Regression"><a href="#Multivariate-Linear-Regression" class="headerlink" title="Multivariate Linear Regression"></a>Multivariate Linear Regression</h4><p>$h_\theta \left(x\right) = \theta_0 + \theta_1x_1 + \theta_2x_2 + \dots + \theta_nx_n$</p>
<p>$\begin{aligned}&amp; x_0 = 0, \quad x = \left[ \begin{matrix} x_0 \\ x_1 \\ x_2 \\ \vdots \\ x_n \end{matrix} \right] \in \mathbb{R} ^{n+1} \qquad \theta= \left[ \begin{matrix} \theta_0 \\ \theta_1 \\ \theta_2 \\ \vdots \\ \theta_n \end{matrix} \right] \in \mathbb{R} ^{n+1} \\ &amp; h_\theta \left(x\right) ^{\strut} = \theta_0 + \theta_1x_1 + \theta_2x_2 + \dots + \theta_nx_n = \theta^{\mathsf{T}} x \end{aligned}$</p>
<h4 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h4><h5 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function"></a>Cost Function</h5><p>$\begin{aligned} J\left(\theta\right) = \dfrac{1}{2m} \sum_{i=1}^{m} \left( h_\theta\left( x^\left(i\right) \right) - y^\left(i\right) \right) ^2 \end{aligned}$</p>
<h5 id="Gradient-Descent-1"><a href="#Gradient-Descent-1" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h5><p>$\begin{aligned} &amp; \textsf{repeat:} \\ &amp; \qquad \theta_j := \theta_j - \alpha \cdot \dfrac{\partial}{\partial \theta_j} J\left(\theta\right) = \theta_j - \alpha \cdot \dfrac{1}{m} \sum_{i=1}^{m} \left( h_\theta\left( x^\left(i\right) \right) - y^\left(i\right) \right) x_j ^\left(i\right) \\ &amp; \qquad \text{simultaneously update for every } j=0,\,\dots,\,n \end{aligned}$</p>
<h5 id="Feature-Scaling"><a href="#Feature-Scaling" class="headerlink" title="Feature Scaling"></a>Feature Scaling</h5><p>make sure features are on a similar scale<br>get every feature into approximately a [-1, 1] range</p>
<h5 id="Mean-Normalization"><a href="#Mean-Normalization" class="headerlink" title="Mean Normalization"></a>Mean Normalization</h5><p>replace x<sub>i</sub> with x<sub>i</sub> - μ<sub>i</sub> to make features have approximately zero mean<br><em>(do not apply to x<sub>0</sub> = 1)</em></p>
<p>$x_i = \dfrac{x_i - \mu_i}{s_i}$</p>
<ul>
<li><strong><em>μ<sub>i</sub>:</em></strong> average value of x<sub>i</sub></li>
<li><strong><em>s<sub>i</sub>:</em></strong> range of x<sub>i</sub> (max - min) or standard deviation</li>
</ul>
<h5 id="Learning-Rate"><a href="#Learning-Rate" class="headerlink" title="Learning Rate"></a>Learning Rate</h5><p>plot (J - #iters) to fix overshooting problems</p>
<h5 id="Polynomial-Regression"><a href="#Polynomial-Regression" class="headerlink" title="Polynomial Regression"></a>Polynomial Regression</h5><p>$x_1 = x \quad x_2 = x^2 \quad x_3 = x^3$</p>
<h3 id="Normal-Equation"><a href="#Normal-Equation" class="headerlink" title="Normal Equation"></a>Normal Equation</h3><p>$\textrm{Solve for } \theta_0,\,\theta_1,\,\dots,\,\theta_n\ \ s.t.\ \ \frac{\partial}{\partial \theta_j} J\left(\theta\right) = 0 \textrm{  for every } j$</p>
<p>$\begin{aligned} X &amp;= \left[ \begin{matrix} 1&amp;2104&amp;5&amp;1&amp;45 \\ 1&amp;1416&amp;3&amp;2&amp;40 \\ 1&amp;1534&amp;3&amp;2&amp;30 \\ 1&amp;852&amp;2&amp;1&amp;36 \end{matrix} \right] \qquad y= \left[ \begin{matrix} 460\\232\\315\\178 \end{matrix} \right] _{m=4} \\\\ x &amp;= \left[ \begin{matrix} x_0^{\left(i\right)} \\ x_1^{\left(i\right)} \\ \vdots \\ x_n^{\left(i\right)} \end{matrix} \right] \in \mathbb{R} ^{n+1} \qquad X = \left[ \begin{matrix} \rule[3pt]{3em}{0.05em} &amp; \left( x^{\left(1\right)}\right) ^{\mathsf{T}} &amp; \rule[3pt]{3em}{0.05em} \\ \rule[3pt]{3em}{0.05em} &amp; \left( x^{\left(2\right)}\right) ^{\mathsf{T}} &amp; \rule[3pt]{3em}{0.05em} \\ &amp;\vdots&amp; \\ \rule[3pt]{3em}{0.05em} &amp; \left( x^{\left(m\right)}\right) ^{\mathsf{T}} &amp; \rule[3pt]{3em}{0.05em} \end{matrix} \right] \in \mathbb{R} ^{m \times \left(n+1\right)} \qquad y= \left[ \begin{matrix} y^{\left(1\right)} \\ y^{\left(2\right)} \\ \vdots \\ y^{\left(m\right)} \end{matrix} \right] \in \mathbb{R} ^{m} \\ &amp; \Rightarrow ^{\strut} \quad \theta = \left(X^{\mathsf{T}}X\right)^{-1} X^{\mathsf{T}} y \end{aligned}$</p>
<ul>
<li><strong>Gradient Descent</strong><ul>
<li>need to choose α</li>
<li>needs many iterations</li>
<li>work well even when n is large</li>
</ul>
</li>
<li><strong>Normal Equation</strong><ul>
<li>no need to choose α</li>
<li>do not need to iterate</li>
<li>need to compute (X<sup>T</sup>X)<sup>-1</sup></li>
<li>slow if n is very large</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Game Theory (1)</title>
    <url>/post/Open-Course/Game-Theory/Game-Theory-Ben-Polak-1/</url>
    <content><![CDATA[<p>Yale University, <strong>Game Theory,</strong> Economics 159</p>
<blockquote>
<p>Game theory is a method of studying strategic situations.</p>
</blockquote>
<p><br></p>
<h2 id="Class-1-Prisoners’-Dilemma"><a href="#Class-1-Prisoners’-Dilemma" class="headerlink" title="Class 1 - Prisoners’ Dilemma"></a>Class 1 - Prisoners’ Dilemma</h2><div class="note default">
            <h4 id="Game-1"><a href="#Game-1" class="headerlink" title="Game 1"></a>Game 1</h4><p>$\begin{matrix} &amp; \begin{matrix} \textrm{Pair} \end{matrix} &amp;&amp;&amp; \textrm{payoffs} \textit{  (evil gits)} &amp;&amp; \textrm{payoffs} \textit{  (indignant angels)} \\ \begin{matrix} \\ \textrm{Me} \end{matrix} &amp; \begin{matrix} &amp;\alpha&amp;\beta \\ \alpha&amp;\textrm{B-, B-}&amp;\textrm{A, C} \\ \beta&amp;\textrm{C, A}&amp;\textrm{B+, B+} \end{matrix} &amp;&amp;&amp; \begin{matrix} &amp;\alpha&amp;\beta \\ \alpha&amp;0,0&amp;3,-1 \\ \beta&amp;-1,3&amp;1,1 \end{matrix} &amp;&amp; \begin{matrix} &amp;\alpha&amp;\beta \\ \alpha&amp;0,0&amp;-1,-3 \\ \beta&amp;-3,-1&amp;1,1 \end{matrix} \\ &amp; &amp;&amp;&amp; {}_\texttt{Prisoners’ Dilemma} &amp;&amp; {}_\texttt{Coordination Problem} \end{matrix}$</p>
          </div>
<a id="more"></a>
<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p style="text-align:left!important"><strong>Lesson 1:</strong> Do not play a strictly <em>(weakly)</em> dominated strategy.</p>
<p style="text-align:left!important"><strong>Lesson 2:</strong> Rational choice can lead to outcomes that "suck" <em>(Pareto Inefficient)</em>. &emsp; <strong>Prisoners' Dilemma</strong></p>
<p style="text-align:left!important"><strong>Lesson 3:</strong> You can't get what you want till you know what you want <em>(payoffs)</em>.</p>
<p style="text-align:left!important"><strong>Lesson 4:</strong> Put yourself in others' shoes and try to figure out what they will do.</p>
<p style="text-align:left!important"><strong>Lesson 5:</strong> Yale students are evil.</p>
            <i class="fa fa-quote-right"></i>
          </blockquote>
<p><br></p>
<h2 id="Class-2-Deleting-Dominated-Strategies"><a href="#Class-2-Deleting-Dominated-Strategies" class="headerlink" title="Class 2 - Deleting Dominated Strategies"></a>Class 2 - Deleting Dominated Strategies</h2><p>$ \textrm{ingredients of a game: } \begin{cases} \texttt{players} \\ \texttt{strategies} \\ \texttt{payoffs} \end{cases}$</p>
<div class="note default">
            <h4 id="Game-2"><a href="#Game-2" class="headerlink" title="Game 2"></a>Game 2</h4><p>Pick a number between 1 and 100. The winner is the person whose number is closest to 2/3 times the average number.</p><p>$\begin{cases} 67 \sim 100 \ \ &amp; &amp; \textrm{weakly dominated} &amp; \textit{ lesson 1} \\ 45 \sim 67 &amp; \texttt{rationality} &amp; \textrm{weakly dominated after delete 67~100} &amp; \textit{ lesson 4} \\ 30 \sim 45 &amp; \texttt{know others are rational} &amp; \textrm{weakly dominated after delete 45~67 and 67~100} &amp; \textit{ in shoes in shoes} \\ \,\vdots &amp;&amp; \texttt{iterative deletion of dominated strategies} \\ 1 &amp; \texttt{R, KR, KKR, KKKR, …} &amp; {}_\texttt{Common Knowledge} \end{cases}$</p><p><strong><em>Mutual knowledge doesn’t imply common knowledge.</em></strong></p>
          </div>
<p><br></p>
<h2 id="Class-3-Median-Voter-Theorem"><a href="#Class-3-Median-Voter-Theorem" class="headerlink" title="Class 3 - Median Voter Theorem"></a>Class 3 - Median Voter Theorem</h2><div class="note default">
            <h4 id="Game-3"><a href="#Game-3" class="headerlink" title="Game 3"></a>Game 3</h4><p><strong>model of politics:</strong> 2 candidates, uniformly distributed voters, $\textrm{choose: }\xrightarrow[\textrm{political spectrum}]{1\,2\,3\,4\,5\,6\,7\,8\,9\,10}$</p><p>$\begin{matrix} \textrm{2 strictly dominates 1} \\  \textrm{9 strictly dominates 10} \end{matrix} \longrightarrow \begin{matrix} \textrm{3 strictly dominates 2} \\  \textrm{8 strictly dominates 9} \end{matrix} \cdots\xrightarrow[\texttt{ dominated strategies }]{\texttt{ iterative deletion of }}\cdots \begin{matrix} \textrm{5 strictly dominates 4} \\  \textrm{6 strictly dominates 7} \end{matrix}$</p><p><strong>Median Voter Theorem:</strong> candidates close to each other, close to the center</p>
          </div>
<p><br></p>
<h2 id="Class-4-Best-Response"><a href="#Class-4-Best-Response" class="headerlink" title="Class 4 - Best Response"></a>Class 4 - Best Response</h2><div class="note default">
            <h4 id="Game-4"><a href="#Game-4" class="headerlink" title="Game 4"></a>Game 4</h4><p>$\begin{matrix} &amp;L&amp;R \\ U&amp;5,1&amp;0,2 \\ M&amp;1,3&amp;4,1 \\ D&amp;4,2&amp;2,3 \end{matrix} \qquad \begin{matrix} \textit{U does best against L} \\ \textit{M does best against R} \end{matrix}\quad \texttt{best response based on belief} $</p><p><img src="/post/Open-Course/Game-Theory/Game-Theory-Ben-Polak-1/1.png" alt="Best Response"></p>
          </div>
<div class="note default">
            <h4 id="Game-5"><a href="#Game-5" class="headerlink" title="Game 5"></a>Game 5</h4><p><strong>Penalty Kick Game</strong></p><p>$\begin{matrix} &amp;L&amp;R \\ U&amp;4,-4&amp;9,-9 \\ M&amp;6,-6&amp;6,-6 \\ D&amp;9,-9&amp;4,-4 \end{matrix} \qquad \begin{matrix} \textrm{no dominated strategies, but:} \\ \textrm{M is not a best response to any belief} \end{matrix}$</p><p><img src="/post/Open-Course/Game-Theory/Game-Theory-Ben-Polak-1/2.png" alt="Best Response"></p>
          </div>
<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p style="text-align:left!important"><strong>Lesson 6:</strong> Do not choose a strategy that is never a best response to any belief.</p>
            <i class="fa fa-quote-right"></i>
          </blockquote>
<div class="note default">
            <h4 id="Game-6"><a href="#Game-6" class="headerlink" title="Game 6"></a>Game 6</h4><p><strong>Partnership Game:</strong> 2 agents, own firm jointly, share $50\%$ of the profit each. Each agent chooses the effort level to put in the firm, $S_i\in\left[\,0,4\,\right]$ <em>(continuum)</em>. The frim profit is given by $4\left(s_1+s_2+b\cdot s_1\,s_2\right),\,\Tiny{0\leq b\leq1/4}$. Payoffs are: $U_1\left(s_1,\,s_2\right)=1/2\cdot4\left(s_1+s_2+b\cdot s_1\,s_2\right)-s_1^2$, $U_2\left(s_1,\,s_2\right)=1/2\cdot4\left(s_1+s_2+b\cdot s_1\,s_2\right)-s_2^2$</p><p>$\max_{s_1}2\left(s_1+s_2+b\cdot s_1\,s_2\right)-s_1^2$</p><p>$\dfrac{\partial U_1}{\partial s_1} = 2 + 2b\,s_2 - 2 \hat s_1 =0 \quad\Rightarrow\quad \mathrm{BR}_1\left(s_2\right) = \hat s_1 = 1 + b\,s_2 \,,\,\, \mathrm{BR}_2\left(s_1\right) = \hat s_2 = 1 + b\,s_1$</p><p><img src="/post/Open-Course/Game-Theory/Game-Theory-Ben-Polak-1/3.png" alt="Best Response"></p><p>$\texttt{iterative deletion until converge} \quad\Rightarrow\quad s_1^\ast = s_2^\ast = \dfrac{1}{1-b} \qquad {}_\texttt{Nash Equilibrium}$</p><p><strong>Externality:</strong> my effort benefits you, not just for me.</p>
          </div>
<p><br></p>
<h2 id="Class-5-Nash-Equilibrium-Coordination-Problems"><a href="#Class-5-Nash-Equilibrium-Coordination-Problems" class="headerlink" title="Class 5 - Nash Equilibrium (Coordination Problems)"></a>Class 5 - Nash Equilibrium (Coordination Problems)</h2><p><strong>Nash Equilibrium:</strong> players are playing a best response to each other. no individual can do <strong>strictly</strong> better by deviating, holding everyone else’s actions <em>(no regrets)</em>.</p>
<div class="note default">
            <h4 id="Game-7"><a href="#Game-7" class="headerlink" title="Game 7"></a>Game 7</h4><p>$\begin{matrix} &amp; \begin{matrix} \textrm{P2} \end{matrix}  \\ \begin{matrix} \\ \textrm{P1} \end{matrix} &amp; \begin{matrix} &amp;L&amp;C&amp;R \\ U&amp;0,\hat4&amp;\hat4,0&amp;5,3 \\ M&amp;\hat4,0&amp;0,\hat4&amp;5,3 \\ D&amp;3,5&amp;3,5&amp;\hat6,\hat6 \end{matrix} &amp;&amp;&amp; \begin{cases} \mathrm{BR}_1\left(L\right)=M \\ \mathrm{BR}_1\left(C\right)=U \\ \mathrm{BR}_1\left(R\right)=D \end{cases} &amp; \begin{cases} \mathrm{BR}_2\left(U\right)=L \\ \mathrm{BR}_2\left(M\right)=C \\ \mathrm{BR}_2\left(D\right)=R \end{cases} \\ &amp; &amp;&amp;&amp;\Rightarrow\ \mathrm{NE} = \left(D,R\right) \end{matrix}$</p><p>$\begin{matrix} &amp; \begin{matrix} \textrm{P2} \end{matrix}  \\ \begin{matrix} \\ \textrm{P1} \end{matrix} &amp; \begin{matrix} &amp;L&amp;C&amp;R \\ U&amp;0,2&amp;2,\hat3&amp;4,\hat3 \\ M&amp;\hat9,1&amp;\hat3,\hat2&amp;0,0 \\ D&amp;0,\hat3&amp;1,0&amp;\hat8,0 \end{matrix} &amp;&amp;&amp; \begin{cases} \mathrm{BR}_1\left(L\right)=M \\ \mathrm{BR}_1\left(C\right)=M \\ \mathrm{BR}_1\left(R\right)=D \end{cases} &amp; \begin{cases} \mathrm{BR}_2\left(U\right)=C,R \\ \mathrm{BR}_2\left(M\right)=C \\ \mathrm{BR}_2\left(D\right)=L \end{cases} \\ &amp; &amp;&amp;&amp;\Rightarrow\ \mathrm{NE} = \left(M,C\right) \end{matrix}$</p>
          </div>
<div class="note default">
            <h4 id="Game-8"><a href="#Game-8" class="headerlink" title="Game 8"></a>Game 8</h4><p><strong>Investment Game:</strong> choose: invest $0$ or $10$ dollar.<br>if you do not invest, $\mathrm{payoff}=0$, if you invest, $\mathrm{payoff}=\begin{cases}\$5&amp;\textrm{if }\geq90\%\textrm{ invest}&amp;\texttt{coordination} \\ -\$10&amp;\textrm{if }&lt;90\%\textrm{ invest}\end{cases}$</p><p>guess and check: <strong>2 NEs</strong> $\quad \mathrm{NE}_1 \textrm{:  all invest,} \quad \mathrm{NE}_2 \textrm{:  no one invest}$</p><p><em>play converged fairly rapidly to the (“bad” maybe) Nash Equilibrium</em></p>
          </div>
<p><strong>In Coordination Problems, unlike Prisoners’ Dilemma, <em>communication</em> can help.<br>Nash Equilibrium can be a self-enforcing agreement.</strong></p>
<div class="note default">
            <h4 id="Game-9"><a href="#Game-9" class="headerlink" title="Game 9"></a>Game 9</h4><p><strong>Going to the movie</strong></p><p>$\begin{matrix} &amp; \begin{matrix} &amp;&amp;&amp;&amp;&amp;&amp;&amp;\textrm{P2} \end{matrix}  \\ \begin{matrix} \\ \textrm{P1} \end{matrix} &amp; \begin{matrix} &amp;\textit{BU}&amp;\textit{GS}&amp;\textit{SW} \\ \textit{Bourne Ultimatum}&amp;\underline{2,1}&amp;0,0&amp;0,-1 \\ \textit{Good Shepherd}&amp;0,0&amp;\underline{1,2}&amp;0,-1 \\ \textit{Snow White}&amp;-1,0&amp;-1,0&amp;-2,-2&amp;\times \\ &amp;&amp;&amp;\times \end{matrix} \end{matrix}$</p><p><strong>the Battle of the Sexes:</strong> different people disagree about where they’d like to coordinate.</p>
          </div>
<p><br></p>
<h2 id="Class-6-Nash-Equilibrium-Cournot-Duopoly"><a href="#Class-6-Nash-Equilibrium-Cournot-Duopoly" class="headerlink" title="Class 6 - Nash Equilibrium (Cournot Duopoly)"></a>Class 6 - Nash Equilibrium (Cournot Duopoly)</h2><div class="note default">
            <h4 id="Game-10"><a href="#Game-10" class="headerlink" title="Game 10"></a>Game 10</h4><p><strong>Cournot Duopoly</strong> (a few players, many strategies)</p><p><strong>players:</strong> 2 firms, <strong>strategies:</strong> quantities of an identical product $q$, <strong>cost of production:</strong> constant marginal cost $c$, <strong>prices:</strong> $p=a-b\left(q_1+q_2\right)$, <strong>payoffs:</strong> profit $u_1\left(q_1,q_2\right)=pq_1-cq_1=aq_1-bq_1^2-bq_1q_2-cq_1$</p><p>$\dfrac{\partial u_1}{\partial p_1} = a-2bq_1-bq_2-c = 0 \quad\Rightarrow\quad \mathrm{BR}_1\left(q_2\right) = \hat q_1 = \dfrac{a-c}{2b} - \dfrac{q_2}{2} \,,\,\, \mathrm{BR}_2\left(q_1\right) = \hat q_2 = \dfrac{a-c}{2b} - \dfrac{q_1}{2}$</p><p><img src="/post/Open-Course/Game-Theory/Game-Theory-Ben-Polak-1/4.png" alt="Best Response"></p><p>$\begin{cases}\begin{aligned} \dfrac{a-c}{b} &amp;&amp; \texttt{competitive quantity} \\ \dfrac{2}{3}\cdot\dfrac{a-c}{b} &amp;&amp; {}\texttt{cournot quantity} \\ \dfrac{1}{2}\cdot\dfrac{a-c}{b} &amp;&amp; \texttt{molopoly quantity} \end{aligned}\end{cases}$</p>
          </div>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Game Theory</category>
      </categories>
      <tags>
        <tag>Economics</tag>
        <tag>Game Theory</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning (3) · Logistic Regression</title>
    <url>/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-3/</url>
    <content><![CDATA[<p>Stanford University, <strong>Machine Learning,</strong> <em>Andrew Ng,</em> <a href="https://www.coursera.org/learn/machine-learning/home/info">Coursera</a></p>
<p><strong><em>Week 3:</em></strong> Logistic Regression, Regularization</p>
<h3 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h3><h4 id="Classification-and-Representation"><a href="#Classification-and-Representation" class="headerlink" title="Classification and Representation"></a>Classification and Representation</h4><p><strong>Binary Classification</strong> $y\in\{0,\,1\}$</p>
<ul>
<li><strong>0:</strong> Negative Cass</li>
<li><strong>1:</strong> Positive Class</li>
</ul>
<p>Logistic Regression (Classification) $0 \leq h_\theta\left(x\right) \leq 1$</p>
<a id="more"></a>
<h5 id="Hypothesis-Representation"><a href="#Hypothesis-Representation" class="headerlink" title="Hypothesis Representation"></a>Hypothesis Representation</h5><p>$\begin{aligned} h_\theta\left(x\right) &amp;= g\left( \theta^{\mathsf{T}} x \right) \qquad g\left(z\right) = \dfrac{1}{1+e^{-z}} \quad \textsf{Sigmoid Function} \\ \Rightarrow \ h_\theta\left(x\right) &amp;= \dfrac{1}{1+e^{-\theta^{\mathsf{T}}x}} \quad \textsf{estimated probability that y=1 on input x} \end{aligned}$</p>
<h5 id="Decision-Boundary"><a href="#Decision-Boundary" class="headerlink" title="Decision Boundary"></a>Decision Boundary</h5><ul>
<li>predict <strong>y=1</strong> if $h_\theta\left(x\right)\geq0.5\quad\Rightarrow\quad\theta^{\mathsf{T}}x\geq0$</li>
<li>predict <strong>y=0</strong> if $h_\theta\left(x\right)&lt;0.5\quad\Rightarrow\quad\theta^{\mathsf{T}}x&lt;0$</li>
</ul>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-3/1.png" alt="decision boundary"></p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-3/2.png" alt="non-linear decision boundary"></p>
<h4 id="Logistic-Regression-Model"><a href="#Logistic-Regression-Model" class="headerlink" title="Logistic Regression Model"></a>Logistic Regression Model</h4><h5 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function"></a>Cost Function</h5><ul>
<li><p><strong>Linear Regression</strong></p>
<p>$\begin{aligned} J\left(\theta\right) = \dfrac{1}{m} \sum_{i=1}^{m} {\dfrac{1}{2} \left( h_\theta\left( x^\left(i\right) \right) - y^\left(i\right) \right) ^2 } \end{aligned}$</p>
</li>
<li><p><strong>Logistic Regression</strong></p>
<p>${\rm Cost}\left(h_\theta,\,y\right) = \dfrac{1}{2} \left( h_\theta\left( x \right) - y \right) ^2$ → <strong><em>J(θ) is non-convex</em></strong></p>
<p>${\rm Cost}\left(h_\theta,\,y\right) = \begin{cases} -\log \left( h_\theta\left( x \right)\right) &amp;\quad {\rm if} \ \ y=1 \\ -\log \left(1- h_\theta\left( x \right)\right) &amp;\quad {\rm if} \ \ y=0 \end{cases}$</p>
<p>$\begin{aligned} J\left(\theta\right) = - \dfrac{1}{m} \sum_{i=1}^{m} \left[ y^\left(i\right) \log \left( h_\theta\left( x^\left(i\right) \right)\right) + \left(1-y^\left(i\right)\right) \log \left(1- h_\theta\left( x^\left(i\right) \right)\right) \right] \end{aligned}$</p>
</li>
</ul>
<h5 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h5><p>&emsp;&emsp;$\begin{aligned} &amp; \min _{\theta}J\left(\theta\right),\ \textsf{repeat:} \\ &amp; \qquad \theta_j := \theta_j - \alpha \cdot \dfrac{\partial}{\partial \theta_j} J\left(\theta\right) = \theta_j - \alpha \cdot \dfrac{1}{m} \sum_{i=1}^{m} \left( h_\theta\left( x^\left(i\right) \right) - y^\left(i\right) \right) x_j ^\left(i\right) \\ &amp; \qquad \text{simultaneously update for every } j=0,\,\dots,\,n \end{aligned}$</p>
<p>&emsp;&emsp;<em>algorithm looks identical to linear regression</em> $\left( h_\theta\left(x\right) = \theta^{\mathsf{T}}x ,\ h_\theta\left(x\right) = \left. {1} \middle/ {\left(1+e^{-\theta^{\mathsf{T}}x}\right)} \right. \right)$</p>
<p>&emsp;&emsp;<strong>vectorized implementation</strong></p>
<p>&emsp;&emsp;$\qquad\begin{aligned}\theta := \theta - \alpha \cdot \dfrac{1}{m} X^\mathsf{T} \left( g\left( X\theta \right) - \vec{y} \right) \end{aligned}$</p>
<h5 id="Advanced-Optimization"><a href="#Advanced-Optimization" class="headerlink" title="Advanced Optimization"></a>Advanced Optimization</h5><p><strong>Optimization Algorithms</strong></p>
<ul>
<li>Gradient Descent</li>
<li>Conjugate Gradient</li>
<li>BFGS</li>
<li>L-BFGS</li>
</ul>
<p><strong>Pros</strong></p>
<ul>
<li>no need to manually pick α</li>
<li>often faster than gradient descent</li>
</ul>
<p><strong>Cons</strong></p>
<ul>
<li>more complex</li>
</ul>
<h4 id="Multiclass-Classification"><a href="#Multiclass-Classification" class="headerlink" title="Multiclass Classification"></a>Multiclass Classification</h4><p><strong>One-vs-all Classification</strong> $y\in\{0,\,1,\,2,\,\dots\}$</p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-3/3.png" alt="one-vs-all"></p>
<p>$h_\theta^{\left(i\right)}\left(x\right) = P\left(y=i\,|\,x;\theta\right),\quad i=1,\,2,\,3 \qquad\Rightarrow\qquad \max_i h_\theta^{\left(i\right)}\left(x\right)$</p>
<h3 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h3><h4 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a>Overfitting</h4><h5 id="The-Problem-of-Overfitting"><a href="#The-Problem-of-Overfitting" class="headerlink" title="The Problem of Overfitting"></a>The Problem of Overfitting</h5><p><strong>Underfit</strong> <em>(high bias)</em> &mdash; “just right” &mdash; <strong>Overfit</strong> <em>(high variance)</em></p>
<p><strong>Addressing Overfitting</strong></p>
<ul>
<li>Reduce number of features<ul>
<li>Manually select which features to keep</li>
<li>Model selection algorithms</li>
</ul>
</li>
<li>Regularization<ul>
<li>Keep all the features, but reduce magnitude/values of parameters θ<sub>j</sub></li>
<li>Works well when we have a lot of features, each of which contributes a bit to predicting y</li>
</ul>
</li>
</ul>
<h5 id="Cost-Function-1"><a href="#Cost-Function-1" class="headerlink" title="Cost Function"></a>Cost Function</h5><!--$\begin{aligned} & \hat{y} = \theta_0 + \theta_1x + \theta_2x^2 + \theta_3x^3 + \theta_4x^4 \\ \Rightarrow{}& \min_\theta \dfrac{1}{2m} \sum_{i=1}^{m} {\left( h_\theta\left( x^\left(i\right) \right) - y^\left(i\right) \right) ^2 } + A\theta_3^2 +B\theta_4^2 \qquad \textsf{penalize and make } \theta_3,\,\theta_4 \textsf{ really small} \end{aligned}$-->
<p><strong>small values for parameters </strong> $\left(\theta_0,\right)\,\theta_1,\,\theta_2,\,\dots,\,\theta_n$</p>
<ul>
<li>simpler hypothesis</li>
<li>less prone to overfitting</li>
</ul>
<p>$\begin{aligned} J\left(\theta\right) = \dfrac{1}{2m} \left[ \sum_{i=1}^{m} { \left( h_\theta\left( x^\left(i\right) \right) - y^\left(i\right) \right) ^2 } + \lambda \sum_{j=1}^{n} \theta_j^{\,2} \right] \end{aligned}$</p>
<h5 id="Regularized-Linear-Regression"><a href="#Regularized-Linear-Regression" class="headerlink" title="Regularized Linear Regression"></a>Regularized Linear Regression</h5><p><strong>Gradient Descent</strong></p>
<p>$\begin{aligned} &amp; \min _{\theta}J\left(\theta\right),\ \textsf{repeat:} \\ &amp; \qquad \begin{aligned} \theta_0 := {}&amp; \theta_0 - \alpha \cdot \dfrac{1}{m} \sum_{i=1}^{m} \left( h_\theta\left( x^\left(i\right) \right) - y^\left(i\right) \right) x_0 ^\left(i\right) &amp; \qquad j &amp;= 0 \\ \theta_j := {}&amp; \theta_j - \alpha \left[ \dfrac{1}{m} \sum_{i=1}^{m} \left( h_\theta\left( x^\left(i\right) \right) - y^\left(i\right) \right) x_j ^\left(i\right) + \dfrac{\lambda}{m} \, \theta_j \right] &amp; \qquad j &amp;= 1,\,2,\,\dots \\ = {}&amp; \left(1-\alpha\,\dfrac{\lambda}{m}\right) \theta_j - \alpha \cdot \dfrac{1}{m} \sum_{i=1}^{m} \left( h_\theta\left( x^\left(i\right) \right) - y^\left(i\right) \right) x_j ^\left(i\right) \end{aligned} \end{aligned}$</p>
<p><strong>Normal Equation</strong></p>
<p>$\begin{aligned} x &amp;= \left[ \begin{matrix} x_0^{\left(i\right)} \\ x_1^{\left(i\right)} \\ \vdots \\ x_n^{\left(i\right)} \end{matrix} \right] \in \mathbb{R} ^{n+1} \qquad X = \left[ \begin{matrix} — &amp; \left( x^{\left(1\right)}\right) ^{\mathsf{T}} &amp; — \\ — &amp; \left( x^{\left(2\right)}\right) ^{\mathsf{T}} &amp; — \\ &amp;\vdots&amp; \\ — &amp; \left( x^{\left(m\right)}\right) ^{\mathsf{T}} &amp; — \end{matrix} \right] \in \mathbb{R} ^{m \times \left(n+1\right)} \qquad y= \left[ \begin{matrix} y^{\left(1\right)} \\ y^{\left(2\right)} \\ \vdots \\ y^{\left(m\right)} \end{matrix} \right] \in \mathbb{R} ^{m} \\ &amp; \begin{aligned} \Rightarrow ^{\strut} \quad \theta &amp;= { { \left(X^{\mathsf{T}}X\right) ^{-1} } } X^{\mathsf{T}} y &amp;&amp; \left(X^{\mathsf{T}}X\right) \textsf{ is non-invertible if } m &lt; n \\\\ \Rightarrow ^{\strut} \quad \theta &amp;= { {\left(X^{\mathsf{T}}X +\lambda \cdot L \right)} }^{-1} X^{\mathsf{T}} y &amp;&amp; \left(X^{\mathsf{T}}X +\lambda \cdot L \right) \textsf{ is invertible if } \lambda > 0 \\ L &amp;= \left[\begin{matrix} 0 \\ &amp;1 \\ &amp;&amp;1 \\ &amp;&amp;&amp;\ddots \\ &amp;&amp;&amp;&amp;1 \end{matrix}\right] ^{\strut} \end{aligned} \end{aligned}$</p>
<h5 id="Regularized-Logistic-Regression"><a href="#Regularized-Logistic-Regression" class="headerlink" title="Regularized Logistic Regression"></a>Regularized Logistic Regression</h5><p><strong>Cost Function</strong></p>
<p>$\begin{aligned} J\left(\theta\right) = - \dfrac{1}{m} \sum_{i=1}^{m} \left[ y^\left(i\right) \log \left( h_\theta\left( x^\left(i\right) \right)\right) + \left(1-y^\left(i\right)\right) \log \left(1- h_\theta\left( x^\left(i\right) \right)\right) \right] + \dfrac{\lambda}{2m} \sum_{j=1}^{n} \theta_j^{\,2} \end{aligned}$</p>
<p><strong>Gradient Descent</strong></p>
<p>$\begin{aligned} &amp; \min _{\theta}J\left(\theta\right),\ \textsf{repeat:} \\ &amp; \qquad \begin{aligned} \theta_0 := {}&amp; \theta_0 - \alpha \cdot \dfrac{1}{m} \sum_{i=1}^{m} \left( h_\theta\left( x^\left(i\right) \right) - y^\left(i\right) \right) x_0 ^\left(i\right) &amp; \qquad j &amp;= 0 \\ \theta_j := {}&amp; \theta_j - \alpha \left[ \dfrac{1}{m} \sum_{i=1}^{m} \left( h_\theta\left( x^\left(i\right) \right) - y^\left(i\right) \right) x_j ^\left(i\right) + \dfrac{\lambda}{m} \, \theta_j \right] &amp; \qquad j &amp;= 1,\,2,\,\dots \end{aligned} \end{aligned}$</p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning (4) · Neural Networks · I</title>
    <url>/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-4/</url>
    <content><![CDATA[<p>Stanford University, <strong>Machine Learning,</strong> <em>Andrew Ng,</em> <a href="https://www.coursera.org/learn/machine-learning/home/info">Coursera</a></p>
<p><strong><em>Week 4:</em></strong> Neural Networks: Representation</p>
<h3 id="Neural-Networks-Representation"><a href="#Neural-Networks-Representation" class="headerlink" title="Neural Networks: Representation"></a>Neural Networks: Representation</h3><h4 id="Motivations"><a href="#Motivations" class="headerlink" title="Motivations"></a>Motivations</h4><h5 id="Non-linear-Hypotheses"><a href="#Non-linear-Hypotheses" class="headerlink" title="Non-linear Hypotheses"></a>Non-linear Hypotheses</h5><p>$\textrm{polynomial terms:} \quad n_{\textsf{}^{\textsf{quadratic}}_{\textsf{features}}} \sim O\left( n_{\textsf{}^{\textsf{original}}_{\textsf{features}}} ^2 \right) \qquad n_{\textsf{}^{\textsf{cubic}}_{\textsf{features}}} \sim O\left( n_{\textsf{}^{\textsf{original}}_{\textsf{features}}} ^3 \right)$</p>
<a id="more"></a>
<h4 id="Neural-Networks"><a href="#Neural-Networks" class="headerlink" title="Neural Networks"></a>Neural Networks</h4><h5 id="Model-Representation"><a href="#Model-Representation" class="headerlink" title="Model Representation"></a>Model Representation</h5><p><strong>Neuron Model:</strong> logistic unit</p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-4/neuron.png" alt="neuron"></p>
<p>$x=\left[\begin{matrix} x_0\\x_1\\x_2\\x_3 \end{matrix}\right] \qquad \theta=\left[\begin{matrix} \theta_0\\\theta_1\\\theta_2\\\theta_3 \end{matrix}\right] \qquad h_\theta \left(x\right) = \dfrac{1}{1+e^{-\theta^{\mathsf{T}}x}}$</p>
<p><strong>Neuron Network</strong></p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-4/network.png" alt="network"></p>
<p>Forward Propagation</p>
<p>$\begin{aligned} a_1^{\left(2\right)} &amp;= g\left( \Theta_{10}^{\left(1\right)}x_0 + \Theta_{11}^{\left(1\right)}x_1 + \Theta_{12}^{\left(1\right)}x_2 + \Theta_{13}^{\left(1\right)}x_3 \right) \\ a_2^{\left(2\right)} &amp;= g\left( \Theta_{20}^{\left(1\right)}x_0 + \Theta_{21}^{\left(1\right)}x_1 + \Theta_{22}^{\left(1\right)}x_2 + \Theta_{23}^{\left(1\right)}x_3 \right) \\ a_3^{\left(2\right)} &amp;= g\left( \Theta_{30}^{\left(1\right)}x_0 + \Theta_{31}^{\left(1\right)}x_1 + \Theta_{32}^{\left(1\right)}x_2 + \Theta_{33}^{\left(1\right)}x_3 \right) \\ h_\Theta \left(x\right) = a_1^{\left(3\right)} &amp;= g\left( \Theta_{10}^{\left(2\right)}a_0^{\left(2\right)} + \Theta_{11}^{\left(2\right)}a_1^{\left(2\right)} + \Theta_{12}^{\left(2\right)}a_2^{\left(2\right)} + \Theta_{13}^{\left(2\right)}a_3^{\left(2\right)} \right) \end{aligned}$</p>
<p><em>vectorized implementation</em></p>
<p>$\begin{aligned} z^{\left(2\right)} = \Theta^{\left(1\right)} a^{\left(1\right)} \quad&amp;\quad a^{\left(2\right)} = g\left( z^{\left(1\right)} \right) \qquad \textrm{add } a_0^{\left(2\right)}=1 \\ z^{\left(3\right)} = \Theta^{\left(2\right)} a^{\left(2\right)} \quad&amp;\quad a^{\left(3\right)} = g\left( z^{\left(3\right)} \right) = h_\Theta \left(x\right) \end{aligned}$</p>
<h4 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h4><p><strong>XOR / XNOR</strong></p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-4/xor1.png" alt="XOR"></p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-4/xor2.png" alt="XOR"></p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-4/xor3.png" alt="XOR"></p>
<h5 id="Multiclass-Classification"><a href="#Multiclass-Classification" class="headerlink" title="Multiclass Classification"></a>Multiclass Classification</h5><p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-4/multiclass.png" alt="MulticlassClassification"></p>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning (5) · Neural Networks · II</title>
    <url>/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-5/</url>
    <content><![CDATA[<p>Stanford University, <strong>Machine Learning,</strong> <em>Andrew Ng,</em> <a href="https://www.coursera.org/learn/machine-learning/home/info">Coursera</a></p>
<p><strong><em>Week 5:</em></strong> Neural Networks: Learning</p>
<h3 id="Neural-Networks-Learning"><a href="#Neural-Networks-Learning" class="headerlink" title="Neural Networks: Learning"></a>Neural Networks: Learning</h3><h4 id="Cost-Function-and-Backpropagation"><a href="#Cost-Function-and-Backpropagation" class="headerlink" title="Cost Function and Backpropagation"></a>Cost Function and Backpropagation</h4><h5 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function"></a>Cost Function</h5><ul>
<li><strong><em>L:</em></strong> total number of layers in network</li>
<li><strong><em>s<sub>l</sub>:</em></strong> number of units in layer l</li>
</ul>
<a id="more"></a>
<p><strong>Binary Classification</strong></p>
<p>$y = 0 \textrm{ or } 1 \\ \textsf{1 output unit:} \qquad h_\Theta \left(x\right) \in \mathbb{R} \quad s_L=1$</p>
<p><strong>Multi-class Classification</strong></p>
<p>$y \in \mathbb{R} ^K \\ \textsf{K output units:} \qquad h_\Theta \left(x\right) \in \mathbb{R} ^K \quad s_L=K$</p>
<p>$\begin{aligned} \large\textrm{Cost } &amp; \large\textrm{Function} _\strut \\ &amp; \textsf{Logistic Regression} \\ &amp; \qquad J\left(\theta\right) = - \dfrac{1}{m} \sum_{i=1}^{m} \left[ y^\left(i\right) \log \left( h_\theta\left( x^\left(i\right) \right)\right) + \left(1-y^\left(i\right)\right) \log \left(1- h_\theta\left( x^\left(i\right) \right)\right) \right] + \dfrac{\lambda}{2m} \sum_{j=1}^{n} \theta_j^{\,2} \\ &amp; \textsf{Neural Network} \\ &amp; \qquad J\left(\Theta\right) = - \dfrac{1}{m} \sum_{i=1}^{m} \sum_{k=1}^{K} \left[ y^\left(i\right)_k \log \left( h_\Theta\left( x^\left(i\right) \right)\right) _k + \left(1-y^\left(i\right)_k \right) \log \left(1- \left( h_\Theta\left( x^\left(i\right) \right) \right)  _k \right) \right] + \dfrac{\lambda}{2m} \sum_{l=1}^{L-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_l+1} \left( \Theta_{ji}^{\left(l\right)} \right)^{2} \end{aligned}$</p>
<h5 id="Backpropagation-Algorithm"><a href="#Backpropagation-Algorithm" class="headerlink" title="Backpropagation Algorithm"></a>Backpropagation Algorithm</h5><p><strong><em>Gradient Computation:</em></strong> $\min_\Theta J\left(\Theta\right)$, need to compute: $J\left(\Theta\right),\, \dfrac{\partial}{\partial \, \Theta_{ji}^{\left(l\right)}} J\left(\Theta\right)$</p>
<p>$\begin{aligned} &amp; \large\textrm{Backpropagation Algorithm} _\strut \\ &amp; \textsf{Training set } \left\{ \left( x^\left(1\right),\,y^\left(1\right) \right) ,\,\dots,\, \left( x^\left(m\right),\,y^\left(m\right) \right) \right\} \\ &amp; \textsf{Set } \Delta_{ij}^{\left(l\right)} = 0 \textsf{ for all } l,\,i,\,j \\ &amp; \textsf{For } i=1 \textsf{ to } m \\ &amp; \qquad \textsf{Set } a^\left(1\right) = x^\left(i\right) \\ &amp; \qquad \textsf{Perform forward propagation to compute } a^\left(l\right) = g\left( \Theta^\left(l-1\right)a^\left(l-1\right) \right) \textsf{ for } l=2,\,3,\,\dots,\,L \\ &amp; \qquad \textsf{Using } y^\left(i\right)  \textsf{ compute } \delta^\left(L\right)=a^\left(L\right)-y^\left(i\right) \\ &amp; \qquad \textsf{Compute } \delta^\left(l\right) = \left(\Theta^\left(l\right)\right) ^\mathsf{T} \delta^\left(l+1\right) \odot g’ \left(z^\left(l\right)\right) \textsf{ for } l=L-1,\,L-2,\,\dots,\,2 \\ &amp; \qquad \Delta_{ij}^{\left(l\right)} := \Delta_{ij}^{\left(l\right)} + a_j^{\left(l\right)} \delta_i^{\left(l+1\right)} \quad\rightarrow\textsf{ vectorized: } \Delta^{\left(l\right)} := \Delta^{\left(l\right)} + \delta^{\left(l+1\right)} \left[a^{\left(l\right)}\right] ^\mathsf{T} \\ &amp; \begin{aligned} D_{ij}^{\left(l\right)} &amp;:= \dfrac{1}{m} \Delta_{ij}^{\left(l\right)} + \lambda \Theta_{ij}^{\left(l\right)} &amp; \textsf{ if } n \neq 0 \\ D_{ij}^{\left(l\right)} &amp;:= \dfrac{1}{m} \Delta_{ij}^{\left(l\right)} &amp; \textsf{ if } n=0 \end{aligned} \qquad \Rightarrow \quad \dfrac{\partial}{\partial \, \Theta_{ji}^{\left(l\right)}} J\left(\Theta\right) = D_{ij}^{\left(l\right)} \end{aligned}$</p>
<h4 id="Backpropagation-in-Practice"><a href="#Backpropagation-in-Practice" class="headerlink" title="Backpropagation in Practice"></a>Backpropagation in Practice</h4><h5 id="Gradient-Checking"><a href="#Gradient-Checking" class="headerlink" title="Gradient Checking"></a>Gradient Checking</h5><p>$\dfrac{\partial}{\partial \, \Theta_j} J\left(\Theta_1 ,\,\dots,\, \Theta_j ,\,\dots,\, \Theta_n\right) \approx \dfrac{J\left(\Theta_1 ,\,\dots,\, \Theta_j+\varepsilon ,\,\dots,\, \Theta_n\right) - J\left(\Theta_1 ,\,\dots,\, \Theta_j-\varepsilon ,\,\dots,\, \Theta_n\right)}{2 \varepsilon} \qquad \left( \varepsilon \sim 10^{-4} \right)$</p>
<p><em>turn off gradient checking before training, use backprop code for learning</em></p>
<h5 id="Random-Initialization"><a href="#Random-Initialization" class="headerlink" title="Random Initialization"></a>Random Initialization</h5><ul>
<li><strong><em>Zero initialization:</em></strong> after each update, parameters corresponding to inputs going into each of two hidden units are <strong>identical</strong></li>
<li><strong><em>Random initialization:</em></strong> symmetry breaking: initialize each $\Theta_{ji}^{\left(l\right)}$ to a random value in $\left[-\varepsilon,\,\varepsilon\right]$</li>
</ul>
<h5 id="Putting-it-Together"><a href="#Putting-it-Together" class="headerlink" title="Putting it Together"></a>Putting it Together</h5><p><strong>Training a Neural Network</strong></p>
<ol>
<li>Pick a network architecture</li>
<li>Randomly initialize weights</li>
<li>Implement forward propagation to get $h_\Theta \left( x^\left(i\right) \right)$ for any $x^\left(i\right)$</li>
<li>Implement code to compute cost function $J\left(\Theta\right)$</li>
<li>Implement backprop to compute partial derivatives $\dfrac{\partial}{\partial \, \Theta_{ji}^{\left(l\right)}} J\left(\Theta\right)$</li>
<li>Use gradient checking to compare $\dfrac{\partial}{\partial \, \Theta_{ji}^{\left(l\right)}} J\left(\Theta\right)$ computed using backprop versus using numerical estimate of gradient of $J\left(\Theta\right)$, and then disable gradient checking code</li>
<li>Use gradient descent or advanced optimization methods with back propagation to try to minimize $J\left(\Theta\right)$ as a function of parameters $\Theta$</li>
</ol>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning (6) · Applying Machine Learning</title>
    <url>/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-6/</url>
    <content><![CDATA[<p>Stanford University, <strong>Machine Learning,</strong> <em>Andrew Ng,</em> <a href="https://www.coursera.org/learn/machine-learning/home/info">Coursera</a></p>
<p><strong><em>Week 6:</em></strong> Advice for Applying Machine Learning, Machine Learning System Design</p>
<h3 id="Advice-for-Applying-Machine-Learning"><a href="#Advice-for-Applying-Machine-Learning" class="headerlink" title="Advice for Applying Machine Learning"></a>Advice for Applying Machine Learning</h3><h4 id="Evaluating-a-Learning-Algorithm"><a href="#Evaluating-a-Learning-Algorithm" class="headerlink" title="Evaluating a Learning Algorithm"></a>Evaluating a Learning Algorithm</h4><h5 id="Deciding-What-to-Try-Next"><a href="#Deciding-What-to-Try-Next" class="headerlink" title="Deciding What to Try Next"></a>Deciding What to Try Next</h5><ul>
<li>get more training examples</li>
<li>try smaller sets of features</li>
<li>try getting additional features</li>
<li>try adding polynomial features</li>
<li>try decreasing / increasing $\lambda$</li>
</ul>
<a id="more"></a>
<h5 id="Evaluating-a-Hypothesis"><a href="#Evaluating-a-Hypothesis" class="headerlink" title="Evaluating a Hypothesis"></a>Evaluating a Hypothesis</h5><p>$\textsf{Dataset} \begin{cases} 70\% \textsf{ Training set} \\ 30\% \textsf{ Test set} \end{cases}$</p>
<ol>
<li>Learn parameter $\theta$ from training data</li>
<li>Compute test set error $J_{test}\left(\theta\right)$</li>
</ol>
<h5 id="Model-Selection-and-Train-Validation-Test-Sets"><a href="#Model-Selection-and-Train-Validation-Test-Sets" class="headerlink" title="Model Selection and Train / Validation / Test Sets"></a>Model Selection and Train / Validation / Test Sets</h5><p><strong>Model selection:</strong> pick $\min J_{test}\left(\theta_d\right), \; d = \textsf{degree of polynomial}$</p>
<p><strong><em>Problem:</em></strong> $J_{test}\left(\theta_d\right)$ is likely to be an optimistic estimate of generalization error, i.e. our extra parameter $d$ is fit to test set.</p>
<p>$\textsf{Dataset} \begin{cases} 60\% \textsf{ Training set} \\ 20\% \textsf{ Cross validation set (CV)}  \\ 20\% \textsf{ Test set} \end{cases}$</p>
<p><strong>Model selection:</strong> pick $\min J_{cv}\left(\theta_d\right)$, estimate generalization error for test set $J_{test}\left(\theta_d\right)$</p>
<h4 id="Bias-vs-Variance"><a href="#Bias-vs-Variance" class="headerlink" title="Bias vs. Variance"></a>Bias vs. Variance</h4><h5 id="Diagnosing-Bias-vs-Variance"><a href="#Diagnosing-Bias-vs-Variance" class="headerlink" title="Diagnosing Bias vs. Variance"></a>Diagnosing Bias vs. Variance</h5><p>$\begin{matrix} \textsf{High Bias} &amp; - &amp; \textsf{just right} &amp; - &amp; \textsf{High Variance} \\ \textsf{underfit}&amp;&amp;&amp;&amp;\textsf{overfit} \end{matrix}$</p>
<p>Training error: $\begin{aligned} J_{train}\left(\theta\right) = \dfrac{1}{2m}\sum_{i=1}^{m} \left( h_\theta \left( x^\left(i\right) \right) - y^\left(i\right) \right) ^2 \end{aligned}$</p>
<p>Validation error: $\begin{aligned} J_{cv}\left(\theta\right) = \dfrac{1}{2m_{cv}}\sum_{i=1}^{m_{cv}} \left( h_\theta \left( x_{cv}^\left(i\right) \right) - y_{cv}^\left(i\right) \right) ^2 \end{aligned}$ or $\begin{aligned} J_{test}\left(\theta\right) \end{aligned}$</p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-6/1.png" alt="Bias vs Variance"></p>
<ul>
<li><strong>Bias (underfit):</strong> $\begin{aligned} J_{train}\left(\theta\right) \end{aligned}$ will be high, $\begin{aligned} J_{cv}\left(\theta\right) \approx J_{train}\left(\theta\right) \end{aligned}$</li>
<li><strong>Variance (overfit):</strong> $\begin{aligned} J_{train}\left(\theta\right) \end{aligned}$ will be low, $\begin{aligned} J_{cv}\left(\theta\right) \gg J_{train}\left(\theta\right) \end{aligned}$</li>
</ul>
<h5 id="Regularization-and-Bias-Variance"><a href="#Regularization-and-Bias-Variance" class="headerlink" title="Regularization and Bias / Variance"></a>Regularization and Bias / Variance</h5><p><strong>Linear regression with regularization</strong></p>
<p>$\begin{aligned} \textsf{Model: } &amp; h_\theta \left(x\right) = \theta_0 + \theta_1x + \theta_2x^2 + \theta_3x^3 + \theta_4x^4 \\ &amp; J\left(\theta\right) = \dfrac{1}{2m} \sum_{i=1}^{m} \left( h_\theta \left( x^\left(i\right) \right) - y^\left(i\right) \right) ^2 + \underbrace{ \dfrac{\lambda}{2m} \sum_{j=1}^{m} \theta_j^2 } \end{aligned}$</p>
<p>$\begin{matrix} \textsf{Large } \lambda &amp;&amp; \textsf{Intermediate } \lambda &amp;&amp; \textsf{Small } \lambda \\ \textsf{High Bias} &amp; - &amp; \textsf{just right} &amp; - &amp; \textsf{High Variance} \\ \textsf{underfit}&amp;&amp;&amp;&amp;\textsf{overfit} \end{matrix}$</p>
<p><strong>Choosing the regularization parameter</strong> $\lambda$</p>
<p>$\begin{aligned} J\left(\theta\right) &amp;= \dfrac{1}{2m} \sum_{i=1}^{m} \left( h_\theta \left( x^\left(i\right) \right) - y^\left(i\right) \right) ^2 + \dfrac{\lambda}{2m} \sum_{j=1}^{m} \theta_j^2 \\ J_{train}\left(\theta\right) &amp;= \dfrac{1}{2m}\sum_{i=1}^{m} \left( h_\theta \left( x^\left(i\right) \right) - y^\left(i\right) \right) ^2 \\ J_{cv}\left(\theta\right) &amp;= \dfrac{1}{2m_{cv}}\sum_{i=1}^{m_{cv}} \left( h_\theta \left( x_{cv}^\left(i\right) \right) - y_{cv}^\left(i\right) \right) ^2 \\ J_{test}\left(\theta\right) &amp;= \dfrac{1}{2m_{test}}\sum_{i=1}^{m_{test}} \left( h_\theta \left( x_{test}^\left(i\right) \right) - y_{test}^\left(i\right) \right) ^2 \end{aligned}$</p>
<p>try $\lambda = 0 ,\, 0.01 ,\, 0.02 ,\, 0.04 ,\, 0.08 ,\, \dots ,\, 10.24$, train $\min_\theta J\left(\theta\right)$, pick $\min J_{cv}\left(\theta\right)$, estimate $J_{test}\left(\theta\right)$</p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-6/2.png" alt="Bias vs Variance"></p>
<h5 id="Learning-Curves"><a href="#Learning-Curves" class="headerlink" title="Learning Curves"></a>Learning Curves</h5><p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-6/3.png" alt="Learning Curves"></p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-6/4.png" alt="Learning Curves"></p>
<h5 id="Deciding-What-to-Do-Next-Revisited"><a href="#Deciding-What-to-Do-Next-Revisited" class="headerlink" title="Deciding What to Do Next Revisited"></a>Deciding What to Do Next Revisited</h5><ul>
<li><p><strong>fix high bias</strong></p>
<ul>
<li>try getting additional features</li>
<li>try adding polynomial features</li>
<li>try decreasing $\lambda$</li>
</ul>
</li>
<li><p><strong>fix high variance</strong></p>
<ul>
<li>get more training examples</li>
<li>try smaller sets of features</li>
<li>try increasing $\lambda$</li>
</ul>
</li>
<li><p><strong><em>small</em> neural network</strong></p>
<ul>
<li>fewer parameters</li>
<li>more prone to underfitting</li>
<li>computationally cheaper</li>
</ul>
</li>
<li><p><strong><em>large</em> neural network</strong></p>
<ul>
<li>more parameters</li>
<li>more prone to overfitting</li>
<li>computationally more expensive</li>
<li>use regularization to address overfitting</li>
</ul>
</li>
</ul>
<h3 id="Machine-Learning-System-Design"><a href="#Machine-Learning-System-Design" class="headerlink" title="Machine Learning System Design"></a>Machine Learning System Design</h3><h4 id="Building-a-Spam-Classifier"><a href="#Building-a-Spam-Classifier" class="headerlink" title="Building a Spam Classifier"></a>Building a Spam Classifier</h4><h5 id="Prioritizing-What-to-Work-on"><a href="#Prioritizing-What-to-Work-on" class="headerlink" title="Prioritizing What to Work on"></a>Prioritizing What to Work on</h5><ul>
<li>Collect lots of data</li>
<li>Develop sophisticated features</li>
<li>Develop algorithms to process your input in different ways</li>
</ul>
<h5 id="Error-Analysis"><a href="#Error-Analysis" class="headerlink" title="Error Analysis"></a>Error Analysis</h5><ul>
<li>Start with a simple algorithm, implement it quickly, and test it early on your cross validation data.</li>
<li>Plot learning curves to decide if more data, more features, etc. are likely to help.</li>
<li>Manually examine the errors on examples in the cross-validation set and try to spot a trend where most of the errors were made.</li>
</ul>
<h4 id="Handling-Skewed-Data"><a href="#Handling-Skewed-Data" class="headerlink" title="Handling Skewed Data"></a>Handling Skewed Data</h4><h5 id="Error-Metrics-for-Skewed-Classes"><a href="#Error-Metrics-for-Skewed-Classes" class="headerlink" title="Error Metrics for Skewed Classes"></a>Error Metrics for Skewed Classes</h5><p><strong>Precision / Recall</strong></p>
<p>$y=1$ in presence of rare class:</p>
<p>$\begin{matrix} &amp; \textrm{actual class} \\ \begin{matrix} \\ \textrm{predicted} &amp;&amp; 1 \\ \textrm{class} &amp;&amp; 0 \end{matrix} &amp; \begin{matrix} 1 &amp; 0 \\ \textsf{True Positive} &amp; \textsf{False Positive} \\  \textsf{False Negative} &amp; \textsf{True Negative} \end{matrix} \end{matrix}$</p>
<p>$\Rightarrow \; \begin{cases} \textsf{Precision} = \dfrac{\textsf{True Positive}}{\textsf{Predicted Positive}} &amp;= \dfrac{\textsf{True Positive}}{\textsf{True Positive}+\textsf{False Positive}} \\ \textsf{Recall} = \dfrac{\textsf{True Positive}}{\textsf{Actual Positive}} &amp;= \dfrac{\textsf{True Positive}}{\textsf{True Positive}+\textsf{False Negative}} ^\strut \end{cases}$</p>
<h5 id="Trading-Off-Precision-and-Recall"><a href="#Trading-Off-Precision-and-Recall" class="headerlink" title="Trading Off Precision and Recall"></a>Trading Off Precision and Recall</h5><p>$\begin{matrix} \begin{matrix} \textsf{lower precision} \\ \textsf{higher recall} \end{matrix}  &amp; \begin{matrix} \xrightarrow{ {\rm diffident} \qquad {\rm confident} } \end{matrix} &amp; \begin{matrix} \textsf{higher precision} \\ \textsf{lower recall} \end{matrix} \end{matrix}$</p>
<p>Predict $1$ if $h_\theta \left(x\right) \geq \textsf{threshold}$</p>
<p>$\Rightarrow \; \textsf{F}_\textsf{1}\textsf{ Score} = \dfrac{2PR}{P+R}$</p>
<h4 id="Using-Large-Data-Sets"><a href="#Using-Large-Data-Sets" class="headerlink" title="Using Large Data Sets"></a>Using Large Data Sets</h4><h5 id="Data-For-Machine-Learning"><a href="#Data-For-Machine-Learning" class="headerlink" title="Data For Machine Learning"></a>Data For Machine Learning</h5><p><em>It’s not who has the best algorithm that wins; it’s who has the most data.</em></p>
<p><strong>Large data rationale</strong></p>
<ul>
<li>Assume feature $x\in\mathbb{R}^{n+1}$ has sufficient information to predict $y$ accurately</li>
<li>Use a learning algorithm with many parameters</li>
<li>Use a very large training set (unlikely to overfit)</li>
</ul>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning (8) · Unsupervised Learning</title>
    <url>/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-8/</url>
    <content><![CDATA[<p>Stanford University, <strong>Machine Learning,</strong> <em>Andrew Ng,</em> <a href="https://www.coursera.org/learn/machine-learning/home/info">Coursera</a></p>
<p><strong><em>Week 8:</em></strong> Unsupervised Learning, Dimensionality Reduction</p>
<h3 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h3><h4 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h4><h5 id="Unsupervised-Learning-Introduction"><a href="#Unsupervised-Learning-Introduction" class="headerlink" title="Unsupervised Learning: Introduction"></a>Unsupervised Learning: Introduction</h5><p>training set: $\left\{ x^\left(1\right),\, x^\left(2\right),\, x^\left(3\right),\, \dots ,\, x^\left(m\right) \right\}$</p>
<h5 id="K-Means-Algorithm"><a href="#K-Means-Algorithm" class="headerlink" title="K-Means Algorithm"></a>K-Means Algorithm</h5><p><strong>step 1:</strong> cluster assignment<br><strong>step 2:</strong> move centroid</p>
<a id="more"></a>
<p><strong>Inputs</strong></p>
<ul>
<li>$K$ (number of clusters)</li>
<li>Training set $\left\{ x^\left(1\right),\, x^\left(2\right),\, \dots ,\, x^\left(m\right) \right\}$, $x^\left(1\right) \in \mathbb{R}^n$ (drop $x_0=1$ convention)</li>
</ul>
<p><strong>Algorithm</strong></p>
<p>$\begin{aligned} &amp; \textsf{Randomly initialize } K \textsf{ cluster centroids } \mu_1,\, \mu_2,\, \dots ,\, \mu_K \in \mathbb{R^n} \\ &amp; \textsf{Repeat} \\ &amp; \qquad \textsf{for } i=1 \textsf{ to } m \qquad \textrm{// cluster assignment step} \\ &amp; \qquad\qquad c^\left(i\right) := \textsf{index of cluster centroid closest to } x^\left(i\right) \\ &amp; \qquad \textsf{for } k=1 \textsf{ to } K \qquad \textrm{// move centroid step} \\ &amp; \qquad\qquad \mu_k := \textsf{average mean of points assigned to cluster } k \end{aligned}$</p>
<h5 id="Optimization-Objective"><a href="#Optimization-Objective" class="headerlink" title="Optimization Objective"></a>Optimization Objective</h5><ul>
<li>$c^\left(i\right)$: index of cluster $\left( 1,\,2,\,\dots,\,K \right)$ to which example $x^\left(i\right)$ is currently assigned</li>
<li>$\mu_k$: cluster centroid $k$ $\left( \mu_k \in \mathbb{R}^n \right)$</li>
<li>$\mu_{c^\left(i\right)}$: cluster centroid of cluster to which example $x\left(i\right)$ has been assigned</li>
</ul>
<p><strong>Optimization Objective</strong></p>
<p>$\begin{aligned} &amp; J\left( c^\left(1\right) ,\, \dots ,\, c^\left(m\right) ,\, \mu_1 ,\, \dots ,\, \mu_K \right) = \dfrac{1}{m} \sum_{i=1}^{m} \left| x^\left(i\right) - \mu_{ c^\left(i\right) } \right| ^2 \\ &amp; \min_{ \substack{ c^\left(i\right) ,\,\dots,\, c^\left(m\right) , \\ \mu_1 ,\,\dots,\, \mu_K } } J\left( c^\left(1\right) ,\, \dots ,\, c^\left(m\right) ,\, \mu_1 ,\, \dots ,\, \mu_K \right) \qquad \textsf{distortion} \end{aligned}$</p>
<ol>
<li><strong>cluster assignment step</strong><br>minimize $J\left( c^\left(1\right) ,\, \dots ,\, c^\left(m\right) ,\, \mu_1 ,\, \dots ,\, \mu_K \right)$ wrt $c^\left(1\right) ,\, \dots ,\, c^\left(m\right)$, holding $\mu_1 ,\, \dots ,\, \mu_K$ fixed</li>
<li><strong>move centroid step</strong><br>minimize $J\left( c^\left(1\right) ,\, \dots ,\, c^\left(m\right) ,\, \mu_1 ,\, \dots ,\, \mu_K \right)$ wrt $\mu_1 ,\, \dots ,\, \mu_K$, holding $c^\left(1\right) ,\, \dots ,\, c^\left(m\right)$ fixed</li>
</ol>
<h5 id="Random-Initialization"><a href="#Random-Initialization" class="headerlink" title="Random Initialization"></a>Random Initialization</h5><p>Randomly pick $K$ training examples and set $\mu_1 ,\,\dots,\, \mu_K$ equal to these $K$ examples. $\left( K \lt m \right)$</p>
<p><strong>Local Optima</strong></p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-8/1.png" alt="LocalOptima"></p>
<p><em>multiple random initializations</em></p>
<p>$\begin{aligned} &amp; \textsf{for } i=1 \textsf{ to } 100 \\ &amp; \qquad \textsf{randomly initialize K-means} \\ &amp; \qquad \textsf{run K-means, get } c^\left(1\right) ,\, \dots ,\, c^\left(m\right) ,\, \mu_1 ,\, \dots ,\, \mu_K \\ &amp; \qquad \textsf{compute distortion } J\left( c^\left(1\right) ,\, \dots ,\, c^\left(m\right) ,\, \mu_1 ,\, \dots ,\, \mu_K \right) \\ &amp; \textsf{pick clustering that gave lowest cost } J\left( c^\left(1\right) ,\, \dots ,\, c^\left(m\right) ,\, \mu_1 ,\, \dots ,\, \mu_K \right) ^\strut \end{aligned}$</p>
<h5 id="Choosing-the-Number-of-Clusters"><a href="#Choosing-the-Number-of-Clusters" class="headerlink" title="Choosing the Number of Clusters"></a>Choosing the Number of Clusters</h5><ul>
<li>Elbow method</li>
<li>Performance on downstream purpose</li>
</ul>
<h3 id="Dimensionality-Reduction"><a href="#Dimensionality-Reduction" class="headerlink" title="Dimensionality Reduction"></a>Dimensionality Reduction</h3><h4 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h4><h5 id="Data-Compression"><a href="#Data-Compression" class="headerlink" title="Data Compression"></a>Data Compression</h5><p>Reduce data from 2D to 1D</p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-8/2.png" alt="Dimensionality Reduction"></p>
<h5 id="Data-Visualization"><a href="#Data-Visualization" class="headerlink" title="Data Visualization"></a>Data Visualization</h5><h4 id="Principal-Component-Analysis"><a href="#Principal-Component-Analysis" class="headerlink" title="Principal Component Analysis"></a>Principal Component Analysis</h4><h5 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h5><p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-8/3.png" alt="3"></p>
<p><strong>Reduce from 2-dimension to 1-dimension:</strong> Find a direction (a vector $u^\left(1\right) \in \mathbb{R}^n$) onto which to project the data, so as to minimize the projection error.<br><br><strong>Reduce from n-dimension to k-dimension:</strong> Find $k$ vectors $u^\left(1\right) ,\, u^\left(2\right) ,\,\dots,\, u^\left(k\right)$ onto which to project the data, so as to minimize the projection error.</p>
<p><strong>Principal Component Analysis is not Linear Regression</strong></p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-8/4.png" alt="PCA vs LR"></p>
<p>$\textsf{LR: } x \rightarrow y \qquad\qquad \textsf{PCA: } x_1 ,\, x_2 ,\,\dots,\, x_n$</p>
<h5 id="PCA-Algorithm"><a href="#PCA-Algorithm" class="headerlink" title="PCA Algorithm"></a>PCA Algorithm</h5><p><strong>Data Preprocessing</strong></p>
<p>Training set: $x^\left(1\right) ,\, x^\left(2\right) ,\,\dots,\, x^\left(m\right)$<br><br>Preprocessing: feature scaling / mean normalization,<br>&emsp;&emsp; $\begin{aligned} \mu_j = \dfrac{1}{m} \sum_{i=1}^m x_j^\left(i\right) \end{aligned}$<br><br>&emsp;&emsp; replace each $x_j^\left(i\right)$ with $x_j-\mu_j$<br><br>&emsp;&emsp; if different features on different scales, scale features to have comparable range of values.</p>
<p><strong>Dimensionality Reduction</strong></p>
<p>Compute covariance matrix<br>&emsp;&emsp; $\begin{aligned} \Sigma = \dfrac{1}{m} \sum_{i=1}^{n} \left( x^\left(i\right) \right) \left( x^\left(i\right) \right) ^\mathsf{T} \quad \in\mathbb{R} ^{n \times n} \end{aligned}$<br><br>Compute eigenvectors $U$ of matrix $\Sigma$<br><br>&emsp;&emsp; $U = \left[ \begin{matrix} \Big| &amp; \Big| &amp; &amp; \Big| &amp; &amp; \Big| \\ u^{\left(1\right)} &amp; u^{\left(2\right)} &amp; \cdots &amp; u^{\left(k\right)} &amp; \cdots &amp; u^{\left(n\right)} \\ \Big| &amp; \Big| &amp; &amp; \Big| &amp; &amp; \Big| \end{matrix} \right]  \quad \in\mathbb{R}^{n \times n}$<br><br>$x \in \mathbb{R}^n \ \longrightarrow \ z \in \mathbb{R}^k$<br><br>&emsp;&emsp; $z _{k \times 1} = U_{\textrm{reduce}}^{\ \mathsf{T}} x = \left( \left[ \begin{matrix} \Big| &amp; \Big| &amp; &amp; \Big| \\ u^{\left(1\right)} &amp; u^{\left(2\right)} &amp; \cdots &amp; u^{\left(k\right)} \\ \Big| &amp; \Big| &amp; &amp; \Big| \end{matrix} \right] ^\mathsf{T} \right) _{k \times n} x _{n \times 1}$</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">[U, S, V] = svd(Sigma)  <span class="comment">% singular value decomposition</span></span><br></pre></td></tr></table></figure>
<h4 id="Applying-PCA"><a href="#Applying-PCA" class="headerlink" title="Applying PCA"></a>Applying PCA</h4><h5 id="Reconstruction-from-Compressed-Representation"><a href="#Reconstruction-from-Compressed-Representation" class="headerlink" title="Reconstruction from Compressed Representation"></a>Reconstruction from Compressed Representation</h5><p>$z = U_{\textrm{reduce}}^{\ \mathsf{T}} x \qquad x_{\textrm{approx}} = U_{\textrm{reduce}} z$</p>
<h5 id="Choosing-the-Number-of-Principal-Components"><a href="#Choosing-the-Number-of-Principal-Components" class="headerlink" title="Choosing the Number of Principal Components"></a>Choosing the Number of Principal Components</h5><p>Averaged squared projection error<br>&emsp;&emsp; $\begin{aligned} \dfrac{1}{m} \sum_{i=1}^{m} \left| x^\left(i\right) - x^\left(i\right)_\mathrm{approx} \right| ^2 \end{aligned}$<br><br>Total variation in the data<br>&emsp;&emsp; $\begin{aligned} \dfrac{1}{m} \sum_{i=1}^{m} \left| x^\left(i\right) \right| ^2 \end{aligned}$</p>
<p>Typically, choose $k$ to be smallest value so that<br><br>&emsp;&emsp; $\begin{aligned} \dfrac{ \begin{aligned} \dfrac{1}{m} \sum_{i=1}^{m} \left| x^\left(i\right) - x^\left(i\right)_\mathrm{approx} \right| ^2 \end{aligned} } { \begin{aligned} \dfrac{1}{m} \sum_{i=1}^{m} \left| x^\left(i\right) \right| ^2 \end{aligned} } \leq 0.01 \end{aligned}$ &emsp;&emsp; <em>99% of variance is retained</em></p>
<p>$S = \begin{bmatrix} \begin{matrix} s_{11} &amp; \\ &amp; s_{22} \end{matrix} &amp; \Large{0} \\ \Large{0} &amp; \begin{matrix} \ddots &amp; \\ &amp; s_{nn} \end{matrix} \end{bmatrix}$</p>
<p>For given $k$<br><br>&emsp;&emsp; $\begin{aligned} \dfrac{ \begin{aligned} \dfrac{1}{m} \sum_{i=1}^{m} \left| x^\left(i\right) - x^\left(i\right)_\mathrm{approx} \right| ^2 \end{aligned} } { \begin{aligned} \dfrac{1}{m} \sum_{i=1}^{m} \left| x^\left(i\right) \right| ^2 \end{aligned} } = 1- \dfrac{ \begin{aligned} \sum_{i=1}^{k} s_{ii} \end{aligned} } { \begin{aligned} \sum_{i=1}^{n} s_{ii} \end{aligned} } \end{aligned}$</p>
<h5 id="Advice-for-Applying-PCA"><a href="#Advice-for-Applying-PCA" class="headerlink" title="Advice for Applying PCA"></a>Advice for Applying PCA</h5><p><strong>Supervised Learning Speedup</strong></p>
<p>$\begin{matrix} x^\left(1\right) ,\, x^\left(1\right) ,\,\dots,\, x^\left(1\right) \quad \in \mathbb{R}^{10000} \\ \qquad \big\downarrow \qquad \textrm{PCA} \\ z^\left(1\right) ,\, z^\left(1\right) ,\,\dots,\, z^\left(1\right) \quad \in \mathbb{R}^{1000} \end{matrix}$</p>
<p><strong>Note:</strong> Mapping $x^\left(i\right) \rightarrow z^\left(i\right)$ should be difined by running PCA only on the training set. This mapping can be applied as well to $x^\left(i\right) _\textrm{cv}$ and $x^\left(i\right) _\textrm{test}$ in the cross validation and test sets.</p>
<p><strong>Application of PCA</strong></p>
<ul>
<li><strong>Compression</strong><ul>
<li>Reduce memory/disk space</li>
<li>Speed up learning algorithm</li>
</ul>
</li>
<li><strong>Visualization</strong></li>
<li>Misuses<ul>
<li>Use PCA to provent overfitting is not recommended</li>
<li>Try original/raw data before implementing PCA</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning (7) · Support Vector Machines</title>
    <url>/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-7/</url>
    <content><![CDATA[<p>Stanford University, <strong>Machine Learning,</strong> <em>Andrew Ng,</em> <a href="https://www.coursera.org/learn/machine-learning/home/info">Coursera</a></p>
<p><strong><em>Week 7:</em></strong> Support Vector Machines</p>
<h3 id="Support-Vector-Machines"><a href="#Support-Vector-Machines" class="headerlink" title="Support Vector Machines"></a>Support Vector Machines</h3><h4 id="Large-Margin-Classification"><a href="#Large-Margin-Classification" class="headerlink" title="Large Margin Classification"></a>Large Margin Classification</h4><h5 id="Optimization-Objective"><a href="#Optimization-Objective" class="headerlink" title="Optimization Objective"></a>Optimization Objective</h5><p><strong>Logistic Regression</strong></p>
<p>$h_{\theta}\left(x\right) = \dfrac{1}{1+e^{ -\theta^\mathsf{T}x }}$</p>
<p>if $y=1$, we want $h_{\theta}\left(x\right)\approx1$, $\theta^\mathsf{T}x\gg0$<br><br>if $y=0$, we want $h_{\theta}\left(x\right)\approx0$, $\theta^\mathsf{T}x\ll0$</p>
<p>cost function $-y \log h_{\theta}\left(x\right) - \left(1-y\right) \log \left( 1- h_{\theta}\left(x\right) \right)$</p>
<a id="more"></a>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-7/1.png" alt="cost"></p>
<p><strong>Support Vector Machine</strong></p>
<ul>
<li><p><strong>logistic regression</strong> <em>“A+λB”</em><br>$\begin{aligned} \min_\theta \dfrac{1}{m} \left[ \sum_{i=1}^m y ^\left(i\right) \left[ -\log h_\theta \left( x^\left(i\right) \right) \right] + \left( 1-y^\left(i\right) \right) \left[ -\log \left( 1- h_\theta \left( x^\left(i\right) \right) \right) \right] \right] + \dfrac{\lambda}{2m} \sum_{j=1}^{n} \theta_j^{\,2} \end{aligned}$</p>
</li>
<li><p><strong>support vector machine</strong> <em>“CA+B”</em><br>$\begin{aligned} \min_\theta {\color{lightgrey} {\dfrac{1}{m}} } C\cdot \left[ \sum_{i=1}^m y ^\left(i\right) \left[ \mathsf{cost}_\mathsf{1} \hspace{-0.5mm} \left( \theta^\mathsf{T} x^\left(i\right) \right) \right] + \left( 1-y^\left(i\right) \right) \left[ \mathsf{cost}_\mathsf{0} \hspace{-0.5mm} \left( \theta^\mathsf{T} x^\left(i\right) \right) \right] \right] + \dfrac{1}{2 {\color{lightgrey} {m} }} \sum_{j=1}^{n} \theta_j^{\,2} \end{aligned}$</p>
<p>hypothesis: $h_{\theta}\left(x\right)= \begin{cases} 1 &amp; \textsf{if } \theta^\mathsf{T}x\geq0 \\ 0 &amp; \textsf{otherwise} \end{cases}$</p>
</li>
</ul>
<h5 id="Large-Margin-Intuition"><a href="#Large-Margin-Intuition" class="headerlink" title="Large Margin Intuition"></a>Large Margin Intuition</h5><p>$\begin{aligned} \min_\theta \; C\cdot \sum_{i=1}^m \left[ y ^\left(i\right) \, \mathsf{cost}_\mathsf{1} \hspace{-0.5mm} \left( \theta^\mathsf{T} x^\left(i\right) \right) + \left( 1-y^\left(i\right) \right) \mathsf{cost}_\mathsf{0} \hspace{-0.5mm} \left( \theta^\mathsf{T} x^\left(i\right) \right) \right] + \dfrac{1}{2} \sum_{j=1}^{n} \theta_j^{\,2} \end{aligned}$</p>
<p>if $y=1$, we want $\theta^\mathsf{T}x\geq+1$ &emsp; (not just $\geq0$)<br><br>if $y=0$, we want $\theta^\mathsf{T}x\lt-1$ &emsp; (not just $\lt0$)</p>
<p><strong>SVM Decision Boundary:</strong> linearly separable case</p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-7/2.png" alt="Large C"></p>
<p><em>large margin classifier in presence of outliers</em></p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-7/3.png" alt="C"></p>
<h5 id="Mathematics-Behind-Large-Margin-Classification"><a href="#Mathematics-Behind-Large-Margin-Classification" class="headerlink" title="Mathematics Behind Large Margin Classification"></a>Mathematics Behind Large Margin Classification</h5><p>$\begin{aligned} &amp; \min_\theta \dfrac{1}{2} \sum_{j=1}^{n} \theta_j^{\,2} = \dfrac{1}{2} \left| \theta \right| ^2 \\ &amp; \quad \begin{matrix} \textrm{s.t.} &amp; p^\left(i\right) \cdot \left| \theta \right| \geq +1 &amp; \textsf{if } y^\left(i\right)=1 \\ &amp; p^\left(i\right) \cdot \left| \theta \right| \lt -1 &amp; \textsf{if } y^\left(i\right)=0 \end{matrix} \\ &amp; \textrm{where } p^\left(i\right) \textrm{ is the projection of } x^\left(i\right) \textrm{ onto the vector } \theta \end{aligned}$</p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-7/4.png" alt="Large Margin"></p>
<h4 id="Kernels"><a href="#Kernels" class="headerlink" title="Kernels"></a>Kernels</h4><h5 id="Kernels-1"><a href="#Kernels-1" class="headerlink" title="Kernels"></a>Kernels</h5><p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-7/5.png" alt="kernels"></p>
<p>Given $x$, compute new feature depending on proximity to landmarks $l^\left(1\right) ,\, l^\left(2\right) ,\, l^\left(3\right)$</p>
<p>$\begin{aligned} f_1 &amp;= \mathrm{similarity} \hspace{-0.5mm} \left( x,\,l^\left(1\right) \right) = \exp \left( - \dfrac{ \left| x-l^\left(1\right) \right| ^2 }{2\sigma^2} \right) \\ f_2 &amp;= \mathrm{similarity} \hspace{-0.5mm} \left( x,\,l^\left(2\right) \right) = \exp \left( - \dfrac{ \left| x-l^\left(2\right) \right| ^2 }{2\sigma^2} \right) \\ f_3 &amp;= \underbrace{\mathrm{similarity}}_\textsf{kernel} \hspace{-0.5mm} \left( x,\,l^\left(3\right) \right) = \exp \left( - \dfrac{ \left| x-l^\left(3\right) \right| ^2 }{2\sigma^2} \right) \quad \textsf{Gaussian kernel} \end{aligned}$</p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-7/6.png" alt="sigma"></p>
<p>Predict $1$ when $\theta_0 + \theta_1f_1 + \theta_2f_2 + \theta_3f_3 \geq 0$</p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-7/7.png" alt="decision boundary"></p>
<h5 id="SVM-with-Kernels"><a href="#SVM-with-Kernels" class="headerlink" title="SVM with Kernels"></a>SVM with Kernels</h5><p>Given $\left(x^\left(1\right),\,y^\left(1\right)\right) ,\, \left(x^\left(2\right),\,y^\left(2\right)\right) ,\,\dots,\, \left(x^\left(m\right),\,y^\left(m\right)\right)$,<br><br>Choose $l^\left(1\right)=x^\left(1\right) ,\, l^\left(2\right)=x^\left(2\right) ,\,\dots,\, l^\left(m\right)=x^\left(m\right)$.<br><br>Given example $x$:<br><br>&emsp; $f = \begin{bmatrix} f_0 \\ f_1 \\ f_2 \\ \vdots \\ f_m \end{bmatrix} = \begin{bmatrix} 1 \\ \mathrm{similarity} \hspace{-0.5mm} \left( x,\,l^\left(1\right) \right) \\ \mathrm{similarity} \hspace{-0.5mm} \left( x,\,l^\left(2\right) \right) \\ \vdots \\ \mathrm{similarity} \hspace{-0.5mm} \left( x,\,l^\left(m\right) \right) \end{bmatrix}$<br><br>For training example $\left(x^\left(i\right),\,y^\left(i\right)\right)$:<br><br>&emsp; $f_i^\left(i\right) = \mathrm{similarity} \hspace{-0.5mm} \left( x^\left(i\right),\,l^\left(i\right) \right) = \mathrm{similarity} \hspace{-0.5mm} \left( x^\left(i\right),\,x^\left(i\right) \right) = \exp \left( -\dfrac{0}{2\sigma^2} \right) =1$<br><br>&emsp; $f = \begin{bmatrix} f_0^\left(i\right) \\ f_1^\left(i\right) \\ f_2^\left(i\right) \\ \vdots \\ f_m^\left(i\right) \end{bmatrix} = \begin{bmatrix} 1 \\ \mathrm{similarity} \hspace{-0.5mm} \left( x^\left(i\right),\,l^\left(1\right) \right) \\ \mathrm{similarity} \hspace{-0.5mm} \left( x^\left(i\right),\,l^\left(2\right) \right) \\ \vdots \\ \mathrm{similarity} \hspace{-0.5mm} \left( x^\left(i\right),\,l^\left(m\right) \right) \end{bmatrix}$</p>
<p><strong>Hypothesis</strong><br>&emsp; Given $x$, compute features $f \in \mathbb{R}^{m+1}$<br><br>&emsp; Predict $y=1$ if $\theta^\mathsf{T}f\geq0$<br><br>&emsp; Predict $y=0$ if $\theta^\mathsf{T}f\lt0$</p>
<p><strong>Training</strong><br>&emsp; $\begin{aligned} \min_\theta \; C\cdot \sum_{i=1}^m \left[ y ^\left(i\right) \, \mathsf{cost}_\mathsf{1}  \hspace{-0.5mm} \left( \theta^\mathsf{T} f^\left(i\right) \right) + \left( 1-y^\left(i\right) \right) \mathsf{cost}_\mathsf{0} \hspace{-0.5mm} \left( \theta^\mathsf{T} f^\left(i\right) \right) \right] + \dfrac{1}{2} \sum_{j=1}^{m} \theta_j^{\,2} \end{aligned}$</p>
<p><strong>SVM Parameters</strong><br>&emsp; $C \ _{ \tiny \left( \sim \dfrac{1}{\lambda} \right) } \ \ \begin{cases} \textsf{Large } C \textsf{: low bias, high variance} \\ \textsf{Small } C \textsf{: high bias, low variance} \end{cases}$<br><br>&emsp; $\sigma^2 \ \ \begin{cases} \textsf{Large } \sigma^2 \textsf{: features } f_i \textsf{ vary more smoothly, high bias, low variance} \\ \textsf{Small } \sigma^2 \textsf{: features } f_i \textsf{ vary less smoothly, low bias, high variance} \end{cases} ^\strut$</p>
<h4 id="SVMs-in-Practice"><a href="#SVMs-in-Practice" class="headerlink" title="SVMs in Practice"></a>SVMs in Practice</h4><h5 id="Using-an-SVM"><a href="#Using-an-SVM" class="headerlink" title="Using an SVM"></a>Using an SVM</h5><p><strong>Choice of kernel (similarity function)</strong></p>
<ul>
<li><strong>No kernel (linear kernel)</strong><br>Predict $y=1$ if $\theta^\mathsf{T}x\geq0$</li>
<li><strong>Gaussian kernel</strong><br>$f_i = \exp \left( - \dfrac{ \left| x-l^\left(i\right) \right| ^2 }{2\sigma^2} \right) \qquad l^\left(i\right)=x^\left(i\right)$<br><br>need to choose $\sigma^2$<br><br>perform feature scaling before using Gaussian kernel</li>
<li><strong>Polynomial kernel</strong><br>$\mathrm{similarity} \hspace{-0.5mm} \left( x,\,l \right) = \left( x^\mathsf{T}l +\mathit{const} \right) ^\mathit{degree}$</li>
<li>String kernel, chi-square kernel, histogram intersection kernel, …</li>
</ul>
<p><em>Not all similarity functions $\mathrm{similarity} \hspace{-0.5mm} \left( x,\,l \right)$ make valid kernels.</em><br><em>Need to satisfy technical condition called “Mercer’s Theorem” to make sure SVM packages’ optimizations run correctly, and do not diverge.</em></p>
<p><strong>Multi-class Classification</strong></p>
<ul>
<li>built-in functionality</li>
<li>use one-vs-all method</li>
</ul>
<p><strong>Logistic Regression vs. SVMs</strong></p>
<p>$\begin{aligned} n &amp;= \textsf{number of features} \quad x \in \mathbb{R}^{n+1} \\ m &amp;= \textsf{number of training examples} \end{aligned}$</p>
<ul>
<li><strong>if $n$ is large (relative to $m$)</strong><br>use logistic regression, or SVM without a kernel (linear kernel)</li>
<li><strong>if $n$ is small, $m$ is intermediate</strong><br>use SVM with Gaussian kernel</li>
<li><strong>if $n$ is small, $m$ is large</strong><br>create/add more features, then use logistic regression or SVM without a kernel</li>
<li>Neural network likely to work well for most of these settings, but maybe slower to train</li>
</ul>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Python · Anaconda Tutorial</title>
    <url>/post/Programming/Python/Python-Anaconda-Tutorial/</url>
    <content><![CDATA[<p>这里只列出了部分基础操作命令。<br><br></p>
<h3 id="环境管理"><a href="#环境管理" class="headerlink" title="环境管理"></a>环境管理</h3><ol>
<li><strong>查看所有环境</strong><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda env list</span><br></pre></td></tr></table></figure>
或者使用命令<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda info --envs</span><br></pre></td></tr></table></figure></li>
<li><strong>创建环境</strong><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create --name your_env_name</span><br></pre></td></tr></table></figure>
或者使用命令<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n your_env_name</span><br></pre></td></tr></table></figure>
指定 Python 版本和安装包<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n your_env_name python=3.5 numpy pandas</span><br></pre></td></tr></table></figure>
克隆一部分旧的环境<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n your_env_name --<span class="built_in">clone</span> oldname</span><br></pre></td></tr></table></figure>
<a id="more"></a></li>
<li><strong>启用环境</strong><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda activate your_env_name</span><br></pre></td></tr></table></figure>
或者使用命令<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">activate your_env_name</span><br></pre></td></tr></table></figure></li>
<li><strong>停用环境</strong><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda deactivate</span><br></pre></td></tr></table></figure></li>
<li><strong>删除环境</strong><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda remove -n your_env_name --all</span><br></pre></td></tr></table></figure></li>
<li><strong>导出环境配置</strong><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda env <span class="built_in">export</span> &gt; environment.yml</span><br></pre></td></tr></table></figure></li>
<li><strong>根据配置文件生成环境</strong><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda env create -f environment.yml</span><br></pre></td></tr></table></figure>
<br></li>
</ol>
<h3 id="包管理"><a href="#包管理" class="headerlink" title="包管理"></a>包管理</h3><ol>
<li><strong>列举包</strong><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda list</span><br></pre></td></tr></table></figure>
指定某个包<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda list -n packagename</span><br></pre></td></tr></table></figure></li>
<li><strong>安装包</strong><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda install packagename</span><br></pre></td></tr></table></figure>
指定某个环境<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda install -n envname</span><br></pre></td></tr></table></figure></li>
<li><strong>更新包</strong><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda update packagename</span><br></pre></td></tr></table></figure>
指定某个环境<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda update -n envname packagename</span><br></pre></td></tr></table></figure></li>
<li><strong>删除包</strong><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda remove packagename</span><br></pre></td></tr></table></figure>
指定某个环境<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda remove -n envname</span><br></pre></td></tr></table></figure></li>
<li><strong>更新 conda、anaconda、python</strong><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda update conda</span><br><span class="line">conda update anaconda</span><br><span class="line">conda update python</span><br></pre></td></tr></table></figure>
指定 Python 版本<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda install python=3.6</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>Programming</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Anaconda</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine Learning (9) · Anomaly Detection</title>
    <url>/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-9/</url>
    <content><![CDATA[<p>Stanford University, <strong>Machine Learning,</strong> <em>Andrew Ng,</em> <a href="https://www.coursera.org/learn/machine-learning/home/info">Coursera</a></p>
<p><strong><em>Week 9:</em></strong> Anomaly Detection, Recommender Systems <sup> <code>Part 1</code></sup></p>
<h3 id="Anomaly-Detection"><a href="#Anomaly-Detection" class="headerlink" title="Anomaly Detection"></a>Anomaly Detection</h3><h4 id="Density-Estimation"><a href="#Density-Estimation" class="headerlink" title="Density Estimation"></a>Density Estimation</h4><h5 id="Problem-Motivation"><a href="#Problem-Motivation" class="headerlink" title="Problem Motivation"></a>Problem Motivation</h5><p>Dataset $\left\{ x^\left(1\right) ,\, x^\left(2\right) ,\,\dots,\, x^\left(m\right) \right\}$, is $x_\mathrm{test}$ anomalous?</p>
<p>Model $p\left(x\right) \begin{cases} \lt \varepsilon &amp; \rightarrow \textsf{flag anomaly} \\ \geq \varepsilon &amp; \rightarrow \textsf{OK} \end{cases}$</p>
<a id="more"></a>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-9/1.png" alt="1"></p>
<ul>
<li>fraud detection</li>
<li>manufacturing</li>
<li>monitoring computers in a data center</li>
</ul>
<h5 id="Gaussian-Distribution"><a href="#Gaussian-Distribution" class="headerlink" title="Gaussian Distribution"></a>Gaussian Distribution</h5><p>Gaussian (Normal) Distribution $x \sim \mathcal{N} \left( \mu ,\, \sigma^2 \right)$<br><br>$x$ is a distributed Gaussian with mean $\mu$, variance $\sigma^2$.<br><br>$p\left( x;\,\mu,\,\sigma^2\right) = \dfrac{1}{\sqrt{2\pi}\sigma} \exp{ \left( - \dfrac{ \left(x-\mu\right)^2 }{ 2\sigma^2 } \right) }$</p>
<p><strong>Parameter Estimation</strong></p>
<p>Dataset $\left\{ x^\left(1\right) ,\, x^\left(2\right) ,\,\dots,\, x^\left(m\right) \right\} \quad x^\left(i\right) \in\mathbb{R}$ $\quad \Leftarrow \quad x^\left(i\right) \sim \mathcal{N} \left( \mu ,\, \sigma^2 \right)$</p>
<p>Maximum Likelihood Estimation<br><br>$\mu = \dfrac{1}{m} \displaystyle\sum_{i=1}^{m} x^\left(i\right) \qquad \sigma^2 = \dfrac{1}{m} \displaystyle\sum_{i=1}^{m} \left( x^\left(i\right)-\mu \right)^2$</p>
<h5 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h5><p><strong>Density Estimation</strong></p>
<p>Training set: $\left\{ x^\left(1\right) ,\, x^\left(2\right) ,\,\dots,\, x^\left(m\right) \right\}$<br><br>Each example is $x\in\mathbb{R}^n$<br><br>$p\left(x\right) = \displaystyle\prod_{j=1}^{n} p\left( x_j;\,\mu_j,\,\sigma_j^2\right)$</p>
<p><strong>Anomaly Detection Algorithm</strong></p>
<ol>
<li><p>Choose features $x_i$ that might be indicative of anomalous examples</p>
</li>
<li><p>Fit parameters $\mu_1,\,\dots,\,\mu_n,\,\sigma_1^2,\,\dots,\,\sigma_n^2$</p>
<p>$\mu = \dfrac{1}{m} \displaystyle\sum_{i=1}^{m} x^\left(i\right) \qquad \sigma^2 = \dfrac{1}{m} \displaystyle\sum_{i=1}^{m} \left( x^\left(i\right)-\mu \right)^2$</p>
</li>
<li><p>Given a new example $x$, compute $p\left(x\right)$</p>
<p>$p\left(x\right) = \displaystyle\prod_{j=1}^{n} p\left( x_j;\,\mu_j,\,\sigma_j^2\right) = \displaystyle\prod_{j=1}^{n} \dfrac{1}{\sqrt{2\pi}\sigma_j} \exp{ \left( - \dfrac{ \left(x_j-\mu_j\right)^2 }{ 2\sigma_j^2 } \right) }$</p>
<p>Flag an anomaly if $p\left(x\right) \lt \varepsilon$</p>
</li>
</ol>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-9/2.png" alt="2"></p>
<h4 id="Building-an-Anomaly-Detection-System"><a href="#Building-an-Anomaly-Detection-System" class="headerlink" title="Building an Anomaly Detection System"></a>Building an Anomaly Detection System</h4><h5 id="Developing-and-Evaluating-an-Anomaly-Detection-System"><a href="#Developing-and-Evaluating-an-Anomaly-Detection-System" class="headerlink" title="Developing and Evaluating an Anomaly Detection System"></a>Developing and Evaluating an Anomaly Detection System</h5><p>Assume we have some labeled data of anomalous and non-anomalous examples.<br>&emsp;&emsp;($y=0$ if normal, $y=1$ if anomalous).<br><br>Training set: $x^\left(1\right) ,\,x^\left(2\right) ,\,\dots ,\,x^\left(m\right)$ (assume normal examples / not anomalous)<br><br>Cross validation set: $\left( x^\left(1\right)_\textrm{cv} ,\, y^\left(1\right)_\textrm{cv} \right) ,\, \left( x^\left(2\right)_\textrm{cv} ,\, y^\left(2\right)_\textrm{cv} \right) ,\, \dots ,\, \left( x^\left(m_\textrm{cv}\right)_\textrm{cv} ,\, y^\left(m_\textrm{cv}\right)_\textrm{cv} \right)$<br><br>Test set: $\left( x^\left(1\right)_\textrm{test} ,\, y^\left(1\right)_\textrm{test} \right) ,\, \left( x^\left(2\right)_\textrm{test} ,\, y^\left(2\right)_\textrm{test} \right) ,\, \dots ,\, \left( x^\left(m_\textrm{test}\right)_\textrm{test} ,\, y^\left(m_\textrm{test}\right)_\textrm{test} \right)$</p>
<p><strong>Algorithm Evaluation</strong></p>
<p>Fit model $p\left(x\right)$ on the training set $\left\{ x^\left(1\right) ,\,x^\left(2\right) ,\,\dots ,\,x^\left(m\right) \right\}$<br><br>On a cross-validation / test example $x$, predict<br><br>$\qquad y= \begin{cases} 1 &amp; \textsf{if } p\left(x\right) \lt \varepsilon \quad \textrm{ (anomaly)} \\ 0 &amp; \textsf{if } p\left(x\right) \geq \varepsilon \quad \textrm{ (normal)} \end{cases}$<br><br>Possible evaluation metrics:<br>$\qquad \begin{aligned} &amp; \textsf{- True Positive, False Positive, True Negative, False Negative} \\ &amp; \textsf{- Precision / Recall} \\ &amp; \textsf{- F}_\textsf{1}\textsf{ score } \end{aligned}$<br><br>Can also use cross-validation set to choose parameter $\varepsilon$</p>
<h5 id="Anomaly-Detection-vs-Supervised-Learning"><a href="#Anomaly-Detection-vs-Supervised-Learning" class="headerlink" title="Anomaly Detection vs. Supervised Learning"></a>Anomaly Detection vs. Supervised Learning</h5><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">Anomaly Detection</th>
<th style="text-align:left">Supervised Learning</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Very small number of positive examples $\left(y=1\right)$; <br>Large number of negative examples $\left(y=0\right)$.</td>
<td style="text-align:left">Large number of positive and negative examples.</td>
</tr>
<tr>
<td style="text-align:left">Many different types of anomalies. Hard for any algorithm to learn from positive examples what the anomalies look like.</td>
<td style="text-align:left">Enough positive examples for algorithm to set a sense of what positive examples are like.</td>
</tr>
<tr>
<td style="text-align:left">Future anomalies may look nothing like any of the anomalous examples we’ve seen so far.</td>
<td style="text-align:left">Future positive examples likely to be similar to ones in training set.</td>
</tr>
</tbody>
</table>
</div>
<h5 id="Choosing-What-Features-to-Use"><a href="#Choosing-What-Features-to-Use" class="headerlink" title="Choosing What Features to Use"></a>Choosing What Features to Use</h5><p><strong>Non-gaussian Features</strong></p>
<p>transform: $x\leftarrow \log\left(x+c\right) ,\, x^{1/t} ,\,\dots$</p>
<p><strong>Error Analysis for Anomaly Detection</strong></p>
<p>Want large $p\left(x\right)$ for normal examples $x$, small $p\left(x\right)$ for anomalous examples $x$.<br><br>The most common problem: $p\left(x\right)$ is comparable for normal and anomalous examples.<br><br>Look at the anomaly that failed to flag, and see if that inspires creating new features.</p>
<h4 id="Multivariate-Gaussian-Distribution"><a href="#Multivariate-Gaussian-Distribution" class="headerlink" title="Multivariate Gaussian Distribution"></a>Multivariate Gaussian Distribution</h4><h5 id="Multivariate-Gaussian-Distribution-1"><a href="#Multivariate-Gaussian-Distribution-1" class="headerlink" title="Multivariate Gaussian Distribution"></a>Multivariate Gaussian Distribution</h5><p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-9/3.png" alt="motivating example"></p>
<p><strong>Multivariate Gaussian Distribution</strong></p>
<p>$x\in\mathbb{R}^n$. Don’t model $p\left(x_1\right) ,\, p\left(x_2\right) ,\, \dots$ separately; model $p\left(x\right)$ all in one go.<br><br><strong>Parameters:</strong> $\mu \in \mathbb{R}^n ,\, \Sigma \in \mathbb{R}^{n \times n}$ (covariance matrix)<br><br>$p\left(x;\,\mu,\,\Sigma\right) = \dfrac{1}{\left(2\pi\right)^{\frac{n}{2}} \left|\Sigma\right|^{\frac{1}{2}}} \exp\left( -\dfrac{1}{2} \left(x-\mu\right)^\mathsf{T} \Sigma^{-1} \left(x-\mu\right) \right)$</p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-9/4.png" alt="Multivariate Gaussian Distribution"></p>
<h5 id="Anomaly-Detection-using-the-Multivariate-Gaussian-Distribution"><a href="#Anomaly-Detection-using-the-Multivariate-Gaussian-Distribution" class="headerlink" title="Anomaly Detection using the Multivariate Gaussian Distribution"></a>Anomaly Detection using the Multivariate Gaussian Distribution</h5><p><strong>Parameters</strong> $\mu ,\, \Sigma$<br><br>$p\left(x;\,\mu,\,\Sigma\right) = \dfrac{1}{\left(2\pi\right)^{\frac{n}{2}} \left|\Sigma\right|^{\frac{1}{2}}} \exp\left( -\dfrac{1}{2} \left(x-\mu\right)^\mathsf{T} \Sigma^{-1} \left(x-\mu\right) \right)$</p>
<p><strong>Parameter Fitting</strong><br><br>Given training set $\left\{ x^\left(1\right) ,\, x^\left(2\right) ,\, \dots ,\, x^\left(m\right) \right\}$<br><br>$\mu=\dfrac{1}{m} \displaystyle\sum_{i=1}^{m} x^\left(i\right) \qquad \Sigma=\dfrac{1}{m} \displaystyle\sum_{i=1}^{m} \left( x^\left(i\right)-\mu \right) \left( x^\left(i\right)-\mu \right)^\mathsf{T}$</p>
<p><strong>Anomaly Detection Algorithm</strong></p>
<ol>
<li><p>Fit model $p\left(x\right)$ by setting</p>
<p>$\mu=\dfrac{1}{m} \displaystyle\sum_{i=1}^{m} x^\left(i\right) \qquad \Sigma=\dfrac{1}{m} \displaystyle\sum_{i=1}^{m} \left( x^\left(i\right)-\mu \right) \left( x^\left(i\right)-\mu \right)^\mathsf{T}$</p>
</li>
<li><p>Given a new example $x$, compute $p\left(x\right)$</p>
<p>$p\left(x\right) = \dfrac{1}{\left(2\pi\right)^{\frac{n}{2}} \left|\Sigma\right|^{\frac{1}{2}}} \exp\left( -\dfrac{1}{2} \left(x-\mu\right)^\mathsf{T} \Sigma^{-1} \left(x-\mu\right) \right)$</p>
<p>Flag an anomaly if $p\left(x\right) \lt \varepsilon$</p>
</li>
</ol>
<p><strong>Relationship to Original Model</strong></p>
<p><img src="/post/Open-Course/Machine-Learning/Machine-Learning-Andrew-Ng-9/5.png" alt="orig"></p>
<p>Original model $p\left(x\right) = p\left( x_1;\,\mu_1,\,\sigma_1^2\right) \times p\left( x_2;\,\mu_2,\,\sigma_2^2\right) \times \cdots \times p\left( x_n;\,\mu_n,\,\sigma_n^2\right)$<br><br>Corresponds to multivariate Gaussian $p\left(x\right) = \dfrac{1}{\left(2\pi\right)^{\frac{n}{2}} \left|\Sigma\right|^{\frac{1}{2}}} \exp\left( -\dfrac{1}{2} \left(x-\mu\right)^\mathsf{T} \Sigma^{-1} \left(x-\mu\right) \right)$<br><br>where $\Sigma = \begin{bmatrix} \begin{matrix} \sigma_1^2 &amp; \\ &amp; \sigma_2^2 \end{matrix} &amp; \Large{0} \\ \Large{0} &amp; \begin{matrix} \ddots &amp; \\ &amp; \sigma_n^2 \end{matrix} \end{bmatrix}$</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Original Model</th>
<th>Multivariate Gaussian</th>
</tr>
</thead>
<tbody>
<tr>
<td>$p\left(x\right) = \displaystyle\prod_{j=1}^{n} p\left( x_j;\,\mu_j,\,\sigma_j^2\right)$</td>
<td>$p\left(x\right) = \dfrac{1}{\left(2\pi\right)^{\frac{n}{2}} \left(\det\Sigma\right)^{\frac{1}{2}}} \exp\left( -\dfrac{1}{2} \left(x-\mu\right)^\mathsf{T} \Sigma^{-1} \left(x-\mu\right) \right)$</td>
</tr>
<tr>
<td>Manually create features to capture anomalies where $x_1,\,x_2$ take unusual combinations of values.</td>
<td>Automatically captures correlations between features.</td>
</tr>
<tr>
<td>Computationally cheaper. (scales better to large $n$)</td>
<td>Computationally more expensive.</td>
</tr>
<tr>
<td>OK even if training set size $m$ is small.</td>
<td>Must have $m\gt n$, or else $\Sigma$ is non-invertible.</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>Open Course</category>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
</search>
